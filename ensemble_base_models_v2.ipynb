{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First ensemble with NSL-KDD\n",
    "# Parameters\n",
    "\n",
    "#----------------------------------------------\n",
    "# 0 for not using it as base learner\n",
    "# 1 for using it as base learner\n",
    "\n",
    "use_model_ada = 1 \n",
    "use_model_dnn = 1 \n",
    "use_model_mlp = 1 \n",
    "use_model_lgbm = 1 \n",
    "use_model_rf = 1 \n",
    "use_model_svm = 1\n",
    "use_model_knn = 1 \n",
    "#----------------------------------------------\n",
    "# 0 for training the model\n",
    "# 1 for using the saved version of the model\n",
    "\n",
    "load_model_ada = 0 \n",
    "load_model_dnn = 0 \n",
    "load_model_mlp = 0 \n",
    "load_model_lgbm = 0 \n",
    "load_model_rf = 0 \n",
    "load_model_svm = 0\n",
    "load_model_knn = 0 \n",
    "#----------------------------------------------\n",
    "\n",
    "# load_model_ada = 1\n",
    "# load_model_dnn = 1 \n",
    "# load_model_mlp = 1 \n",
    "# load_model_lgbm = 1 \n",
    "# load_model_rf = 1 \n",
    "# load_model_svm = 1\n",
    "# load_model_knn = 1 \n",
    "#----------------------------------------------\n",
    "feature_selection_bit = 0\n",
    "# feature_selection_bit = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the name of the output text file\n",
    "if feature_selection_bit == 0:\n",
    "    output_file_name = \"ensemble_base_models_all_features.txt\"\n",
    "    with open(output_file_name, \"w\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('---- ensemble_base_models_all_features', file = f)\n",
    "\n",
    "elif feature_selection_bit == 1:\n",
    "    output_file_name = \"ensemble_base_models_feature_selection.txt\"\n",
    "    with open(output_file_name, \"w\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('----ensemble_base_models_feature_selection--', file = f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle # saving and loading trained model\n",
    "from os import path\n",
    "\n",
    "\n",
    "# importing required libraries for normalizing data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import (StandardScaler, OrdinalEncoder,LabelEncoder, MinMaxScaler, OneHotEncoder)\n",
    "from sklearn.preprocessing import Normalizer, MaxAbsScaler , RobustScaler, PowerTransformer\n",
    "\n",
    "# importing library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score # for calculating accuracy of model\n",
    "from sklearn.model_selection import train_test_split # for splitting the dataset for training and testing\n",
    "from sklearn.metrics import classification_report # for generating a classification report of model\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Dense # importing dense layer\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "# representation of model layers\n",
    "#from keras.utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import shap\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "start_program = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def confusion_metrics (name_model,predictions,true_labels):\n",
    "\n",
    "    name = name_model\n",
    "    pred_label = predictions\n",
    "    y_test_01 = true_labels \n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('--------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print(name, file = f)\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('CONFUSION MATRIX')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    # pred_label = label[ypred]\n",
    "\n",
    "    confusion_matrix = pd.crosstab(y_test_01, pred_label,rownames=['Actual ALERT'],colnames = ['Predicted ALERT'], dropna=False).sort_index(axis=0).sort_index(axis=1)\n",
    "    all_unique_values = sorted(set(pred_label) | set(y_test_01))\n",
    "    z = np.zeros((len(all_unique_values), len(all_unique_values)))\n",
    "    rows, cols = confusion_matrix.shape\n",
    "    z[:rows, :cols] = confusion_matrix\n",
    "    confusion_matrix  = pd.DataFrame(z, columns=all_unique_values, index=all_unique_values)\n",
    "    # confusion_matrix.to_csv('Ensemble_conf_matrix.csv')\n",
    "    # with open(output_file_name, \"a\") as f:print(confusion_matrix,file=f)\n",
    "    print(confusion_matrix)\n",
    "    with open(output_file_name, \"a\") as f: print('Confusion Matrix', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print(confusion_matrix, file = f)\n",
    "\n",
    "\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "    TP_total = sum(TP)\n",
    "    TN_total = sum(TN)\n",
    "    FP_total = sum(FP)\n",
    "    FN_total = sum(FN)\n",
    "\n",
    "    TP_total = np.array(TP_total,dtype=np.float64)\n",
    "    TN_total = np.array(TN_total,dtype=np.float64)\n",
    "    FP_total = np.array(FP_total,dtype=np.float64)\n",
    "    FN_total = np.array(FN_total,dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------------------------------------#----------------------------------------------------------------\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('METRICS')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    Acc = accuracy_score(y_test_01, pred_label)\n",
    "    Precision = precision_score(y_test_01, pred_label, average='macro')\n",
    "    Recall = recall_score(y_test_01, pred_label, average='macro')\n",
    "    F1 =  f1_score(y_test_01, pred_label, average='macro')\n",
    "    BACC = balanced_accuracy_score(y_test_01, pred_label)\n",
    "    MCC = matthews_corrcoef(y_test_01, pred_label)\n",
    "\n",
    "\n",
    "    # voting_acc_01 = Acc\n",
    "    # voting_pre_01 = Precision\n",
    "    # weighed_avg_rec_01 = Recall\n",
    "    # weighed_avg_f1_01 = F1\n",
    "    # weighed_avg_bacc_01 = BACC\n",
    "    # weighed_avg_mcc_01 = MCC\n",
    "    # with open(output_file_name, \"a\") as f:print('Accuracy total: ', Acc,file=f)\n",
    "    print('Accuracy total: ', Acc)\n",
    "    print('Precision total: ', Precision )\n",
    "    print('Recall total: ', Recall )\n",
    "    print('F1 total: ', F1 )\n",
    "    print('BACC total: ', BACC)\n",
    "    print('MCC total: ', MCC)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Accuracy total: ', Acc, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Precision total: ', Precision, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Recall total: ', Recall , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('F1 total: ', F1, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('BACC total: ', BACC , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('MCC total: ', MCC, file = f)\n",
    "\n",
    "    return Acc, Precision, Recall, F1, BACC, MCC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# attach the column names to the dataset\n",
    "feature=[\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\n",
    "          \"num_failed_logins\",\"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\n",
    "          \"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\n",
    "          \"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\", \n",
    "          \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\n",
    "          \"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\",\"difficulty\"]\n",
    "# KDDTrain+_2.csv & KDDTest+_2.csv are the datafiles without the last column about the difficulty score\n",
    "# these have already been removed.\n",
    "\n",
    "train='KDDTrain+.txt'\n",
    "test='KDDTest+.txt'\n",
    "\n",
    "df=pd.read_csv(train,names=feature)\n",
    "df_test=pd.read_csv(test,names=feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Training set: (125973, 43)\n",
      "Dimensions of the Test set: (22544, 43)\n",
      "Label distribution Training set:\n",
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Label distribution Test set:\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "xterm                13\n",
      "rootkit              13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "phf                   2\n",
      "worm                  2\n",
      "sqlattack             2\n",
      "perl                  2\n",
      "udpstorm              2\n",
      "loadmodule            2\n",
      "imap                  1\n",
      "Name: label, dtype: int64\n",
      "Training set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'service' has 70 categories\n",
      "Feature 'flag' has 11 categories\n",
      "Feature 'label' has 23 categories\n",
      "\n",
      "Distribution of categories in service:\n",
      "http        40338\n",
      "private     21853\n",
      "domain_u     9043\n",
      "smtp         7313\n",
      "ftp_data     6860\n",
      "Name: service, dtype: int64\n",
      "Test set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'service' has 64 categories\n",
      "Feature 'flag' has 11 categories\n",
      "Feature 'label' has 38 categories\n",
      "['Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp', 'service_IRC', 'service_X11', 'service_Z39_50', 'service_aol', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_harvest', 'service_hostnames', 'service_http', 'service_http_2784', 'service_http_443', 'service_http_8001', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_red_i', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urh_i', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois', 'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n",
      "   protocol_type  service  flag\n",
      "0              1       20     9\n",
      "1              2       44     9\n",
      "2              1       49     5\n",
      "3              1       24     9\n",
      "4              1       24     9\n",
      "(125973, 123)\n",
      "(22544, 123)\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has shape: (125973, 122) \n",
      "y_train has shape: (125973, 1)\n",
      "X_test has shape: (22544, 122) \n",
      "y_test has shape: (22544, 1)\n",
      "Counter({0: 67343, 1: 45927, 2: 11656, 3: 995, 4: 52})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# shape, this gives the dimensions of the dataset\n",
    "print('Dimensions of the Training set:',df.shape)\n",
    "print('Dimensions of the Test set:',df_test.shape)\n",
    "\n",
    "\n",
    "df.drop(['difficulty'],axis=1,inplace=True)\n",
    "df_test.drop(['difficulty'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print('Label distribution Training set:')\n",
    "print(df['label'].value_counts())\n",
    "print()\n",
    "print('Label distribution Test set:')\n",
    "print(df_test['label'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# colums that are categorical and not binary yet: protocol_type (column 2), service (column 3), flag (column 4).\n",
    "# explore categorical features\n",
    "print('Training set:')\n",
    "for col_name in df.columns:\n",
    "    if df[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "#see how distributed the feature service is, it is evenly distributed and therefore we need to make dummies for all.\n",
    "print()\n",
    "print('Distribution of categories in service:')\n",
    "print(df['service'].value_counts().sort_values(ascending=False).head())\n",
    "\n",
    "\n",
    "\n",
    "# Test set\n",
    "print('Test set:')\n",
    "for col_name in df_test.columns:\n",
    "    if df_test[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df_test[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "categorical_columns=['protocol_type', 'service', 'flag']\n",
    "# insert code to get a list of categorical columns into a variable, categorical_columns\n",
    "categorical_columns=['protocol_type', 'service', 'flag'] \n",
    " # Get the categorical values into a 2D numpy array\n",
    "df_categorical_values = df[categorical_columns]\n",
    "testdf_categorical_values = df_test[categorical_columns]\n",
    "df_categorical_values.head()\n",
    "\n",
    "\n",
    "# protocol type\n",
    "unique_protocol=sorted(df.protocol_type.unique())\n",
    "string1 = 'Protocol_type_'\n",
    "unique_protocol2=[string1 + x for x in unique_protocol]\n",
    "# service\n",
    "unique_service=sorted(df.service.unique())\n",
    "string2 = 'service_'\n",
    "unique_service2=[string2 + x for x in unique_service]\n",
    "# flag\n",
    "unique_flag=sorted(df.flag.unique())\n",
    "string3 = 'flag_'\n",
    "unique_flag2=[string3 + x for x in unique_flag]\n",
    "# put together\n",
    "dumcols=unique_protocol2 + unique_service2 + unique_flag2\n",
    "print(dumcols)\n",
    "\n",
    "#do same for test set\n",
    "unique_service_test=sorted(df_test.service.unique())\n",
    "unique_service2_test=[string2 + x for x in unique_service_test]\n",
    "testdumcols=unique_protocol2 + unique_service2_test + unique_flag2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "print(df_categorical_values_enc.head())\n",
    "# test set\n",
    "testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "df_categorical_values_encenc = enc.fit_transform(df_categorical_values_enc)\n",
    "df_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(),columns=dumcols)\n",
    "# test set\n",
    "testdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\n",
    "testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)\n",
    "\n",
    "df_cat_data.head()\n",
    "\n",
    "\n",
    "trainservice=df['service'].tolist()\n",
    "testservice= df_test['service'].tolist()\n",
    "difference=list(set(trainservice) - set(testservice))\n",
    "string = 'service_'\n",
    "difference=[string + x for x in difference]\n",
    "difference\n",
    "\n",
    "for col in difference:\n",
    "    testdf_cat_data[col] = 0\n",
    "\n",
    "testdf_cat_data.shape\n",
    "\n",
    "newdf=df.join(df_cat_data)\n",
    "newdf.drop('flag', axis=1, inplace=True)\n",
    "newdf.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf.drop('service', axis=1, inplace=True)\n",
    "# test data\n",
    "newdf_test=df_test.join(testdf_cat_data)\n",
    "newdf_test.drop('flag', axis=1, inplace=True)\n",
    "newdf_test.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf_test.drop('service', axis=1, inplace=True)\n",
    "print(newdf.shape)\n",
    "print(newdf_test.shape)\n",
    "\n",
    "\n",
    "# take label column\n",
    "labeldf=newdf['label']\n",
    "labeldf_test=newdf_test['label']\n",
    "# change the label column\n",
    "newlabeldf=labeldf.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "newlabeldf_test=labeldf_test.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "# put the new label column back\n",
    "newdf['label'] = newlabeldf\n",
    "newdf_test['label'] = newlabeldf_test\n",
    "print(newdf['label'].head())\n",
    "\n",
    "\n",
    "# Specify your selected features. Note that you'll need to modify this list according to your final processed dataframe\n",
    "#Uncomment the below lines to use these top 20 features from shap analysis\n",
    "#selected_features = [\"root_shell\",\"service_telnet\",\"num_shells\",\"service_uucp\",\"dst_host_same_src_port_rate\"\n",
    "#                     ,\"dst_host_rerror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_srv_count\",\"service_private\",\"logged_in\",\n",
    "#                    \"dst_host_serror_rate\",\"serror_rate\",\"srv_serror_rate\",\"flag_S0\",\"diff_srv_rate\",\"dst_host_srv_diff_host_rate\",\"num_file_creations\",\"flag_RSTR\"#,\"dst_host_same_srv_rate\",\"service_Idap\",\"label\"]\n",
    "                     \n",
    "\n",
    "# Select those features from your dataframe\n",
    "#newdf = newdf[selected_features]\n",
    "#newdf_test = newdf_test[selected_features]\n",
    "\n",
    "# Now your dataframe only contains your selected features.\n",
    "\n",
    "# creating a dataframe with multi-class labels (Dos,Probe,R2L,U2R,normal)\n",
    "multi_data = newdf.copy()\n",
    "multi_label = pd.DataFrame(multi_data.label)\n",
    "\n",
    "multi_data_test=newdf_test.copy()\n",
    "multi_label_test = pd.DataFrame(multi_data_test.label)\n",
    "\n",
    "\n",
    "# using standard scaler for normalizing\n",
    "std_scaler = StandardScaler()\n",
    "def standardization(df,col):\n",
    "    for i in col:\n",
    "        arr = df[i]\n",
    "        arr = np.array(arr)\n",
    "        df[i] = std_scaler.fit_transform(arr.reshape(len(arr),1))\n",
    "    return df\n",
    "\n",
    "numeric_col = multi_data.select_dtypes(include='number').columns\n",
    "data = standardization(multi_data,numeric_col)\n",
    "numeric_col_test = multi_data_test.select_dtypes(include='number').columns\n",
    "data_test = standardization(multi_data_test,numeric_col_test)\n",
    "\n",
    "# label encoding (0,1,2,3,4) multi-class labels (Dos,normal,Probe,R2L,U2R)\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2_test = preprocessing.LabelEncoder()\n",
    "enc_label = multi_label.apply(le2.fit_transform)\n",
    "enc_label_test = multi_label_test.apply(le2_test.fit_transform)\n",
    "multi_data = multi_data.copy()\n",
    "multi_data_test = multi_data_test.copy()\n",
    "\n",
    "multi_data['intrusion'] = enc_label\n",
    "multi_data_test['intrusion'] = enc_label_test\n",
    "\n",
    "#y_mul = multi_data['intrusion']\n",
    "multi_data\n",
    "multi_data_test\n",
    "\n",
    "\n",
    "\n",
    "multi_data.drop(labels= [ 'label'], axis=1, inplace=True)\n",
    "multi_data\n",
    "multi_data_test.drop(labels= [ 'label'], axis=1, inplace=True)\n",
    "multi_data_test\n",
    "\n",
    "\n",
    "y_train_multi= multi_data[['intrusion']]\n",
    "X_train_multi= multi_data.drop(labels=['intrusion'], axis=1)\n",
    "\n",
    "print('X_train has shape:',X_train_multi.shape,'\\ny_train has shape:',y_train_multi.shape)\n",
    "\n",
    "y_test_multi= multi_data_test[['intrusion']]\n",
    "X_test_multi= multi_data_test.drop(labels=['intrusion'], axis=1)\n",
    "\n",
    "print('X_test has shape:',X_test_multi.shape,'\\ny_test has shape:',y_test_multi.shape)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "label_counts = Counter(y_train_multi['intrusion'])\n",
    "print(label_counts)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "y_train_multi = LabelBinarizer().fit_transform(y_train_multi)\n",
    "\n",
    "y_test_multi = LabelBinarizer().fit_transform(y_test_multi)\n",
    "\n",
    "\n",
    "Y_train=y_train_multi.copy()\n",
    "X_train=X_train_multi.copy()\n",
    "\n",
    "Y_test=y_test_multi.copy()\n",
    "X_test=X_test_multi.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " ...\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 1 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.10249223e-01, -7.67859947e-03, -4.91864438e-03, ...,\n",
       "        -1.97262160e-02,  8.25150071e-01, -4.64315895e-02],\n",
       "       [-1.10249223e-01, -7.73736981e-03, -4.91864438e-03, ...,\n",
       "        -1.97262160e-02,  8.25150071e-01, -4.64315895e-02],\n",
       "       [-1.10249223e-01, -7.76224074e-03, -4.91864438e-03, ...,\n",
       "        -1.97262160e-02, -1.21190076e+00, -4.64315895e-02],\n",
       "       ...,\n",
       "       [-9.29714678e-02, -7.36430591e-03, -3.87394518e-03, ...,\n",
       "        -1.97262160e-02,  8.25150071e-01, -4.64315895e-02],\n",
       "       [-8.68282658e-02, -7.36430591e-03, -3.87568593e-03, ...,\n",
       "        -1.97262160e-02,  8.25150071e-01, -4.64315895e-02],\n",
       "       [ 1.61587463e-01, -7.46804833e-03,  1.06953862e-03, ...,\n",
       "        -1.97262160e-02,  8.25150071e-01, -4.64315895e-02]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Assuming you have features X and labels Y\n",
    "# X, Y = make_classification()\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy='minority', random_state=100)\n",
    "\n",
    "X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "print(Y_test)\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "X_train.values\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_class_train = np.argmax(y_train_multi, axis=1)\n",
    "single_class_test = np.argmax(y_test_multi, axis=1)\n",
    "\n",
    "\n",
    "df1 = X_train_multi.assign(Label = single_class_train)\n",
    "df2 =  X_test_multi.assign(Label = single_class_test)\n",
    "\n",
    "frames = [df1,  df2]\n",
    "\n",
    "df = pd.concat(frames,ignore_index=True)\n",
    "\n",
    "\n",
    "if feature_selection_bit == 1:\n",
    "    feature_selection = [\n",
    "                        'dst_host_same_srv_rate',\n",
    "                        'dst_host_srv_count',\n",
    "                        'dst_host_same_src_port_rate',\n",
    "                        'logged_in',\n",
    "                        'dst_host_serror_rate',\n",
    "                        'count',\n",
    "                        'srv_count',\n",
    "                        'dst_host_rerror_rate',\n",
    "                        'Label'\n",
    "                        ]\n",
    "\n",
    "    df_og = df\n",
    "    df = df[feature_selection]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y = df.pop('Label')\n",
    "X = df\n",
    "\n",
    "y1, y2 = pd.factorize(y)\n",
    "\n",
    "y_0 = pd.DataFrame(y1)\n",
    "y_1 = pd.DataFrame(y1)\n",
    "y_2 = pd.DataFrame(y1)\n",
    "y_3 = pd.DataFrame(y1)\n",
    "y_4 = pd.DataFrame(y1)\n",
    "\n",
    "\n",
    "# y_0 = y_0.replace(0, 0)\n",
    "# y_0 = y_0.replace(1, 1)\n",
    "y_0 = y_0.replace(2, 1)\n",
    "y_0 = y_0.replace(3, 1)\n",
    "y_0 = y_0.replace(4, 1)\n",
    "\n",
    "\n",
    "y_1 = y_1.replace(1, 999)\n",
    "y_1 = y_1.replace(0, 1)\n",
    "# y_1 = y_1.replace(1, 0)\n",
    "y_1 = y_1.replace(2, 1)\n",
    "y_1 = y_1.replace(3, 1)\n",
    "y_1 = y_1.replace(4, 1)\n",
    "y_1 = y_1.replace(999, 1)\n",
    "\n",
    "\n",
    "y_2 = y_2.replace(0, 1)\n",
    "y_2 = y_2.replace(1, 1)\n",
    "y_2 = y_2.replace(2, 0)\n",
    "y_2 = y_2.replace(3, 1)\n",
    "y_2 = y_2.replace(4, 1)\n",
    "\n",
    "\n",
    "y_3 = y_3.replace(0, 1)\n",
    "# y_3 = y_3.replace(1, 1)\n",
    "y_3 = y_3.replace(2, 1)\n",
    "y_3 = y_3.replace(3, 0)\n",
    "y_3 = y_3.replace(4, 1)\n",
    "\n",
    "\n",
    "y_4 = y_4.replace(0, 1)\n",
    "# y_4 = y_4.replace(1, 1)\n",
    "y_4 = y_4.replace(2, 1)\n",
    "y_4 = y_4.replace(3, 1)\n",
    "y_4 = y_4.replace(4, 0)\n",
    "\n",
    "\n",
    "\n",
    "df = df.assign(Label = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the dataset between level 00 and level 01\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "split = 0.7 # 0.5\n",
    "\n",
    "# X_00,X_01, y_00, y_01 = sklearn.model_selection.train_test_split(X, y, train_size=split)\n",
    "X_train,X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 77054, 1: 53387, 2: 14077, 3: 3880, 4: 119})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "label_counts2 = Counter(y)\n",
    "print(label_counts2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base learner Split\n",
    "# split = 0.7\n",
    "\n",
    "# X_train,X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_00, y_00, train_size=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83887</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>1.616978</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-1.211901</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105197</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007569</td>\n",
       "      <td>-0.004837</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>-0.618438</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>0.825150</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131702</th>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.577911</td>\n",
       "      <td>-0.096896</td>\n",
       "      <td>-0.017624</td>\n",
       "      <td>-0.059104</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>-0.113521</td>\n",
       "      <td>-0.143999</td>\n",
       "      <td>-0.890373</td>\n",
       "      <td>-0.016494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453815</td>\n",
       "      <td>-0.18843</td>\n",
       "      <td>-0.009419</td>\n",
       "      <td>-0.174880</td>\n",
       "      <td>-0.313124</td>\n",
       "      <td>-0.030535</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>-0.105681</td>\n",
       "      <td>0.718027</td>\n",
       "      <td>-0.056997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140096</th>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.577911</td>\n",
       "      <td>-0.096896</td>\n",
       "      <td>-0.017624</td>\n",
       "      <td>-0.059104</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>-0.113521</td>\n",
       "      <td>-0.143999</td>\n",
       "      <td>-0.890373</td>\n",
       "      <td>-0.016494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453815</td>\n",
       "      <td>-0.18843</td>\n",
       "      <td>-0.009419</td>\n",
       "      <td>-0.174880</td>\n",
       "      <td>-0.313124</td>\n",
       "      <td>-0.030535</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>-0.105681</td>\n",
       "      <td>0.718027</td>\n",
       "      <td>-0.056997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134296</th>\n",
       "      <td>-0.155534</td>\n",
       "      <td>-0.021480</td>\n",
       "      <td>-0.067959</td>\n",
       "      <td>-0.017624</td>\n",
       "      <td>-0.059104</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>-0.113521</td>\n",
       "      <td>-0.143999</td>\n",
       "      <td>-0.890373</td>\n",
       "      <td>-0.016494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453815</td>\n",
       "      <td>-0.18843</td>\n",
       "      <td>-0.009419</td>\n",
       "      <td>-0.174880</td>\n",
       "      <td>-0.313124</td>\n",
       "      <td>-0.030535</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>-0.105681</td>\n",
       "      <td>0.718027</td>\n",
       "      <td>-0.056997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59753</th>\n",
       "      <td>-0.109481</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>7.143771</td>\n",
       "      <td>-0.618438</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-1.211901</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007761</td>\n",
       "      <td>-0.004909</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>-0.618438</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>0.825150</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138463</th>\n",
       "      <td>-0.155534</td>\n",
       "      <td>-0.021988</td>\n",
       "      <td>-0.094822</td>\n",
       "      <td>-0.017624</td>\n",
       "      <td>-0.059104</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>-0.113521</td>\n",
       "      <td>-0.143999</td>\n",
       "      <td>-0.890373</td>\n",
       "      <td>-0.016494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453815</td>\n",
       "      <td>-0.18843</td>\n",
       "      <td>-0.009419</td>\n",
       "      <td>-0.174880</td>\n",
       "      <td>-0.313124</td>\n",
       "      <td>-0.030535</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>9.462460</td>\n",
       "      <td>-1.392705</td>\n",
       "      <td>-0.056997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52372</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>1.616978</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-1.211901</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146819</th>\n",
       "      <td>-0.155534</td>\n",
       "      <td>-0.021523</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>-0.017624</td>\n",
       "      <td>-0.059104</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>-0.113521</td>\n",
       "      <td>-0.143999</td>\n",
       "      <td>1.123125</td>\n",
       "      <td>-0.016494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453815</td>\n",
       "      <td>-0.18843</td>\n",
       "      <td>-0.009419</td>\n",
       "      <td>-0.174880</td>\n",
       "      <td>-0.313124</td>\n",
       "      <td>-0.030535</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>-0.105681</td>\n",
       "      <td>0.718027</td>\n",
       "      <td>-0.056997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103961 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  src_bytes  dst_bytes      land  wrong_fragment    urgent  \\\n",
       "83887  -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "105197 -0.110249  -0.007569  -0.004837 -0.014089       -0.089486 -0.007736   \n",
       "131702  0.043450   0.577911  -0.096896 -0.017624       -0.059104 -0.019459   \n",
       "140096  0.043450   0.577911  -0.096896 -0.017624       -0.059104 -0.019459   \n",
       "134296 -0.155534  -0.021480  -0.067959 -0.017624       -0.059104 -0.019459   \n",
       "...          ...        ...        ...       ...             ...       ...   \n",
       "59753  -0.109481  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "3516   -0.110249  -0.007761  -0.004909 -0.014089       -0.089486 -0.007736   \n",
       "138463 -0.155534  -0.021988  -0.094822 -0.017624       -0.059104 -0.019459   \n",
       "52372  -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "146819 -0.155534  -0.021523   0.003015 -0.017624       -0.059104 -0.019459   \n",
       "\n",
       "             hot  num_failed_logins  logged_in  num_compromised  ...  \\\n",
       "83887  -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "105197 -0.095076          -0.027023   1.235694        -0.011664  ...   \n",
       "131702 -0.113521          -0.143999  -0.890373        -0.016494  ...   \n",
       "140096 -0.113521          -0.143999  -0.890373        -0.016494  ...   \n",
       "134296 -0.113521          -0.143999  -0.890373        -0.016494  ...   \n",
       "...          ...                ...        ...              ...  ...   \n",
       "59753  -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "3516   -0.095076          -0.027023   1.235694        -0.011664  ...   \n",
       "138463 -0.113521          -0.143999  -0.890373        -0.016494  ...   \n",
       "52372  -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "146819 -0.113521          -0.143999   1.123125        -0.016494  ...   \n",
       "\n",
       "        flag_REJ  flag_RSTO  flag_RSTOS0  flag_RSTR   flag_S0   flag_S1  \\\n",
       "83887  -0.312889   -0.11205    -0.028606  -0.139982  1.616978 -0.053906   \n",
       "105197 -0.312889   -0.11205    -0.028606  -0.139982 -0.618438 -0.053906   \n",
       "131702 -0.453815   -0.18843    -0.009419  -0.174880 -0.313124 -0.030535   \n",
       "140096 -0.453815   -0.18843    -0.009419  -0.174880 -0.313124 -0.030535   \n",
       "134296 -0.453815   -0.18843    -0.009419  -0.174880 -0.313124 -0.030535   \n",
       "...          ...        ...          ...        ...       ...       ...   \n",
       "59753  -0.312889   -0.11205    -0.028606   7.143771 -0.618438 -0.053906   \n",
       "3516   -0.312889   -0.11205    -0.028606  -0.139982 -0.618438 -0.053906   \n",
       "138463 -0.453815   -0.18843    -0.009419  -0.174880 -0.313124 -0.030535   \n",
       "52372  -0.312889   -0.11205    -0.028606  -0.139982  1.616978 -0.053906   \n",
       "146819 -0.453815   -0.18843    -0.009419  -0.174880 -0.313124 -0.030535   \n",
       "\n",
       "         flag_S2   flag_S3   flag_SF   flag_SH  \n",
       "83887  -0.031767 -0.019726 -1.211901 -0.046432  \n",
       "105197 -0.031767 -0.019726  0.825150 -0.046432  \n",
       "131702 -0.025803 -0.105681  0.718027 -0.056997  \n",
       "140096 -0.025803 -0.105681  0.718027 -0.056997  \n",
       "134296 -0.025803 -0.105681  0.718027 -0.056997  \n",
       "...          ...       ...       ...       ...  \n",
       "59753  -0.031767 -0.019726 -1.211901 -0.046432  \n",
       "3516   -0.031767 -0.019726  0.825150 -0.046432  \n",
       "138463 -0.025803  9.462460 -1.392705 -0.056997  \n",
       "52372  -0.031767 -0.019726 -1.211901 -0.046432  \n",
       "146819 -0.025803 -0.105681  0.718027 -0.056997  \n",
       "\n",
       "[103961 rows x 122 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83887     1\n",
       "105197    0\n",
       "131702    3\n",
       "140096    3\n",
       "134296    3\n",
       "         ..\n",
       "59753     2\n",
       "3516      0\n",
       "138463    1\n",
       "52372     1\n",
       "146819    0\n",
       "Name: Label, Length: 103961, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEVEL 0 - Weak models - Base Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Defining RF Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Defining ADA Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Defining LGBM Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Defining KNN Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Defining SVM Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Defining MLP Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Defining DNN Model\n",
      "---------------------------------------------------------------------------------\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 3)                 369       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 20        \n",
      "=================================================================\n",
      "Total params: 437\n",
      "Trainable params: 437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open(output_file_name, \"a\") as f: print('------------START of WEAK LEARNERS (BASE MODELS) - STACK 00 -----------------', file = f)\n",
    "\n",
    "#Defining Basemodels\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining RF Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "rf = RandomForestClassifier(max_depth = 5,  n_estimators = 10, min_samples_split = 2, n_jobs = -1)\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining ADA Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "#ADA\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import time\n",
    "abc = AdaBoostClassifier(n_estimators=50, learning_rate=1.0)\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining LGBM Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "#LGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "\n",
    "\n",
    "\n",
    "#KNN\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining KNN Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf=KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "\n",
    "#SVM\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining SVM Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Instantiate the SGDClassifier with additional hyperparameters\n",
    "clf = SGDClassifier(\n",
    "    loss='hinge',           # hinge loss for linear SVM\n",
    "    penalty='l2',           # L2 regularization to prevent overfitting\n",
    "    alpha=1e-4,             # Learning rate (small value for fine-grained updates)\n",
    "    max_iter=1000,          # Number of passes over the training data\n",
    "    random_state=42,        # Seed for reproducible results\n",
    "    learning_rate='optimal' # Automatically adjusts the learning rate based on the training data\n",
    ")\n",
    "\n",
    "\n",
    "#MLP\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining MLP Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import time\n",
    "\n",
    "# create MLPClassifier instance\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=200, random_state=1)\n",
    "\n",
    "\n",
    "#DNN\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining DNN Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# #Model Parameters\n",
    "# dropout_rate = 0.01\n",
    "# nodes = 70\n",
    "# out_layer = 5\n",
    "# optimizer='adam'\n",
    "# loss='sparse_categorical_crossentropy'\n",
    "# epochs=1\n",
    "# batch_size=2*256\n",
    "\n",
    "#Model Parameters\n",
    "dropout_rate = 0.2\n",
    "nodes = 3\n",
    "out_layer = 5\n",
    "optimizer='adam'\n",
    "loss='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=128\n",
    "\n",
    "\n",
    "num_columns = X_train.shape[1]\n",
    "\n",
    "dnn = tf.keras.Sequential()\n",
    "\n",
    "# Input layer\n",
    "dnn.add(tf.keras.Input(shape=(num_columns,)))\n",
    "\n",
    "# Dense layers with dropout\n",
    "dnn.add(tf.keras.layers.Dense(nodes))\n",
    "dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "dnn.add(tf.keras.layers.Dense(nodes))\n",
    "dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "dnn.add(tf.keras.layers.Dense(nodes))\n",
    "dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "dnn.add(tf.keras.layers.Dense(nodes))\n",
    "dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "dnn.add(tf.keras.layers.Dense(nodes))\n",
    "dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "# Output layer\n",
    "dnn.add(tf.keras.layers.Dense(out_layer, activation='softmax'))\n",
    "\n",
    "dnn.compile(optimizer=optimizer, loss=loss,metrics=['accuracy'])\n",
    "\n",
    "dnn.summary()\n",
    "\n",
    "\n",
    "\n",
    "# dnn = Sequential()\n",
    "# dnn.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))  # Input layer\n",
    "# dnn.add(Dense(64, activation='relu'))  # Hidden layer\n",
    "# dnn.add(Dense(5))  # Output layer\n",
    "\n",
    "# dnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# # summary of model layers\n",
    "# dnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SVM\n",
    "# # Wrap SGDClassifier with MultiOutputClassifier\n",
    "# multi_target_clf = MultiOutputClassifier(clf)\n",
    "\n",
    "# # Fit the model on the training data\n",
    "# multi_target_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Training Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Training ADA\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.59779734 0.83060793 0.66116776 0.58839938 0.8088207 ]\n",
      "Mean accuracy: 0.6973586206489453\n",
      "---------------------------------------------------------------------------------\n",
      "Training RF\n",
      "---------------------------------------------------------------------------------\n",
      "Cross-validation scores: [0.93911412 0.93035783 0.9547903  0.92992497 0.9348788 ]\n",
      "Mean accuracy: 0.9378132059049159\n",
      "---------------------------------------------------------------------------------\n",
      "Training SVM\n",
      "---------------------------------------------------------------------------------\n",
      "Cross-validation scores: [0.97114414 0.9674875  0.96801654 0.97042132 0.96878607]\n",
      "Mean accuracy: 0.9691711125035105\n",
      "---------------------------------------------------------------------------------\n",
      "Training KNN\n",
      "---------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Training Basemodels\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "n_splits = 5  # You can adjust the number of folds as needed\n",
    "\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Training Model')\n",
    "with open(output_file_name, \"a\") as f: print('Training weak models - level 0', file = f)\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_ada == 1 and load_model_ada == 0:\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training ADA')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training ADA', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #ADA\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    ada = abc.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(ada, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "    ada_tr_time_taken= time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "\n",
    "    # Assuming 'model' is your trained model\n",
    "    joblib.dump(ada, 'ada_base_model.joblib')\n",
    "\n",
    "\n",
    "if use_model_rf == 1 and load_model_rf == 0:\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training RF')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Training RF', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #RF\n",
    "    start = time.time()\n",
    "    model_rf = rf.fit(X_train,y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model_rf, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "\n",
    "    rf_tr_time_taken = time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    joblib.dump(model_rf, 'rf_base_model.joblib')\n",
    "\n",
    "if use_model_svm == 1 and load_model_svm == 0:\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training SVM')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training SVM', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #SVM\n",
    "\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    # clf.score(X_train, y_train)\n",
    "    svm_tr_time_taken= time_taken = end - start\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(clf, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    joblib.dump(clf, 'svm_base_model.joblib')\n",
    "\n",
    "\n",
    "if use_model_knn == 1 and load_model_knn == 0:\n",
    "\n",
    "    #KNN\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training KNN')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training KNN', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    start = time.time()\n",
    "    knn_clf.fit(X_train,y_train)\n",
    "    end = time.time()\n",
    "\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(knn_clf, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "\n",
    "    knn_tr_time_taken = time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    joblib.dump(knn_clf, 'knn_base_model.joblib')\n",
    "\n",
    "\n",
    "if use_model_lgbm == 1 and load_model_lgbm == 0:\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training LGBM')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training LGBM', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    start = time.time()\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(lgbm, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "    lgbm_tr_time_taken = time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    joblib.dump(lgbm, 'lgbm_base_model.joblib')\n",
    "\n",
    "if use_model_mlp == 1 and load_model_mlp == 0:\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training MLP')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training MLP', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "    start = time.time()\n",
    "    MLP = mlp.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(MLP, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "    mlp_tr_time_taken= time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    joblib.dump(MLP, 'mlp_base_model.joblib')\n",
    "\n",
    "\n",
    "if use_model_dnn == 1 and load_model_dnn == 0:\n",
    "    from keras.callbacks import EarlyStopping\n",
    "\n",
    "    # Define EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training DNN')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training DNN', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    # Convert Y_test back to its original format\n",
    "    # y_test = np.argmax(Y_test, axis=1)\n",
    "\n",
    "    # Start the timer\n",
    "    start = time.time()\n",
    "    # dnn.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    dnn.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "    # End the timer\n",
    "    end = time.time()\n",
    "\n",
    "    # # Create the StratifiedKFold object\n",
    "    # stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # # Perform cross-validation\n",
    "    # cv_scores = cross_val_score(dnn, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # # Print the cross-validation scores\n",
    "    # print(\"Cross-validation scores:\", cv_scores)\n",
    "    # print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    # with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "\n",
    "    dnn_tr_time_taken= time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    dnn.save(\"DNN_base_model.h5\")\n",
    "\n",
    "    # Calculate the time taken and print it out\n",
    "    # print(f'Time taken for training: {time_taken} seconds')\n",
    "\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # Define your Keras model as a function\n",
    "# def create_model(optimizer='adam', hidden_layer_size=16):\n",
    "#     # model = Sequential()\n",
    "#     # model.add(Dense(hidden_layer_size, input_dim=input_size, activation='relu'))\n",
    "#     # model.add(Dense(1, activation='sigmoid'))\n",
    "#     # model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        \n",
    "#     dnn = tf.keras.Sequential()\n",
    "\n",
    "#     # Input layer\n",
    "#     dnn.add(tf.keras.Input(shape=(num_columns,)))\n",
    "\n",
    "#     # Dense layers with dropout\n",
    "#     dnn.add(tf.keras.layers.Dense(nodes))\n",
    "#     dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "#     dnn.add(tf.keras.layers.Dense(nodes))\n",
    "#     dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "#     dnn.add(tf.keras.layers.Dense(nodes))\n",
    "#     dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "#     dnn.add(tf.keras.layers.Dense(nodes))\n",
    "#     dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "#     dnn.add(tf.keras.layers.Dense(nodes))\n",
    "#     dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "#     # Output layer\n",
    "#     dnn.add(tf.keras.layers.Dense(out_layer))\n",
    "\n",
    "\n",
    "\n",
    "#     dnn.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "#     dnn.summary()\n",
    "#     return dnn\n",
    "\n",
    "# # Create a KerasClassifier\n",
    "# dnn = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# # Define the parameter grid for GridSearchCV\n",
    "# param_grid = {\n",
    "#     'optimizer': ['adam', 'sgd'],\n",
    "#     'hidden_layer_size': [8, 16, 32]\n",
    "# }\n",
    "\n",
    "# # Create the StratifiedKFold\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# # Create GridSearchCV\n",
    "# grid = GridSearchCV(estimator=dnn, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters and best accuracy\n",
    "# print(\"Best Parameters: \", grid_result.best_params_)\n",
    "# print(\"Best Accuracy: \", grid_result.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Models\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "if load_model_ada == 1:\n",
    "    ada = joblib.load('ada_base_model.joblib')\n",
    "\n",
    "if load_model_svm == 1:\n",
    "    clf =  joblib.load('svm_base_model.joblib')\n",
    "\n",
    "if load_model_dnn == 1:\n",
    "    dnn = load_model(\"DNN_base_model.h5\")\n",
    "\n",
    "if load_model_knn == 1:\n",
    "    knn_clf = joblib.load('knn_base_model.joblib')\n",
    "\n",
    "if load_model_mlp == 1:\n",
    "    MLP = joblib.load('mlp_base_model.joblib')\n",
    "\n",
    "if load_model_rf == 1:\n",
    "    rf = joblib.load('rf_base_model.joblib')\n",
    "\n",
    "if load_model_lgbm == 1:\n",
    "    lgbm = joblib.load('lgbm_base_model.joblib')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "# preds_svm = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# y_scores = y_pred\n",
    "# y_true = y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base leaners predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Prediction RF\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Prediction SVM\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Prediction LGBM\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Prediction DNN\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Prediction ADA\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Prediction MLP\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Prediction KNN\n",
      "---------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "with open(output_file_name, \"a\") as f: print('Generating Predictions', file = f)\n",
    "\n",
    "if use_model_rf == 1:\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Prediction RF')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction RF', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #RF\n",
    "    start = time.time()\n",
    "    preds_rf = rf.predict(X_test)\n",
    "    preds_rf_prob = rf.predict_proba(X_test)\n",
    "    end = time.time()\n",
    "    rf_pr_time_taken=  time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_svm == 1:\n",
    "\n",
    "    print('Prediction SVM')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction SVM', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #SVM\n",
    "    start = time.time()\n",
    "    preds_svm = clf.predict(X_test)\n",
    "    # preds_svm_prob = clf.predict_proba(X_test)\n",
    "\n",
    "    #Since SVM does not deal with prob by nature we use a meta learner\n",
    "    # https://stackoverflow.com/questions/55250963/how-to-get-probabilities-for-sgdclassifier-linearsvm\n",
    "\n",
    "    model = CalibratedClassifierCV(clf)\n",
    "\n",
    "    model.fit(X, y)\n",
    "    preds_svm_prob = model.predict_proba(X)\n",
    "\n",
    "    end = time.time()\n",
    "    svm_pr_time_taken = time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_lgbm == 1:\n",
    "\n",
    "    print('Prediction LGBM')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction LGBM', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #LGBM\n",
    "    start = time.time()\n",
    "    preds_lgbm = lgbm.predict(X_test)\n",
    "    preds_lgbm_prob = lgbm.predict_proba(X_test)\n",
    "\n",
    "    end = time.time()\n",
    "    lgbm_pr_time_taken=time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_dnn == 1:\n",
    "\n",
    "    print('Prediction DNN')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction DNN', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #DNN\n",
    "    start = time.time()\n",
    "    pred_dnn = dnn.predict(X_test)\n",
    "    preds_dnn_prob = pred_dnn\n",
    "    preds_dnn = np.argmax(pred_dnn,axis = 1)\n",
    "    end = time.time()\n",
    "    dnn_pr_time_taken=time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_ada == 1:\n",
    "\n",
    "    print('Prediction ADA')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction ADA', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #ADA\n",
    "    start = time.time()\n",
    "    preds_ada = ada.predict(X_test)\n",
    "    preds_ada_prob = ada.predict_proba(X_test)\n",
    "\n",
    "    end = time.time()\n",
    "    ada_pr_time_taken=time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Prediction MLP')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction MLP', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_mlp == 1:\n",
    "\n",
    "    #MLP\n",
    "    start = time.time()\n",
    "    y_pred = MLP.predict_proba(X_test)\n",
    "    preds_mlp_prob = y_pred\n",
    "    preds_mlp = np.argmax(y_pred,axis = 1)\n",
    "    end = time.time()\n",
    "    mlp_pr_time_taken=time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Prediction KNN')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction KNN', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_knn == 1:\n",
    "\n",
    "    #KNN\n",
    "    start = time.time()\n",
    "    preds_knn =knn_clf.predict(X_test)\n",
    "    preds_knn_prob =knn_clf.predict_proba(X_test)\n",
    "\n",
    "    preds_knn\n",
    "    end = time.time()\n",
    "    knn_pr_time_taken=time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "# model = CalibratedClassifierCV(clf)\n",
    "\n",
    "# model.fit(X, y)\n",
    "# preds_svm_prob = model.predict_proba(X)\n",
    "\n",
    "# print(preds_ada_prob)\n",
    "# print(preds_knn_prob)\n",
    "# print(preds_dnn_prob)\n",
    "# print(preds_mlp_prob)\n",
    "# print(preds_rf_prob)\n",
    "# print(preds_svm_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.86755451e-01 9.15808640e-02 7.78774782e-02 4.31012582e-02\n",
      "  6.84948135e-04]\n",
      " [2.62305098e-01 2.71329463e-02 6.45857927e-01 6.23936481e-02\n",
      "  2.31038051e-03]\n",
      " [1.69951428e-02 9.10446456e-01 5.10282199e-02 2.14799179e-02\n",
      "  5.02632551e-05]\n",
      " ...\n",
      " [9.42972082e-01 3.31526500e-02 1.34223706e-03 2.24056309e-02\n",
      "  1.27400343e-04]\n",
      " [9.12741440e-01 3.97164126e-02 1.80198033e-02 2.95111286e-02\n",
      "  1.12159303e-05]\n",
      " [5.57736620e-01 3.72736907e-01 5.55977328e-02 1.35376604e-02\n",
      "  3.91079556e-04]]\n",
      "[0 2 1 ... 0 0 0]\n",
      "[1 0 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(preds_svm_prob)\n",
    "preds_3 = np.argmax(preds_svm_prob,axis = 1)\n",
    "print(preds_3)\n",
    "\n",
    "print(preds_svm)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METRICS - Base Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# >>> \n",
    "# >>> roc_auc_score(y, clf.predict_proba(X)[:, 1])\n",
    "# 0.99...\n",
    "# >>> roc_auc_score(y, clf.decision_function(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test\n",
    "# pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2    3    4\n",
      "0  22616.0    169.0   220.0  2.0  0.0\n",
      "1    964.0  15042.0    95.0  0.0  0.0\n",
      "2    350.0    292.0  3635.0  0.0  0.0\n",
      "3   1009.0      1.0   122.0  6.0  0.0\n",
      "4     32.0      0.0     1.0  0.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9269009785438549\n",
      "Precision total:  0.7036708795596386\n",
      "Recall total:  0.5544800107715953\n",
      "F1 total:  0.5551540048700508\n",
      "BACC total:  0.5544800107715953\n",
      "MCC total:  0.875668923834827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "if use_model_rf == 1:\n",
    "    # start = time.time()\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('RF base model', file = f)\n",
    "\n",
    "    pred_label = preds_rf\n",
    "    name = 'rf'\n",
    "    metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "    Acc = metrics[0]\n",
    "    Precision = metrics[1]\n",
    "    Recall = metrics[2]\n",
    "    F1 = metrics[3]\n",
    "    BACC = metrics[4]\n",
    "    MCC = metrics[5]    \n",
    "\n",
    "    globals()[f\"{name}_acc_00\"] = Acc\n",
    "    globals()[f\"{name}_pre_00\"] = Precision\n",
    "    globals()[f\"{name}_rec_00\"] = Recall\n",
    "    globals()[f\"{name}_f1_00\"] = F1\n",
    "    globals()[f\"{name}_bacc_00\"] = BACC\n",
    "    globals()[f\"{name}_mcc_00\"] = MCC\n",
    "    globals()[f\"{name}_time_00\"] = rf_pr_time_taken + rf_tr_time_taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1    2    3    4\n",
      "0  22693.0    314.0  0.0  0.0  0.0\n",
      "1   1382.0  14719.0  0.0  0.0  0.0\n",
      "2   2101.0   2176.0  0.0  0.0  0.0\n",
      "3   1128.0     10.0  0.0  0.0  0.0\n",
      "4     29.0      4.0  0.0  0.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.8396624472573839\n",
      "Precision total:  0.3369709699388192\n",
      "Recall total:  0.38010376035375015\n",
      "F1 total:  0.35699530838837495\n",
      "BACC total:  0.38010376035375015\n",
      "MCC total:  0.7226654496793403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "#DNN\n",
    "if use_model_dnn == 1:\n",
    "    start = time.time()\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('DNN base model', file = f)\n",
    "\n",
    "\n",
    "    pred_label = preds_dnn\n",
    "    name = 'dnn'\n",
    "    metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "    Acc = metrics[0]\n",
    "    Precision = metrics[1]\n",
    "    Recall = metrics[2]\n",
    "    F1 = metrics[3]\n",
    "    BACC = metrics[4]\n",
    "    MCC = metrics[5]    \n",
    "\n",
    "    globals()[f\"{name}_acc_00\"] = Acc\n",
    "    globals()[f\"{name}_pre_00\"] = Precision\n",
    "    globals()[f\"{name}_rec_00\"] = Recall\n",
    "    globals()[f\"{name}_f1_00\"] = F1\n",
    "    globals()[f\"{name}_bacc_00\"] = BACC\n",
    "    globals()[f\"{name}_mcc_00\"] = MCC\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    globals()[f\"{name}_time_00\"] = dnn_pr_time_taken + dnn_tr_time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3    4\n",
      "0  18156.0   2883.0  1462.0  505.0  1.0\n",
      "1    251.0  12405.0  3356.0   89.0  0.0\n",
      "2    426.0   1050.0  2743.0   58.0  0.0\n",
      "3    555.0     57.0    72.0  446.0  8.0\n",
      "4     12.0      0.0     1.0   20.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total:  0.7574737409103152\n",
      "Precision total:  0.4901499320639549\n",
      "Recall total:  0.5185706391688746\n",
      "F1 total:  0.4951450071968294\n",
      "BACC total:  0.5185706391688746\n",
      "MCC total:  0.6186463514073031\n"
     ]
    }
   ],
   "source": [
    "#ADA\n",
    "if use_model_ada == 1:\n",
    "    start = time.time()\n",
    "    \n",
    "    pred_label = preds_ada\n",
    "    name = 'ada'\n",
    "    metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "    Acc = metrics[0]\n",
    "    Precision = metrics[1]\n",
    "    Recall = metrics[2]\n",
    "    F1 = metrics[3]\n",
    "    BACC = metrics[4]\n",
    "    MCC = metrics[5]    \n",
    "\n",
    "    globals()[f\"{name}_acc_00\"] = Acc\n",
    "    globals()[f\"{name}_pre_00\"] = Precision\n",
    "    globals()[f\"{name}_rec_00\"] = Recall\n",
    "    globals()[f\"{name}_f1_00\"] = F1\n",
    "    globals()[f\"{name}_bacc_00\"] = BACC\n",
    "    globals()[f\"{name}_mcc_00\"] = MCC\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    globals()[f\"{name}_time_00\"] = ada_pr_time_taken + ada_tr_time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2    3    4\n",
      "0  21396.0    492.0  1114.0  5.0  0.0\n",
      "1   1283.0  14671.0   147.0  0.0  0.0\n",
      "2    521.0   1198.0  2558.0  0.0  0.0\n",
      "3    970.0     36.0   131.0  1.0  0.0\n",
      "4     27.0      3.0     3.0  0.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total:  0.866909058263758\n",
      "Precision total:  0.518517030256721\n",
      "Recall total:  0.4880249952789204\n",
      "F1 total:  0.48654255532153956\n",
      "BACC total:  0.4880249952789204\n",
      "MCC total:  0.7710117391455595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "if use_model_svm == 1:\n",
    "    start = time.time()\n",
    "\n",
    "    pred_label = preds_svm\n",
    "    name = 'svm'\n",
    "    metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "    Acc = metrics[0]\n",
    "    Precision = metrics[1]\n",
    "    Recall = metrics[2]\n",
    "    F1 = metrics[3]\n",
    "    BACC = metrics[4]\n",
    "    MCC = metrics[5]    \n",
    "\n",
    "    globals()[f\"{name}_acc_00\"] = Acc\n",
    "    globals()[f\"{name}_pre_00\"] = Precision\n",
    "    globals()[f\"{name}_rec_00\"] = Recall\n",
    "    globals()[f\"{name}_f1_00\"] = F1\n",
    "    globals()[f\"{name}_bacc_00\"] = BACC\n",
    "    globals()[f\"{name}_mcc_00\"] = MCC\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    globals()[f\"{name}_time_00\"] = svm_pr_time_taken + svm_tr_time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3    4\n",
      "0  22464.0    186.0   163.0  194.0  0.0\n",
      "1    114.0  15957.0    17.0   12.0  1.0\n",
      "2    144.0     22.0  4092.0   19.0  0.0\n",
      "3    133.0      4.0    10.0  991.0  0.0\n",
      "4     24.0      2.0     0.0    6.0  1.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total:  0.9764117066163929\n",
      "Precision total:  0.8470442740595739\n",
      "Recall total:  0.7650658733325508\n",
      "F1 total:  0.7642377601210751\n",
      "BACC total:  0.7650658733325508\n",
      "MCC total:  0.9602870072104996\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "if use_model_knn == 1:\n",
    "    start = time.time()\n",
    "    pred_label = preds_knn\n",
    "    name = 'knn'\n",
    "    metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "    Acc = metrics[0]\n",
    "    Precision = metrics[1]\n",
    "    Recall = metrics[2]\n",
    "    F1 = metrics[3]\n",
    "    BACC = metrics[4]\n",
    "    MCC = metrics[5]    \n",
    "\n",
    "    globals()[f\"{name}_acc_00\"] = Acc\n",
    "    globals()[f\"{name}_pre_00\"] = Precision\n",
    "    globals()[f\"{name}_rec_00\"] = Recall\n",
    "    globals()[f\"{name}_f1_00\"] = F1\n",
    "    globals()[f\"{name}_bacc_00\"] = BACC\n",
    "    globals()[f\"{name}_mcc_00\"] = MCC\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    globals()[f\"{name}_time_00\"] = knn_pr_time_taken + knn_tr_time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3    4\n",
      "0  22293.0    159.0   298.0  257.0  0.0\n",
      "1    252.0  15788.0    42.0   19.0  0.0\n",
      "2    148.0     46.0  4056.0   27.0  0.0\n",
      "3    176.0     16.0    14.0  932.0  0.0\n",
      "4     25.0      2.0     0.0    6.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total:  0.9666262680671515\n",
      "Precision total:  0.7261111598469259\n",
      "Recall total:  0.7433670231692975\n",
      "F1 total:  0.734398287148619\n",
      "BACC total:  0.7433670231692975\n",
      "MCC total:  0.9438970625968045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "if use_model_mlp == 1:\n",
    "    start = time.time()\n",
    "    pred_label = preds_mlp\n",
    "    name = 'mlp'\n",
    "    metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "    Acc = metrics[0]\n",
    "    Precision = metrics[1]\n",
    "    Recall = metrics[2]\n",
    "    F1 = metrics[3]\n",
    "    BACC = metrics[4]\n",
    "    MCC = metrics[5]    \n",
    "\n",
    "    globals()[f\"{name}_acc_00\"] = Acc\n",
    "    globals()[f\"{name}_pre_00\"] = Precision\n",
    "    globals()[f\"{name}_rec_00\"] = Recall\n",
    "    globals()[f\"{name}_f1_00\"] = F1\n",
    "    globals()[f\"{name}_bacc_00\"] = BACC\n",
    "    globals()[f\"{name}_mcc_00\"] = MCC\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    globals()[f\"{name}_time_00\"] = mlp_pr_time_taken + mlp_tr_time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3     4\n",
      "0  22512.0    136.0   144.0  170.0  45.0\n",
      "1    191.0  15841.0    36.0   21.0  12.0\n",
      "2    113.0     21.0  4119.0   15.0   9.0\n",
      "3    119.0      0.0    17.0  989.0  13.0\n",
      "4     20.0      0.0     0.0    9.0   4.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy total:  0.9755139599604992\n",
      "Precision total:  0.7589729746251801\n",
      "Recall total:  0.7831351249047284\n",
      "F1 total:  0.7677661766112274\n",
      "BACC total:  0.7831351249047284\n",
      "MCC total:  0.9588050806562161\n"
     ]
    }
   ],
   "source": [
    "#lgbm\n",
    "start_lgbm = time.time()\n",
    "if use_model_lgbm == 1:\n",
    "\n",
    "    pred_label = preds_lgbm\n",
    "    name = 'lgbm'\n",
    "    metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "    Acc = metrics[0]\n",
    "    Precision = metrics[1]\n",
    "    Recall = metrics[2]\n",
    "    F1 = metrics[3]\n",
    "    BACC = metrics[4]\n",
    "    MCC = metrics[5]    \n",
    "\n",
    "    globals()[f\"{name}_acc_00\"] = Acc\n",
    "    globals()[f\"{name}_pre_00\"] = Precision\n",
    "    globals()[f\"{name}_rec_00\"] = Recall\n",
    "    globals()[f\"{name}_f1_00\"] = F1\n",
    "    globals()[f\"{name}_bacc_00\"] = BACC\n",
    "    globals()[f\"{name}_mcc_00\"] = MCC\n",
    "    end = time.time()\n",
    "    time_taken = end - start_lgbm\n",
    "    globals()[f\"{name}_time_00\"] = lgbm_pr_time_taken + lgbm_tr_time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "start = time.time()\n",
    "\n",
    "# Create a Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "# Train the classifier on the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "# Make predictions on the test data\n",
    "preds_dt = dt_classifier.predict(X_test)\n",
    "# Evaluate the accuracy of the model\n",
    "preds_dt_prob = dt_classifier.predict_proba(X_test)\n",
    "\n",
    "\n",
    "pred_label = preds_dt\n",
    "name = 'dt'\n",
    "metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "Acc = metrics[0]\n",
    "Precision = metrics[1]\n",
    "Recall = metrics[2]\n",
    "F1 = metrics[3]\n",
    "BACC = metrics[4]\n",
    "MCC = metrics[5]    \n",
    "\n",
    "globals()[f\"{name}_acc_00\"] = Acc\n",
    "globals()[f\"{name}_pre_00\"] = Precision\n",
    "globals()[f\"{name}_rec_00\"] = Recall\n",
    "globals()[f\"{name}_f1_00\"] = F1\n",
    "globals()[f\"{name}_bacc_00\"] = BACC\n",
    "globals()[f\"{name}_mcc_00\"] = MCC\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "globals()[f\"{name}_time_00\"] = time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3044871\ttest: 1.3039134\tbest: 1.3039134 (0)\ttotal: 78.1ms\tremaining: 7.73s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:\tlearn: 0.4630357\ttest: 0.4618663\tbest: 0.4618663 (10)\ttotal: 326ms\tremaining: 2.64s\n",
      "20:\tlearn: 0.2676941\ttest: 0.2670392\tbest: 0.2670392 (20)\ttotal: 558ms\tremaining: 2.1s\n",
      "30:\tlearn: 0.1908402\ttest: 0.1910453\tbest: 0.1910453 (30)\ttotal: 814ms\tremaining: 1.81s\n",
      "40:\tlearn: 0.1529783\ttest: 0.1538367\tbest: 0.1538367 (40)\ttotal: 1.05s\tremaining: 1.52s\n",
      "50:\tlearn: 0.1353746\ttest: 0.1365274\tbest: 0.1365274 (50)\ttotal: 1.27s\tremaining: 1.22s\n",
      "60:\tlearn: 0.1221059\ttest: 0.1237006\tbest: 0.1237006 (60)\ttotal: 1.49s\tremaining: 949ms\n",
      "70:\tlearn: 0.1126627\ttest: 0.1146082\tbest: 0.1146082 (70)\ttotal: 1.68s\tremaining: 688ms\n",
      "80:\tlearn: 0.1054775\ttest: 0.1077428\tbest: 0.1077428 (80)\ttotal: 1.92s\tremaining: 449ms\n",
      "90:\tlearn: 0.0997292\ttest: 0.1022796\tbest: 0.1022796 (90)\ttotal: 2.14s\tremaining: 212ms\n",
      "99:\tlearn: 0.0950370\ttest: 0.0978098\tbest: 0.0978098 (99)\ttotal: 2.35s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.09780975775\n",
      "bestIteration = 99\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3    4\n",
      "0  22429.0    186.0   192.0  200.0  0.0\n",
      "1    189.0  15821.0    81.0   10.0  0.0\n",
      "2    209.0     32.0  4024.0   12.0  0.0\n",
      "3    225.0      5.0    25.0  883.0  0.0\n",
      "4     15.0      0.0     1.0   17.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9686013107101176\n",
      "Precision total:  0.735252950737121\n",
      "Recall total:  0.734851209216399\n",
      "F1 total:  0.7350379423206291\n",
      "BACC total:  0.734851209216399\n",
      "MCC total:  0.9470193235023843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "import catboost\n",
    "start = time.time()\n",
    "cat_00 = catboost.CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='MultiClass', custom_metric='Accuracy')\n",
    "\n",
    "# Fit the model\n",
    "cat_00.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=10)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds_cat = cat_00.predict(X_test)\n",
    "preds_cat_prob = cat_00.predict_proba(X_test)\n",
    "preds_cat = np.squeeze(preds_cat)\n",
    "\n",
    "\n",
    "if 1 == 1:\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Catboost base model', file = f)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    pred_label = preds_cat\n",
    "    \n",
    "    \n",
    "\n",
    "    # pred_label = y_pred\n",
    "\n",
    "    name = 'cat'\n",
    "    metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "    Acc = metrics[0]\n",
    "    Precision = metrics[1]\n",
    "    Recall = metrics[2]\n",
    "    F1 = metrics[3]\n",
    "    BACC = metrics[4]\n",
    "    MCC = metrics[5]    \n",
    "\n",
    "    globals()[f\"{name}_acc_00\"] = Acc\n",
    "    globals()[f\"{name}_pre_00\"] = Precision\n",
    "    globals()[f\"{name}_rec_00\"] = Recall\n",
    "    globals()[f\"{name}_f1_00\"] = F1\n",
    "    globals()[f\"{name}_bacc_00\"] = BACC\n",
    "    globals()[f\"{name}_mcc_00\"] = MCC\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    globals()[f\"{name}_time_00\"] = time_taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "start = time.time()\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have your features and labels as X and y\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # for multi-class classification\n",
    "    'num_class': 5,  # specify the number of classes\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'eval_metric': 'mlogloss'  # metric for multi-class classification\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "num_round = 100\n",
    "xgb_00 = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds_xgb = xgb_00.predict(dtest)\n",
    "# preds_xgb_prob = xgb_00.predict_proba(dtest)\n",
    "\n",
    "\n",
    "# Get class probabilities\n",
    "# Assuming binary classification, get the probability for the positive class (class 1)\n",
    "preds_xgb_margin = xgb_00.predict(dtest, output_margin=True)\n",
    "preds_xgb_prob = 1 / (1 + np.exp(-preds_xgb_margin))\n",
    "\n",
    "# Print or use positive_class_probabilities as needed\n",
    "# print(positive_class_probabilities)\n",
    "\n",
    "\n",
    "# Convert predicted probabilities to class labels (if necessary)\n",
    "# y_pred_labels = [round(value) for value in y_pred]\n",
    "\n",
    "# Evaluate the accuracy\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0.0      1.0     2.0    3.0  4.0\n",
      "0.0  22299.0    235.0   302.0  171.0  0.0\n",
      "1.0    477.0  15502.0   103.0   19.0  0.0\n",
      "2.0    212.0     88.0  3944.0   33.0  0.0\n",
      "3.0    433.0      5.0    25.0  675.0  0.0\n",
      "4.0     14.0      3.0     0.0   16.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.952060328575276\n",
      "Precision total:  0.7141647286115903\n",
      "Recall total:  0.6894623313800716\n",
      "F1 total:  0.700173767262395\n",
      "BACC total:  0.6894623313800716\n",
      "MCC total:  0.9188887582697526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if 1 == 1:\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('xgboost base model', file = f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    pred_label = preds_xgb\n",
    "    # pred_label = label[ypred]\n",
    "    name = 'xgb'\n",
    "    metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "    Acc = metrics[0]\n",
    "    Precision = metrics[1]\n",
    "    Recall = metrics[2]\n",
    "    F1 = metrics[3]\n",
    "    BACC = metrics[4]\n",
    "    MCC = metrics[5]    \n",
    "\n",
    "    globals()[f\"{name}_acc_00\"] = Acc\n",
    "    globals()[f\"{name}_pre_00\"] = Precision\n",
    "    globals()[f\"{name}_rec_00\"] = Recall\n",
    "    globals()[f\"{name}_f1_00\"] = F1\n",
    "    globals()[f\"{name}_bacc_00\"] = BACC\n",
    "    globals()[f\"{name}_mcc_00\"] = MCC\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    globals()[f\"{name}_time_00\"] = time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Defining Logistic Regression Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Training LR \n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2     3    4\n",
      "0  21419.0    546.0   992.0  50.0  0.0\n",
      "1   1274.0  14749.0    78.0   0.0  0.0\n",
      "2    976.0   1216.0  2085.0   0.0  0.0\n",
      "3    971.0     27.0   127.0  13.0  0.0\n",
      "4     24.0      5.0     3.0   1.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.8588293383607146\n",
      "Precision total:  0.51956305186457\n",
      "Recall total:  0.4691844742165842\n",
      "F1 total:  0.47506332958775077\n",
      "BACC total:  0.4691844742165842\n",
      "MCC total:  0.7557912792195774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Logistic Regression\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining Logistic Regression Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "logreg_00 = LogisticRegression()\n",
    "\n",
    "if 1 == 1 and 0 == 0:\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training LR ')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training LR', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    start_lr = start = time.time()\n",
    "    logreg_00.fit(X_train,y_train)\n",
    "    end = time.time()\n",
    "\n",
    "\n",
    "    # # Create the StratifiedKFold object\n",
    "    # stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # # Perform cross-validation\n",
    "    # cv_scores = cross_val_score(knn_clf, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # # Print the cross-validation scores\n",
    "    # print(\"Cross-validation scores:\", cv_scores)\n",
    "    # print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    # with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    # joblib.dump(logreg_01, 'logreg_01.joblib')\n",
    "\n",
    "\n",
    "# if 1 == 1:\n",
    "    # logreg_01 = joblib.load('logreg_01.joblib')\n",
    "\n",
    "if 1 == 1:\n",
    "\n",
    "    #lR\n",
    "    start = time.time()\n",
    "    preds_lr = preds_logreg =logreg_00.predict(X_test)\n",
    "    preds_lr_prob = logreg_00.predict_proba(X_test)\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "#LR\n",
    "if 1 == 1:\n",
    "    pred_label = preds_logreg\n",
    "    name = 'lr'\n",
    "    metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "    Acc = metrics[0]\n",
    "    Precision = metrics[1]\n",
    "    Recall = metrics[2]\n",
    "    F1 = metrics[3]\n",
    "    BACC = metrics[4]\n",
    "    MCC = metrics[5]    \n",
    "\n",
    "    globals()[f\"{name}_acc_00\"] = Acc\n",
    "    globals()[f\"{name}_pre_00\"] = Precision\n",
    "    globals()[f\"{name}_rec_00\"] = Recall\n",
    "    globals()[f\"{name}_f1_00\"] = F1\n",
    "    globals()[f\"{name}_bacc_00\"] = BACC\n",
    "    globals()[f\"{name}_mcc_00\"] = MCC\n",
    "    \n",
    "    end = time.time()\n",
    "    time_taken = end - start_lr\n",
    "    globals()[f\"{name}_time_00\"] = time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging DT  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3    4\n",
      "0  22613.0    133.0   107.0  150.0  4.0\n",
      "1    157.0  15921.0    18.0    5.0  0.0\n",
      "2    122.0     23.0  4118.0   14.0  0.0\n",
      "3    138.0      2.0    11.0  979.0  8.0\n",
      "4     20.0      0.0     0.0    8.0  5.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9793518269144448\n",
      "Precision total:  0.8160496565078939\n",
      "Recall total:  0.7892632207239577\n",
      "F1 total:  0.7980809808386418\n",
      "BACC total:  0.7892632207239577\n",
      "MCC total:  0.9651604098104272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "start = time.time()\n",
    "# # Define the base classifier (Decision Tree in this case)\n",
    "base_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the BaggingClassifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('--------------------------------------------------------------------------', file = f)\n",
    "\n",
    "\n",
    "pred_label = y_pred\n",
    "name = 'bag_dt'\n",
    "metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "Acc = metrics[0]\n",
    "Precision = metrics[1]\n",
    "Recall = metrics[2]\n",
    "F1 = metrics[3]\n",
    "BACC = metrics[4]\n",
    "MCC = metrics[5]    \n",
    "\n",
    "globals()[f\"{name}_acc_00\"] = Acc\n",
    "globals()[f\"{name}_pre_00\"] = Precision\n",
    "globals()[f\"{name}_rec_00\"] = Recall\n",
    "globals()[f\"{name}_f1_00\"] = F1\n",
    "globals()[f\"{name}_bacc_00\"] = BACC\n",
    "globals()[f\"{name}_mcc_00\"] = MCC\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "globals()[f\"{name}_time_00\"] = time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bagging SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2    3    4\n",
      "0  21394.0    549.0  1061.0  3.0  0.0\n",
      "1   1279.0  14689.0   133.0  0.0  0.0\n",
      "2    603.0   1200.0  2474.0  0.0  0.0\n",
      "3    970.0     37.0   129.0  2.0  0.0\n",
      "4     27.0      3.0     3.0  0.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.865405332615136\n",
      "Precision total:  0.5647748952564643\n",
      "Recall total:  0.48447895788066797\n",
      "F1 total:  0.4845682631281675\n",
      "BACC total:  0.48447895788066797\n",
      "MCC total:  0.7681012409166899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "## bagging  with SVM\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Instantiate the SGDClassifier with additional hyperparameters\n",
    "svm_01 = SGDClassifier(\n",
    "    loss='hinge',           # hinge loss for linear SVM\n",
    "    penalty='l2',           # L2 regularization to prevent overfitting\n",
    "    alpha=1e-4,             # Learning rate (small value for fine-grained updates)\n",
    "    max_iter=1000,          # Number of passes over the training data\n",
    "    random_state=42,        # Seed for reproducible results\n",
    "    learning_rate='optimal' # Automatically adjusts the learning rate based on the training data\n",
    ")\n",
    "\n",
    "# # Define the base classifier (Decision Tree in this case)\n",
    "base_classifier = svm_01\n",
    "\n",
    "# Define the BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the BaggingClassifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('--------------------------------------------------------------------------', file = f)\n",
    "\n",
    "name = 'bag_svm'\n",
    "pred_label = y_pred\n",
    "metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "Acc = metrics[0]\n",
    "Precision = metrics[1]\n",
    "Recall = metrics[2]\n",
    "F1 = metrics[3]\n",
    "BACC = metrics[4]\n",
    "MCC = metrics[5]    \n",
    "\n",
    "\n",
    "globals()[f\"{name}_acc_00\"] = Acc\n",
    "globals()[f\"{name}_pre_00\"] = Precision\n",
    "globals()[f\"{name}_rec_00\"] = Recall\n",
    "globals()[f\"{name}_f1_00\"] = F1\n",
    "globals()[f\"{name}_bacc_00\"] = BACC\n",
    "globals()[f\"{name}_mcc_00\"] = MCC\n",
    "\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "globals()[f\"{name}_time_00\"] = time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3    4\n",
      "0  22334.0    176.0   309.0  188.0  0.0\n",
      "1    192.0  15842.0    52.0   15.0  0.0\n",
      "2    123.0     21.0  4111.0   22.0  0.0\n",
      "3    228.0      1.0    21.0  888.0  0.0\n",
      "4     23.0      1.0     0.0    9.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9690052967052698\n",
      "Precision total:  0.7338601677386349\n",
      "Recall total:  0.7392332337398194\n",
      "F1 total:  0.7364232688402375\n",
      "BACC total:  0.7392332337398194\n",
      "MCC total:  0.9478644629569626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import time\n",
    "start = time.time()\n",
    "# create MLPClassifier instance\n",
    "mlp_00 = MLPClassifier(hidden_layer_sizes=(100,), max_iter=200, random_state=1)\n",
    "\n",
    "base_classifier = mlp_00\n",
    "\n",
    "# Define the BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the BaggingClassifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "# accuracy = accuracy_score(y_test_00, y_pred)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('--------------------------------------------------------------------------', file = f)\n",
    "\n",
    "name = 'bag_mlp'\n",
    "pred_label = y_pred\n",
    "metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "Acc = metrics[0]\n",
    "Precision = metrics[1]\n",
    "Recall = metrics[2]\n",
    "F1 = metrics[3]\n",
    "BACC = metrics[4]\n",
    "MCC = metrics[5]    \n",
    "\n",
    "\n",
    "globals()[f\"{name}_acc_00\"] = Acc\n",
    "globals()[f\"{name}_pre_00\"] = Precision\n",
    "globals()[f\"{name}_rec_00\"] = Recall\n",
    "globals()[f\"{name}_f1_00\"] = F1\n",
    "globals()[f\"{name}_bacc_00\"] = BACC\n",
    "globals()[f\"{name}_mcc_00\"] = MCC\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "globals()[f\"{name}_time_00\"] = time_taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bagging KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3    4\n",
      "0  22459.0    182.0   166.0  198.0  2.0\n",
      "1    116.0  15950.0    22.0   12.0  1.0\n",
      "2    129.0     17.0  4110.0   21.0  0.0\n",
      "3    131.0      3.0    11.0  991.0  2.0\n",
      "4     21.0      2.0     0.0    9.0  1.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.976546368614777\n",
      "Precision total:  0.7791045487524741\n",
      "Recall total:  0.7657771686591303\n",
      "F1 total:  0.7627367120222106\n",
      "BACC total:  0.7657771686591303\n",
      "MCC total:  0.9605401288763482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_00=KNeighborsClassifier(n_neighbors = 5)\n",
    "start = time.time()\n",
    "base_classifier = knn_00\n",
    "\n",
    "# Define the BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the BaggingClassifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "# accuracy = accuracy_score(y_test_00, y_pred)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('--------------------------------------------------------------------------', file = f)\n",
    "\n",
    "name = 'bag_knn'\n",
    "\n",
    "pred_label = y_pred\n",
    "\n",
    "\n",
    "metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "Acc = metrics[0]\n",
    "Precision = metrics[1]\n",
    "Recall = metrics[2]\n",
    "F1 = metrics[3]\n",
    "BACC = metrics[4]\n",
    "MCC = metrics[5]    \n",
    "\n",
    "\n",
    "globals()[f\"{name}_acc_00\"] = Acc\n",
    "globals()[f\"{name}_pre_00\"] = Precision\n",
    "globals()[f\"{name}_rec_00\"] = Recall\n",
    "globals()[f\"{name}_f1_00\"] = F1\n",
    "globals()[f\"{name}_bacc_00\"] = BACC\n",
    "globals()[f\"{name}_mcc_00\"] = MCC\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "globals()[f\"{name}_time_00\"] = time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### bag LogRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Defining baggin Logistic Regression Model\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2     3    4\n",
      "0  21419.0    546.0   993.0  49.0  0.0\n",
      "1   1273.0  14749.0    79.0   0.0  0.0\n",
      "2    968.0   1216.0  2093.0   0.0  0.0\n",
      "3    971.0     27.0   127.0  13.0  0.0\n",
      "4     24.0      5.0     3.0   1.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.8590088876918933\n",
      "Precision total:  0.5203716270654932\n",
      "Recall total:  0.46955856820769953\n",
      "F1 total:  0.47537782565924197\n",
      "BACC total:  0.46955856820769953\n",
      "MCC total:  0.7561206279709384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "start = time.time()\n",
    "#Logistic Regression\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining baggin Logistic Regression Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "logreg_00 = LogisticRegression()\n",
    "\n",
    "\n",
    "base_classifier = logreg_00\n",
    "\n",
    "# Define the BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the BaggingClassifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "# accuracy = accuracy_score(y_test_00, y_pred)\n",
    "# print(f'Accuracy: {accuracy}')\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('--------------------------------------------------------------------------', file = f)\n",
    "\n",
    "name = 'bag_lr'\n",
    "\n",
    "pred_label = y_pred\n",
    "\n",
    "\n",
    "metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "Acc = metrics[0]\n",
    "Precision = metrics[1]\n",
    "Recall = metrics[2]\n",
    "F1 = metrics[3]\n",
    "BACC = metrics[4]\n",
    "MCC = metrics[5]    \n",
    "\n",
    "\n",
    "globals()[f\"{name}_acc_00\"] = Acc\n",
    "globals()[f\"{name}_pre_00\"] = Precision\n",
    "globals()[f\"{name}_rec_00\"] = Recall\n",
    "globals()[f\"{name}_f1_00\"] = F1\n",
    "globals()[f\"{name}_bacc_00\"] = BACC\n",
    "globals()[f\"{name}_mcc_00\"] = MCC\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "globals()[f\"{name}_time_00\"] = time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2     3    4\n",
      "0  22639.0    148.0   216.0   4.0  0.0\n",
      "1    992.0  15039.0    70.0   0.0  0.0\n",
      "2    381.0    191.0  3705.0   0.0  0.0\n",
      "3   1075.0      0.0    24.0  39.0  0.0\n",
      "4     32.0      0.0     0.0   1.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9296615495107281\n",
      "Precision total:  0.737675730295928\n",
      "Recall total:  0.5637156560827961\n",
      "F1 total:  0.5711876824692197\n",
      "BACC total:  0.5637156560827961\n",
      "MCC total:  0.8806680889666707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth = 5,  n_estimators = 10, min_samples_split = 2, n_jobs = -1)\n",
    "\n",
    "base_classifier = rf\n",
    "\n",
    "# Define the BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the BaggingClassifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('--------------------------------------------------------------------------', file = f)\n",
    "\n",
    "name = 'bag_rf'\n",
    "\n",
    "pred_label = y_pred\n",
    "\n",
    "\n",
    "metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "Acc = metrics[0]\n",
    "Precision = metrics[1]\n",
    "Recall = metrics[2]\n",
    "F1 = metrics[3]\n",
    "BACC = metrics[4]\n",
    "MCC = metrics[5]    \n",
    "\n",
    "\n",
    "globals()[f\"{name}_acc_00\"] = Acc\n",
    "globals()[f\"{name}_pre_00\"] = Precision\n",
    "globals()[f\"{name}_rec_00\"] = Recall\n",
    "globals()[f\"{name}_f1_00\"] = F1\n",
    "globals()[f\"{name}_bacc_00\"] = BACC\n",
    "globals()[f\"{name}_mcc_00\"] = MCC\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "globals()[f\"{name}_time_00\"] = time_taken\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging ADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3     4\n",
      "0  17016.0   4739.0   964.0  273.0  15.0\n",
      "1    417.0  12639.0  2980.0   63.0   2.0\n",
      "2    545.0   1028.0  2673.0   31.0   0.0\n",
      "3    522.0     40.0     5.0  567.0   4.0\n",
      "4     11.0      0.0     1.0   18.0   3.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.7383517371397792\n",
      "Precision total:  0.5457216368368039\n",
      "Recall total:  0.5477411371621115\n",
      "F1 total:  0.537939422804649\n",
      "BACC total:  0.5477411371621115\n",
      "MCC total:  0.586453467150978\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import time\n",
    "ada = AdaBoostClassifier(n_estimators=50, learning_rate=1.0)\n",
    "\n",
    "base_classifier = ada\n",
    "\n",
    "# Define the BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the BaggingClassifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('--------------------------------------------------------------------------', file = f)\n",
    "\n",
    "name = 'bag_ada'\n",
    "\n",
    "pred_label = y_pred\n",
    "\n",
    "\n",
    "metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "Acc = metrics[0]\n",
    "Precision = metrics[1]\n",
    "Recall = metrics[2]\n",
    "F1 = metrics[3]\n",
    "BACC = metrics[4]\n",
    "MCC = metrics[5]    \n",
    "\n",
    "\n",
    "globals()[f\"{name}_acc_00\"] = Acc\n",
    "globals()[f\"{name}_pre_00\"] = Precision\n",
    "globals()[f\"{name}_rec_00\"] = Recall\n",
    "globals()[f\"{name}_f1_00\"] = F1\n",
    "globals()[f\"{name}_bacc_00\"] = BACC\n",
    "globals()[f\"{name}_mcc_00\"] = MCC\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "globals()[f\"{name}_time_00\"] = time_taken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3    4\n",
      "0  22588.0    145.0   123.0  147.0  4.0\n",
      "1     97.0  15973.0    22.0    9.0  0.0\n",
      "2    108.0     11.0  4148.0   10.0  0.0\n",
      "3    128.0      1.0    13.0  990.0  6.0\n",
      "4     20.0      0.0     0.0   11.0  2.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.980810665230272\n",
      "Precision total:  0.7906364030266764\n",
      "Recall total:  0.774846068629134\n",
      "F1 total:  0.7777617691423482\n",
      "BACC total:  0.774846068629134\n",
      "MCC total:  0.9676636808145522\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "\n",
    "\n",
    "base_classifier = lgbm\n",
    "\n",
    "# Define the BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the BaggingClassifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('--------------------------------------------------------------------------', file = f)\n",
    "\n",
    "name = 'bag_lgbm'\n",
    "\n",
    "pred_label = y_pred\n",
    "\n",
    "\n",
    "metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "Acc = metrics[0]\n",
    "Precision = metrics[1]\n",
    "Recall = metrics[2]\n",
    "F1 = metrics[3]\n",
    "BACC = metrics[4]\n",
    "MCC = metrics[5]    \n",
    "\n",
    "\n",
    "globals()[f\"{name}_acc_00\"] = Acc\n",
    "globals()[f\"{name}_pre_00\"] = Precision\n",
    "globals()[f\"{name}_rec_00\"] = Recall\n",
    "globals()[f\"{name}_f1_00\"] = F1\n",
    "globals()[f\"{name}_bacc_00\"] = BACC\n",
    "globals()[f\"{name}_mcc_00\"] = MCC\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "globals()[f\"{name}_time_00\"] = time_taken\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Catboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3066352\ttotal: 28.8ms\tremaining: 2.85s\n",
      "1:\tlearn: 1.1146871\ttotal: 52.4ms\tremaining: 2.57s\n",
      "2:\tlearn: 0.9747702\ttotal: 74ms\tremaining: 2.39s\n",
      "3:\tlearn: 0.8682439\ttotal: 93.4ms\tremaining: 2.24s\n",
      "4:\tlearn: 0.7769188\ttotal: 116ms\tremaining: 2.2s\n",
      "5:\tlearn: 0.7031324\ttotal: 141ms\tremaining: 2.21s\n",
      "6:\tlearn: 0.6427024\ttotal: 167ms\tremaining: 2.22s\n",
      "7:\tlearn: 0.5875422\ttotal: 191ms\tremaining: 2.19s\n",
      "8:\tlearn: 0.5432293\ttotal: 215ms\tremaining: 2.18s\n",
      "9:\tlearn: 0.5019902\ttotal: 242ms\tremaining: 2.17s\n",
      "10:\tlearn: 0.4668573\ttotal: 269ms\tremaining: 2.18s\n",
      "11:\tlearn: 0.4357264\ttotal: 294ms\tremaining: 2.16s\n",
      "12:\tlearn: 0.4085990\ttotal: 320ms\tremaining: 2.14s\n",
      "13:\tlearn: 0.3833979\ttotal: 345ms\tremaining: 2.12s\n",
      "14:\tlearn: 0.3617594\ttotal: 370ms\tremaining: 2.1s\n",
      "15:\tlearn: 0.3421378\ttotal: 397ms\tremaining: 2.09s\n",
      "16:\tlearn: 0.3250150\ttotal: 424ms\tremaining: 2.07s\n",
      "17:\tlearn: 0.3087622\ttotal: 450ms\tremaining: 2.05s\n",
      "18:\tlearn: 0.2957416\ttotal: 473ms\tremaining: 2.02s\n",
      "19:\tlearn: 0.2820295\ttotal: 498ms\tremaining: 1.99s\n",
      "20:\tlearn: 0.2710298\ttotal: 520ms\tremaining: 1.96s\n",
      "21:\tlearn: 0.2592751\ttotal: 547ms\tremaining: 1.94s\n",
      "22:\tlearn: 0.2483847\ttotal: 574ms\tremaining: 1.92s\n",
      "23:\tlearn: 0.2389775\ttotal: 600ms\tremaining: 1.9s\n",
      "24:\tlearn: 0.2292423\ttotal: 628ms\tremaining: 1.88s\n",
      "25:\tlearn: 0.2214874\ttotal: 653ms\tremaining: 1.86s\n",
      "26:\tlearn: 0.2141230\ttotal: 680ms\tremaining: 1.84s\n",
      "27:\tlearn: 0.2077125\ttotal: 705ms\tremaining: 1.81s\n",
      "28:\tlearn: 0.2002015\ttotal: 732ms\tremaining: 1.79s\n",
      "29:\tlearn: 0.1950885\ttotal: 758ms\tremaining: 1.77s\n",
      "30:\tlearn: 0.1901082\ttotal: 781ms\tremaining: 1.74s\n",
      "31:\tlearn: 0.1855567\ttotal: 804ms\tremaining: 1.71s\n",
      "32:\tlearn: 0.1803171\ttotal: 829ms\tremaining: 1.68s\n",
      "33:\tlearn: 0.1766954\ttotal: 851ms\tremaining: 1.65s\n",
      "34:\tlearn: 0.1724880\ttotal: 875ms\tremaining: 1.62s\n",
      "35:\tlearn: 0.1693706\ttotal: 900ms\tremaining: 1.6s\n",
      "36:\tlearn: 0.1653315\ttotal: 926ms\tremaining: 1.58s\n",
      "37:\tlearn: 0.1617788\ttotal: 952ms\tremaining: 1.55s\n",
      "38:\tlearn: 0.1592638\ttotal: 977ms\tremaining: 1.53s\n",
      "39:\tlearn: 0.1561820\ttotal: 1s\tremaining: 1.5s\n",
      "40:\tlearn: 0.1537438\ttotal: 1.03s\tremaining: 1.48s\n",
      "41:\tlearn: 0.1519202\ttotal: 1.05s\tremaining: 1.45s\n",
      "42:\tlearn: 0.1493953\ttotal: 1.07s\tremaining: 1.42s\n",
      "43:\tlearn: 0.1464853\ttotal: 1.1s\tremaining: 1.4s\n",
      "44:\tlearn: 0.1447019\ttotal: 1.12s\tremaining: 1.37s\n",
      "45:\tlearn: 0.1424649\ttotal: 1.15s\tremaining: 1.35s\n",
      "46:\tlearn: 0.1407982\ttotal: 1.18s\tremaining: 1.33s\n",
      "47:\tlearn: 0.1386475\ttotal: 1.2s\tremaining: 1.3s\n",
      "48:\tlearn: 0.1377652\ttotal: 1.23s\tremaining: 1.28s\n",
      "49:\tlearn: 0.1361409\ttotal: 1.25s\tremaining: 1.25s\n",
      "50:\tlearn: 0.1340505\ttotal: 1.28s\tremaining: 1.23s\n",
      "51:\tlearn: 0.1328784\ttotal: 1.3s\tremaining: 1.2s\n",
      "52:\tlearn: 0.1315815\ttotal: 1.33s\tremaining: 1.18s\n",
      "53:\tlearn: 0.1295317\ttotal: 1.35s\tremaining: 1.15s\n",
      "54:\tlearn: 0.1279568\ttotal: 1.38s\tremaining: 1.13s\n",
      "55:\tlearn: 0.1266665\ttotal: 1.4s\tremaining: 1.1s\n",
      "56:\tlearn: 0.1253980\ttotal: 1.43s\tremaining: 1.08s\n",
      "57:\tlearn: 0.1247375\ttotal: 1.45s\tremaining: 1.05s\n",
      "58:\tlearn: 0.1236855\ttotal: 1.47s\tremaining: 1.02s\n",
      "59:\tlearn: 0.1219283\ttotal: 1.5s\tremaining: 1s\n",
      "60:\tlearn: 0.1204999\ttotal: 1.53s\tremaining: 976ms\n",
      "61:\tlearn: 0.1194213\ttotal: 1.55s\tremaining: 951ms\n",
      "62:\tlearn: 0.1180624\ttotal: 1.58s\tremaining: 926ms\n",
      "63:\tlearn: 0.1166585\ttotal: 1.6s\tremaining: 901ms\n",
      "64:\tlearn: 0.1159357\ttotal: 1.62s\tremaining: 875ms\n",
      "65:\tlearn: 0.1151883\ttotal: 1.65s\tremaining: 849ms\n",
      "66:\tlearn: 0.1141572\ttotal: 1.67s\tremaining: 824ms\n",
      "67:\tlearn: 0.1135040\ttotal: 1.69s\tremaining: 797ms\n",
      "68:\tlearn: 0.1129210\ttotal: 1.72s\tremaining: 771ms\n",
      "69:\tlearn: 0.1117327\ttotal: 1.74s\tremaining: 748ms\n",
      "70:\tlearn: 0.1107958\ttotal: 1.77s\tremaining: 724ms\n",
      "71:\tlearn: 0.1100848\ttotal: 1.8s\tremaining: 699ms\n",
      "72:\tlearn: 0.1094094\ttotal: 1.82s\tremaining: 673ms\n",
      "73:\tlearn: 0.1084366\ttotal: 1.84s\tremaining: 648ms\n",
      "74:\tlearn: 0.1077244\ttotal: 1.87s\tremaining: 623ms\n",
      "75:\tlearn: 0.1070268\ttotal: 1.9s\tremaining: 601ms\n",
      "76:\tlearn: 0.1061278\ttotal: 1.92s\tremaining: 574ms\n",
      "77:\tlearn: 0.1055979\ttotal: 1.94s\tremaining: 546ms\n",
      "78:\tlearn: 0.1048256\ttotal: 1.95s\tremaining: 519ms\n",
      "79:\tlearn: 0.1043491\ttotal: 1.97s\tremaining: 492ms\n",
      "80:\tlearn: 0.1036577\ttotal: 1.99s\tremaining: 466ms\n",
      "81:\tlearn: 0.1030378\ttotal: 2.01s\tremaining: 441ms\n",
      "82:\tlearn: 0.1023799\ttotal: 2.03s\tremaining: 416ms\n",
      "83:\tlearn: 0.1020899\ttotal: 2.05s\tremaining: 391ms\n",
      "84:\tlearn: 0.1015921\ttotal: 2.07s\tremaining: 366ms\n",
      "85:\tlearn: 0.1008936\ttotal: 2.1s\tremaining: 341ms\n",
      "86:\tlearn: 0.1005711\ttotal: 2.12s\tremaining: 317ms\n",
      "87:\tlearn: 0.1002163\ttotal: 2.14s\tremaining: 292ms\n",
      "88:\tlearn: 0.0997380\ttotal: 2.17s\tremaining: 268ms\n",
      "89:\tlearn: 0.0994525\ttotal: 2.19s\tremaining: 243ms\n",
      "90:\tlearn: 0.0991570\ttotal: 2.21s\tremaining: 219ms\n",
      "91:\tlearn: 0.0984980\ttotal: 2.24s\tremaining: 195ms\n",
      "92:\tlearn: 0.0975179\ttotal: 2.26s\tremaining: 170ms\n",
      "93:\tlearn: 0.0969562\ttotal: 2.29s\tremaining: 146ms\n",
      "94:\tlearn: 0.0963558\ttotal: 2.31s\tremaining: 122ms\n",
      "95:\tlearn: 0.0958138\ttotal: 2.33s\tremaining: 97.3ms\n",
      "96:\tlearn: 0.0952268\ttotal: 2.36s\tremaining: 72.9ms\n",
      "97:\tlearn: 0.0950198\ttotal: 2.38s\tremaining: 48.6ms\n",
      "98:\tlearn: 0.0944624\ttotal: 2.4s\tremaining: 24.3ms\n",
      "99:\tlearn: 0.0939727\ttotal: 2.42s\tremaining: 0us\n",
      "0:\tlearn: 1.3077547\ttotal: 31.1ms\tremaining: 3.08s\n",
      "1:\tlearn: 1.1142102\ttotal: 56.2ms\tremaining: 2.75s\n",
      "2:\tlearn: 0.9747718\ttotal: 82.7ms\tremaining: 2.67s\n",
      "3:\tlearn: 0.8685470\ttotal: 109ms\tremaining: 2.62s\n",
      "4:\tlearn: 0.7774106\ttotal: 136ms\tremaining: 2.59s\n",
      "5:\tlearn: 0.7041608\ttotal: 164ms\tremaining: 2.56s\n",
      "6:\tlearn: 0.6438207\ttotal: 189ms\tremaining: 2.51s\n",
      "7:\tlearn: 0.5887491\ttotal: 215ms\tremaining: 2.48s\n",
      "8:\tlearn: 0.5453449\ttotal: 244ms\tremaining: 2.47s\n",
      "9:\tlearn: 0.5050559\ttotal: 269ms\tremaining: 2.42s\n",
      "10:\tlearn: 0.4729509\ttotal: 294ms\tremaining: 2.38s\n",
      "11:\tlearn: 0.4413995\ttotal: 319ms\tremaining: 2.34s\n",
      "12:\tlearn: 0.4145264\ttotal: 345ms\tremaining: 2.31s\n",
      "13:\tlearn: 0.3898298\ttotal: 373ms\tremaining: 2.29s\n",
      "14:\tlearn: 0.3660071\ttotal: 403ms\tremaining: 2.28s\n",
      "15:\tlearn: 0.3464409\ttotal: 429ms\tremaining: 2.25s\n",
      "16:\tlearn: 0.3271464\ttotal: 454ms\tremaining: 2.21s\n",
      "17:\tlearn: 0.3111972\ttotal: 478ms\tremaining: 2.17s\n",
      "18:\tlearn: 0.2980380\ttotal: 501ms\tremaining: 2.13s\n",
      "19:\tlearn: 0.2848759\ttotal: 524ms\tremaining: 2.1s\n",
      "20:\tlearn: 0.2732097\ttotal: 550ms\tremaining: 2.07s\n",
      "21:\tlearn: 0.2616800\ttotal: 577ms\tremaining: 2.05s\n",
      "22:\tlearn: 0.2512795\ttotal: 604ms\tremaining: 2.02s\n",
      "23:\tlearn: 0.2396361\ttotal: 635ms\tremaining: 2.01s\n",
      "24:\tlearn: 0.2313413\ttotal: 660ms\tremaining: 1.98s\n",
      "25:\tlearn: 0.2234461\ttotal: 685ms\tremaining: 1.95s\n",
      "26:\tlearn: 0.2160913\ttotal: 711ms\tremaining: 1.92s\n",
      "27:\tlearn: 0.2110445\ttotal: 735ms\tremaining: 1.89s\n",
      "28:\tlearn: 0.2048369\ttotal: 760ms\tremaining: 1.86s\n",
      "29:\tlearn: 0.1990933\ttotal: 783ms\tremaining: 1.83s\n",
      "30:\tlearn: 0.1936292\ttotal: 805ms\tremaining: 1.79s\n",
      "31:\tlearn: 0.1880810\ttotal: 828ms\tremaining: 1.76s\n",
      "32:\tlearn: 0.1829157\ttotal: 855ms\tremaining: 1.74s\n",
      "33:\tlearn: 0.1786672\ttotal: 881ms\tremaining: 1.71s\n",
      "34:\tlearn: 0.1751039\ttotal: 907ms\tremaining: 1.68s\n",
      "35:\tlearn: 0.1722465\ttotal: 933ms\tremaining: 1.66s\n",
      "36:\tlearn: 0.1681456\ttotal: 960ms\tremaining: 1.63s\n",
      "37:\tlearn: 0.1656831\ttotal: 982ms\tremaining: 1.6s\n",
      "38:\tlearn: 0.1639616\ttotal: 1s\tremaining: 1.57s\n",
      "39:\tlearn: 0.1603491\ttotal: 1.03s\tremaining: 1.55s\n",
      "40:\tlearn: 0.1570734\ttotal: 1.06s\tremaining: 1.52s\n",
      "41:\tlearn: 0.1549666\ttotal: 1.08s\tremaining: 1.5s\n",
      "42:\tlearn: 0.1518530\ttotal: 1.11s\tremaining: 1.47s\n",
      "43:\tlearn: 0.1488308\ttotal: 1.13s\tremaining: 1.44s\n",
      "44:\tlearn: 0.1473257\ttotal: 1.16s\tremaining: 1.41s\n",
      "45:\tlearn: 0.1451748\ttotal: 1.18s\tremaining: 1.39s\n",
      "46:\tlearn: 0.1423903\ttotal: 1.21s\tremaining: 1.36s\n",
      "47:\tlearn: 0.1401784\ttotal: 1.23s\tremaining: 1.34s\n",
      "48:\tlearn: 0.1378574\ttotal: 1.26s\tremaining: 1.31s\n",
      "49:\tlearn: 0.1364061\ttotal: 1.28s\tremaining: 1.28s\n",
      "50:\tlearn: 0.1342721\ttotal: 1.3s\tremaining: 1.25s\n",
      "51:\tlearn: 0.1323853\ttotal: 1.33s\tremaining: 1.23s\n",
      "52:\tlearn: 0.1314423\ttotal: 1.35s\tremaining: 1.2s\n",
      "53:\tlearn: 0.1297294\ttotal: 1.37s\tremaining: 1.17s\n",
      "54:\tlearn: 0.1281406\ttotal: 1.4s\tremaining: 1.15s\n",
      "55:\tlearn: 0.1263856\ttotal: 1.43s\tremaining: 1.12s\n",
      "56:\tlearn: 0.1250811\ttotal: 1.45s\tremaining: 1.09s\n",
      "57:\tlearn: 0.1244379\ttotal: 1.47s\tremaining: 1.07s\n",
      "58:\tlearn: 0.1227580\ttotal: 1.5s\tremaining: 1.04s\n",
      "59:\tlearn: 0.1217239\ttotal: 1.52s\tremaining: 1.01s\n",
      "60:\tlearn: 0.1205933\ttotal: 1.54s\tremaining: 985ms\n",
      "61:\tlearn: 0.1197606\ttotal: 1.56s\tremaining: 958ms\n",
      "62:\tlearn: 0.1187947\ttotal: 1.59s\tremaining: 933ms\n",
      "63:\tlearn: 0.1180026\ttotal: 1.61s\tremaining: 905ms\n",
      "64:\tlearn: 0.1170887\ttotal: 1.63s\tremaining: 877ms\n",
      "65:\tlearn: 0.1155724\ttotal: 1.65s\tremaining: 851ms\n",
      "66:\tlearn: 0.1146071\ttotal: 1.68s\tremaining: 826ms\n",
      "67:\tlearn: 0.1136361\ttotal: 1.7s\tremaining: 801ms\n",
      "68:\tlearn: 0.1125062\ttotal: 1.73s\tremaining: 776ms\n",
      "69:\tlearn: 0.1116687\ttotal: 1.75s\tremaining: 750ms\n",
      "70:\tlearn: 0.1104856\ttotal: 1.77s\tremaining: 724ms\n",
      "71:\tlearn: 0.1101282\ttotal: 1.79s\tremaining: 698ms\n",
      "72:\tlearn: 0.1095898\ttotal: 1.81s\tremaining: 671ms\n",
      "73:\tlearn: 0.1090487\ttotal: 1.84s\tremaining: 647ms\n",
      "74:\tlearn: 0.1087569\ttotal: 1.86s\tremaining: 620ms\n",
      "75:\tlearn: 0.1083533\ttotal: 1.88s\tremaining: 595ms\n",
      "76:\tlearn: 0.1075334\ttotal: 1.91s\tremaining: 569ms\n",
      "77:\tlearn: 0.1068824\ttotal: 1.93s\tremaining: 544ms\n",
      "78:\tlearn: 0.1060838\ttotal: 1.96s\tremaining: 520ms\n",
      "79:\tlearn: 0.1052026\ttotal: 1.98s\tremaining: 495ms\n",
      "80:\tlearn: 0.1043359\ttotal: 2.01s\tremaining: 471ms\n",
      "81:\tlearn: 0.1039090\ttotal: 2.03s\tremaining: 446ms\n",
      "82:\tlearn: 0.1030931\ttotal: 2.06s\tremaining: 422ms\n",
      "83:\tlearn: 0.1023553\ttotal: 2.08s\tremaining: 397ms\n",
      "84:\tlearn: 0.1018797\ttotal: 2.11s\tremaining: 372ms\n",
      "85:\tlearn: 0.1014211\ttotal: 2.14s\tremaining: 348ms\n",
      "86:\tlearn: 0.1009569\ttotal: 2.16s\tremaining: 323ms\n",
      "87:\tlearn: 0.1003826\ttotal: 2.19s\tremaining: 298ms\n",
      "88:\tlearn: 0.0998423\ttotal: 2.21s\tremaining: 273ms\n",
      "89:\tlearn: 0.0991603\ttotal: 2.24s\tremaining: 249ms\n",
      "90:\tlearn: 0.0986138\ttotal: 2.26s\tremaining: 224ms\n",
      "91:\tlearn: 0.0979239\ttotal: 2.29s\tremaining: 199ms\n",
      "92:\tlearn: 0.0971229\ttotal: 2.32s\tremaining: 174ms\n",
      "93:\tlearn: 0.0964290\ttotal: 2.34s\tremaining: 150ms\n",
      "94:\tlearn: 0.0960384\ttotal: 2.37s\tremaining: 125ms\n",
      "95:\tlearn: 0.0957573\ttotal: 2.39s\tremaining: 99.6ms\n",
      "96:\tlearn: 0.0953528\ttotal: 2.41s\tremaining: 74.7ms\n",
      "97:\tlearn: 0.0950752\ttotal: 2.44s\tremaining: 49.8ms\n",
      "98:\tlearn: 0.0946997\ttotal: 2.46s\tremaining: 24.9ms\n",
      "99:\tlearn: 0.0942705\ttotal: 2.48s\tremaining: 0us\n",
      "0:\tlearn: 1.3067663\ttotal: 31.1ms\tremaining: 3.08s\n",
      "1:\tlearn: 1.1132523\ttotal: 55.8ms\tremaining: 2.73s\n",
      "2:\tlearn: 0.9738509\ttotal: 81.8ms\tremaining: 2.65s\n",
      "3:\tlearn: 0.8675154\ttotal: 106ms\tremaining: 2.54s\n",
      "4:\tlearn: 0.7765746\ttotal: 131ms\tremaining: 2.48s\n",
      "5:\tlearn: 0.7041653\ttotal: 157ms\tremaining: 2.45s\n",
      "6:\tlearn: 0.6439792\ttotal: 183ms\tremaining: 2.44s\n",
      "7:\tlearn: 0.5890270\ttotal: 211ms\tremaining: 2.42s\n",
      "8:\tlearn: 0.5456611\ttotal: 236ms\tremaining: 2.39s\n",
      "9:\tlearn: 0.5038427\ttotal: 259ms\tremaining: 2.33s\n",
      "10:\tlearn: 0.4689616\ttotal: 283ms\tremaining: 2.29s\n",
      "11:\tlearn: 0.4377635\ttotal: 306ms\tremaining: 2.24s\n",
      "12:\tlearn: 0.4106172\ttotal: 330ms\tremaining: 2.21s\n",
      "13:\tlearn: 0.3859711\ttotal: 355ms\tremaining: 2.18s\n",
      "14:\tlearn: 0.3626324\ttotal: 380ms\tremaining: 2.15s\n",
      "15:\tlearn: 0.3431710\ttotal: 400ms\tremaining: 2.1s\n",
      "16:\tlearn: 0.3262175\ttotal: 423ms\tremaining: 2.07s\n",
      "17:\tlearn: 0.3103197\ttotal: 448ms\tremaining: 2.04s\n",
      "18:\tlearn: 0.2959025\ttotal: 474ms\tremaining: 2.02s\n",
      "19:\tlearn: 0.2826613\ttotal: 500ms\tremaining: 2s\n",
      "20:\tlearn: 0.2699523\ttotal: 529ms\tremaining: 1.99s\n",
      "21:\tlearn: 0.2586884\ttotal: 557ms\tremaining: 1.97s\n",
      "22:\tlearn: 0.2485372\ttotal: 582ms\tremaining: 1.95s\n",
      "23:\tlearn: 0.2392931\ttotal: 609ms\tremaining: 1.93s\n",
      "24:\tlearn: 0.2316455\ttotal: 632ms\tremaining: 1.9s\n",
      "25:\tlearn: 0.2241075\ttotal: 657ms\tremaining: 1.87s\n",
      "26:\tlearn: 0.2150517\ttotal: 685ms\tremaining: 1.85s\n",
      "27:\tlearn: 0.2095998\ttotal: 710ms\tremaining: 1.82s\n",
      "28:\tlearn: 0.2033863\ttotal: 734ms\tremaining: 1.8s\n",
      "29:\tlearn: 0.1977323\ttotal: 762ms\tremaining: 1.78s\n",
      "30:\tlearn: 0.1921735\ttotal: 789ms\tremaining: 1.75s\n",
      "31:\tlearn: 0.1885561\ttotal: 816ms\tremaining: 1.73s\n",
      "32:\tlearn: 0.1836647\ttotal: 841ms\tremaining: 1.71s\n",
      "33:\tlearn: 0.1795942\ttotal: 866ms\tremaining: 1.68s\n",
      "34:\tlearn: 0.1747991\ttotal: 894ms\tremaining: 1.66s\n",
      "35:\tlearn: 0.1716657\ttotal: 919ms\tremaining: 1.63s\n",
      "36:\tlearn: 0.1680407\ttotal: 944ms\tremaining: 1.61s\n",
      "37:\tlearn: 0.1653059\ttotal: 968ms\tremaining: 1.58s\n",
      "38:\tlearn: 0.1619229\ttotal: 993ms\tremaining: 1.55s\n",
      "39:\tlearn: 0.1586898\ttotal: 1.02s\tremaining: 1.53s\n",
      "40:\tlearn: 0.1559097\ttotal: 1.05s\tremaining: 1.51s\n",
      "41:\tlearn: 0.1537615\ttotal: 1.07s\tremaining: 1.48s\n",
      "42:\tlearn: 0.1514049\ttotal: 1.1s\tremaining: 1.46s\n",
      "43:\tlearn: 0.1492573\ttotal: 1.13s\tremaining: 1.43s\n",
      "44:\tlearn: 0.1479109\ttotal: 1.15s\tremaining: 1.41s\n",
      "45:\tlearn: 0.1459252\ttotal: 1.18s\tremaining: 1.38s\n",
      "46:\tlearn: 0.1445475\ttotal: 1.2s\tremaining: 1.35s\n",
      "47:\tlearn: 0.1428896\ttotal: 1.21s\tremaining: 1.32s\n",
      "48:\tlearn: 0.1414343\ttotal: 1.24s\tremaining: 1.28s\n",
      "49:\tlearn: 0.1393508\ttotal: 1.26s\tremaining: 1.26s\n",
      "50:\tlearn: 0.1380147\ttotal: 1.28s\tremaining: 1.23s\n",
      "51:\tlearn: 0.1362431\ttotal: 1.31s\tremaining: 1.21s\n",
      "52:\tlearn: 0.1352786\ttotal: 1.33s\tremaining: 1.18s\n",
      "53:\tlearn: 0.1336166\ttotal: 1.35s\tremaining: 1.15s\n",
      "54:\tlearn: 0.1317819\ttotal: 1.38s\tremaining: 1.13s\n",
      "55:\tlearn: 0.1308088\ttotal: 1.4s\tremaining: 1.1s\n",
      "56:\tlearn: 0.1290686\ttotal: 1.42s\tremaining: 1.07s\n",
      "57:\tlearn: 0.1275940\ttotal: 1.45s\tremaining: 1.05s\n",
      "58:\tlearn: 0.1261087\ttotal: 1.47s\tremaining: 1.02s\n",
      "59:\tlearn: 0.1244848\ttotal: 1.5s\tremaining: 1000ms\n",
      "60:\tlearn: 0.1230846\ttotal: 1.53s\tremaining: 977ms\n",
      "61:\tlearn: 0.1212846\ttotal: 1.56s\tremaining: 955ms\n",
      "62:\tlearn: 0.1199993\ttotal: 1.59s\tremaining: 932ms\n",
      "63:\tlearn: 0.1188502\ttotal: 1.61s\tremaining: 907ms\n",
      "64:\tlearn: 0.1176177\ttotal: 1.64s\tremaining: 882ms\n",
      "65:\tlearn: 0.1168511\ttotal: 1.66s\tremaining: 857ms\n",
      "66:\tlearn: 0.1160619\ttotal: 1.69s\tremaining: 831ms\n",
      "67:\tlearn: 0.1148637\ttotal: 1.71s\tremaining: 804ms\n",
      "68:\tlearn: 0.1144204\ttotal: 1.73s\tremaining: 776ms\n",
      "69:\tlearn: 0.1133965\ttotal: 1.75s\tremaining: 750ms\n",
      "70:\tlearn: 0.1122751\ttotal: 1.78s\tremaining: 726ms\n",
      "71:\tlearn: 0.1117469\ttotal: 1.8s\tremaining: 700ms\n",
      "72:\tlearn: 0.1113138\ttotal: 1.82s\tremaining: 673ms\n",
      "73:\tlearn: 0.1102224\ttotal: 1.85s\tremaining: 649ms\n",
      "74:\tlearn: 0.1095554\ttotal: 1.87s\tremaining: 624ms\n",
      "75:\tlearn: 0.1088764\ttotal: 1.9s\tremaining: 599ms\n",
      "76:\tlearn: 0.1081120\ttotal: 1.92s\tremaining: 574ms\n",
      "77:\tlearn: 0.1073562\ttotal: 1.95s\tremaining: 549ms\n",
      "78:\tlearn: 0.1061972\ttotal: 1.97s\tremaining: 525ms\n",
      "79:\tlearn: 0.1055896\ttotal: 2s\tremaining: 500ms\n",
      "80:\tlearn: 0.1047978\ttotal: 2.02s\tremaining: 474ms\n",
      "81:\tlearn: 0.1041383\ttotal: 2.04s\tremaining: 449ms\n",
      "82:\tlearn: 0.1033263\ttotal: 2.07s\tremaining: 424ms\n",
      "83:\tlearn: 0.1028663\ttotal: 2.09s\tremaining: 398ms\n",
      "84:\tlearn: 0.1018835\ttotal: 2.12s\tremaining: 374ms\n",
      "85:\tlearn: 0.1013222\ttotal: 2.14s\tremaining: 349ms\n",
      "86:\tlearn: 0.1005539\ttotal: 2.17s\tremaining: 324ms\n",
      "87:\tlearn: 0.0999183\ttotal: 2.19s\tremaining: 299ms\n",
      "88:\tlearn: 0.0996389\ttotal: 2.21s\tremaining: 274ms\n",
      "89:\tlearn: 0.0992018\ttotal: 2.24s\tremaining: 249ms\n",
      "90:\tlearn: 0.0986433\ttotal: 2.26s\tremaining: 224ms\n",
      "91:\tlearn: 0.0978713\ttotal: 2.29s\tremaining: 199ms\n",
      "92:\tlearn: 0.0974655\ttotal: 2.31s\tremaining: 174ms\n",
      "93:\tlearn: 0.0968120\ttotal: 2.33s\tremaining: 149ms\n",
      "94:\tlearn: 0.0961622\ttotal: 2.36s\tremaining: 124ms\n",
      "95:\tlearn: 0.0955395\ttotal: 2.38s\tremaining: 99.3ms\n",
      "96:\tlearn: 0.0949775\ttotal: 2.41s\tremaining: 74.5ms\n",
      "97:\tlearn: 0.0943489\ttotal: 2.43s\tremaining: 49.6ms\n",
      "98:\tlearn: 0.0935551\ttotal: 2.46s\tremaining: 24.8ms\n",
      "99:\tlearn: 0.0929045\ttotal: 2.48s\tremaining: 0us\n",
      "0:\tlearn: 1.3060089\ttotal: 31.3ms\tremaining: 3.1s\n",
      "1:\tlearn: 1.1141593\ttotal: 56.3ms\tremaining: 2.76s\n",
      "2:\tlearn: 0.9743383\ttotal: 79.7ms\tremaining: 2.58s\n",
      "3:\tlearn: 0.8669071\ttotal: 104ms\tremaining: 2.5s\n",
      "4:\tlearn: 0.7761999\ttotal: 129ms\tremaining: 2.44s\n",
      "5:\tlearn: 0.7034503\ttotal: 154ms\tremaining: 2.41s\n",
      "6:\tlearn: 0.6430327\ttotal: 179ms\tremaining: 2.37s\n",
      "7:\tlearn: 0.5860947\ttotal: 205ms\tremaining: 2.36s\n",
      "8:\tlearn: 0.5412606\ttotal: 233ms\tremaining: 2.36s\n",
      "9:\tlearn: 0.5020146\ttotal: 262ms\tremaining: 2.36s\n",
      "10:\tlearn: 0.4699056\ttotal: 288ms\tremaining: 2.33s\n",
      "11:\tlearn: 0.4384516\ttotal: 314ms\tremaining: 2.3s\n",
      "12:\tlearn: 0.4106381\ttotal: 339ms\tremaining: 2.27s\n",
      "13:\tlearn: 0.3869354\ttotal: 364ms\tremaining: 2.24s\n",
      "14:\tlearn: 0.3643464\ttotal: 394ms\tremaining: 2.23s\n",
      "15:\tlearn: 0.3447449\ttotal: 421ms\tremaining: 2.21s\n",
      "16:\tlearn: 0.3257491\ttotal: 448ms\tremaining: 2.19s\n",
      "17:\tlearn: 0.3104840\ttotal: 471ms\tremaining: 2.15s\n",
      "18:\tlearn: 0.2974501\ttotal: 493ms\tremaining: 2.1s\n",
      "19:\tlearn: 0.2843337\ttotal: 517ms\tremaining: 2.07s\n",
      "20:\tlearn: 0.2717139\ttotal: 542ms\tremaining: 2.04s\n",
      "21:\tlearn: 0.2600474\ttotal: 571ms\tremaining: 2.02s\n",
      "22:\tlearn: 0.2499655\ttotal: 597ms\tremaining: 2s\n",
      "23:\tlearn: 0.2392660\ttotal: 622ms\tremaining: 1.97s\n",
      "24:\tlearn: 0.2298566\ttotal: 649ms\tremaining: 1.95s\n",
      "25:\tlearn: 0.2221636\ttotal: 674ms\tremaining: 1.92s\n",
      "26:\tlearn: 0.2157013\ttotal: 701ms\tremaining: 1.89s\n",
      "27:\tlearn: 0.2099651\ttotal: 724ms\tremaining: 1.86s\n",
      "28:\tlearn: 0.2039638\ttotal: 749ms\tremaining: 1.83s\n",
      "29:\tlearn: 0.1980075\ttotal: 775ms\tremaining: 1.81s\n",
      "30:\tlearn: 0.1923047\ttotal: 801ms\tremaining: 1.78s\n",
      "31:\tlearn: 0.1882054\ttotal: 827ms\tremaining: 1.76s\n",
      "32:\tlearn: 0.1828600\ttotal: 853ms\tremaining: 1.73s\n",
      "33:\tlearn: 0.1788060\ttotal: 879ms\tremaining: 1.71s\n",
      "34:\tlearn: 0.1741828\ttotal: 904ms\tremaining: 1.68s\n",
      "35:\tlearn: 0.1709093\ttotal: 931ms\tremaining: 1.65s\n",
      "36:\tlearn: 0.1680569\ttotal: 954ms\tremaining: 1.62s\n",
      "37:\tlearn: 0.1649970\ttotal: 979ms\tremaining: 1.6s\n",
      "38:\tlearn: 0.1627525\ttotal: 1s\tremaining: 1.57s\n",
      "39:\tlearn: 0.1592431\ttotal: 1.03s\tremaining: 1.54s\n",
      "40:\tlearn: 0.1562606\ttotal: 1.05s\tremaining: 1.52s\n",
      "41:\tlearn: 0.1536937\ttotal: 1.08s\tremaining: 1.49s\n",
      "42:\tlearn: 0.1517666\ttotal: 1.1s\tremaining: 1.46s\n",
      "43:\tlearn: 0.1495202\ttotal: 1.13s\tremaining: 1.43s\n",
      "44:\tlearn: 0.1480139\ttotal: 1.15s\tremaining: 1.4s\n",
      "45:\tlearn: 0.1447325\ttotal: 1.17s\tremaining: 1.38s\n",
      "46:\tlearn: 0.1435279\ttotal: 1.2s\tremaining: 1.35s\n",
      "47:\tlearn: 0.1413388\ttotal: 1.22s\tremaining: 1.32s\n",
      "48:\tlearn: 0.1392228\ttotal: 1.25s\tremaining: 1.3s\n",
      "49:\tlearn: 0.1374146\ttotal: 1.27s\tremaining: 1.27s\n",
      "50:\tlearn: 0.1360004\ttotal: 1.29s\tremaining: 1.24s\n",
      "51:\tlearn: 0.1347577\ttotal: 1.31s\tremaining: 1.21s\n",
      "52:\tlearn: 0.1330488\ttotal: 1.34s\tremaining: 1.19s\n",
      "53:\tlearn: 0.1320895\ttotal: 1.36s\tremaining: 1.16s\n",
      "54:\tlearn: 0.1300987\ttotal: 1.39s\tremaining: 1.13s\n",
      "55:\tlearn: 0.1289502\ttotal: 1.41s\tremaining: 1.11s\n",
      "56:\tlearn: 0.1275913\ttotal: 1.43s\tremaining: 1.08s\n",
      "57:\tlearn: 0.1264174\ttotal: 1.46s\tremaining: 1.05s\n",
      "58:\tlearn: 0.1258586\ttotal: 1.48s\tremaining: 1.02s\n",
      "59:\tlearn: 0.1249280\ttotal: 1.5s\tremaining: 998ms\n",
      "60:\tlearn: 0.1234284\ttotal: 1.52s\tremaining: 972ms\n",
      "61:\tlearn: 0.1223606\ttotal: 1.54s\tremaining: 946ms\n",
      "62:\tlearn: 0.1211253\ttotal: 1.57s\tremaining: 922ms\n",
      "63:\tlearn: 0.1199123\ttotal: 1.59s\tremaining: 896ms\n",
      "64:\tlearn: 0.1189061\ttotal: 1.61s\tremaining: 869ms\n",
      "65:\tlearn: 0.1176278\ttotal: 1.64s\tremaining: 843ms\n",
      "66:\tlearn: 0.1165599\ttotal: 1.66s\tremaining: 818ms\n",
      "67:\tlearn: 0.1154980\ttotal: 1.68s\tremaining: 793ms\n",
      "68:\tlearn: 0.1142681\ttotal: 1.71s\tremaining: 767ms\n",
      "69:\tlearn: 0.1138683\ttotal: 1.73s\tremaining: 742ms\n",
      "70:\tlearn: 0.1129384\ttotal: 1.75s\tremaining: 717ms\n",
      "71:\tlearn: 0.1124334\ttotal: 1.78s\tremaining: 691ms\n",
      "72:\tlearn: 0.1114312\ttotal: 1.8s\tremaining: 665ms\n",
      "73:\tlearn: 0.1104559\ttotal: 1.82s\tremaining: 641ms\n",
      "74:\tlearn: 0.1100010\ttotal: 1.84s\tremaining: 615ms\n",
      "75:\tlearn: 0.1092744\ttotal: 1.87s\tremaining: 589ms\n",
      "76:\tlearn: 0.1079992\ttotal: 1.89s\tremaining: 566ms\n",
      "77:\tlearn: 0.1071394\ttotal: 1.92s\tremaining: 541ms\n",
      "78:\tlearn: 0.1062846\ttotal: 1.95s\tremaining: 517ms\n",
      "79:\tlearn: 0.1050466\ttotal: 1.97s\tremaining: 494ms\n",
      "80:\tlearn: 0.1042852\ttotal: 2s\tremaining: 469ms\n",
      "81:\tlearn: 0.1036678\ttotal: 2.02s\tremaining: 445ms\n",
      "82:\tlearn: 0.1028578\ttotal: 2.05s\tremaining: 420ms\n",
      "83:\tlearn: 0.1024970\ttotal: 2.07s\tremaining: 395ms\n",
      "84:\tlearn: 0.1018503\ttotal: 2.09s\tremaining: 369ms\n",
      "85:\tlearn: 0.1010801\ttotal: 2.11s\tremaining: 344ms\n",
      "86:\tlearn: 0.1003180\ttotal: 2.13s\tremaining: 319ms\n",
      "87:\tlearn: 0.0996738\ttotal: 2.15s\tremaining: 293ms\n",
      "88:\tlearn: 0.0990121\ttotal: 2.17s\tremaining: 268ms\n",
      "89:\tlearn: 0.0986537\ttotal: 2.19s\tremaining: 243ms\n",
      "90:\tlearn: 0.0980927\ttotal: 2.2s\tremaining: 218ms\n",
      "91:\tlearn: 0.0974923\ttotal: 2.22s\tremaining: 193ms\n",
      "92:\tlearn: 0.0968093\ttotal: 2.24s\tremaining: 168ms\n",
      "93:\tlearn: 0.0961030\ttotal: 2.25s\tremaining: 144ms\n",
      "94:\tlearn: 0.0956150\ttotal: 2.27s\tremaining: 120ms\n",
      "95:\tlearn: 0.0950109\ttotal: 2.29s\tremaining: 95.6ms\n",
      "96:\tlearn: 0.0946158\ttotal: 2.31s\tremaining: 71.6ms\n",
      "97:\tlearn: 0.0943589\ttotal: 2.33s\tremaining: 47.6ms\n",
      "98:\tlearn: 0.0936458\ttotal: 2.35s\tremaining: 23.8ms\n",
      "99:\tlearn: 0.0931788\ttotal: 2.38s\tremaining: 0us\n",
      "0:\tlearn: 1.3065339\ttotal: 31.9ms\tremaining: 3.15s\n",
      "1:\tlearn: 1.1147316\ttotal: 58.8ms\tremaining: 2.88s\n",
      "2:\tlearn: 0.9750041\ttotal: 84.3ms\tremaining: 2.72s\n",
      "3:\tlearn: 0.8670682\ttotal: 109ms\tremaining: 2.61s\n",
      "4:\tlearn: 0.7761886\ttotal: 135ms\tremaining: 2.56s\n",
      "5:\tlearn: 0.7028453\ttotal: 161ms\tremaining: 2.53s\n",
      "6:\tlearn: 0.6423959\ttotal: 189ms\tremaining: 2.51s\n",
      "7:\tlearn: 0.5876456\ttotal: 216ms\tremaining: 2.48s\n",
      "8:\tlearn: 0.5423488\ttotal: 242ms\tremaining: 2.45s\n",
      "9:\tlearn: 0.5007407\ttotal: 269ms\tremaining: 2.42s\n",
      "10:\tlearn: 0.4651346\ttotal: 296ms\tremaining: 2.4s\n",
      "11:\tlearn: 0.4344946\ttotal: 324ms\tremaining: 2.37s\n",
      "12:\tlearn: 0.4070624\ttotal: 352ms\tremaining: 2.36s\n",
      "13:\tlearn: 0.3829205\ttotal: 380ms\tremaining: 2.33s\n",
      "14:\tlearn: 0.3618725\ttotal: 406ms\tremaining: 2.3s\n",
      "15:\tlearn: 0.3426793\ttotal: 433ms\tremaining: 2.27s\n",
      "16:\tlearn: 0.3237020\ttotal: 459ms\tremaining: 2.24s\n",
      "17:\tlearn: 0.3078481\ttotal: 485ms\tremaining: 2.21s\n",
      "18:\tlearn: 0.2951035\ttotal: 507ms\tremaining: 2.16s\n",
      "19:\tlearn: 0.2823803\ttotal: 531ms\tremaining: 2.12s\n",
      "20:\tlearn: 0.2697311\ttotal: 556ms\tremaining: 2.09s\n",
      "21:\tlearn: 0.2579314\ttotal: 580ms\tremaining: 2.06s\n",
      "22:\tlearn: 0.2487143\ttotal: 602ms\tremaining: 2.01s\n",
      "23:\tlearn: 0.2389835\ttotal: 624ms\tremaining: 1.98s\n",
      "24:\tlearn: 0.2297454\ttotal: 649ms\tremaining: 1.95s\n",
      "25:\tlearn: 0.2222803\ttotal: 673ms\tremaining: 1.91s\n",
      "26:\tlearn: 0.2154593\ttotal: 698ms\tremaining: 1.89s\n",
      "27:\tlearn: 0.2099271\ttotal: 724ms\tremaining: 1.86s\n",
      "28:\tlearn: 0.2036124\ttotal: 749ms\tremaining: 1.83s\n",
      "29:\tlearn: 0.1972672\ttotal: 775ms\tremaining: 1.81s\n",
      "30:\tlearn: 0.1918354\ttotal: 803ms\tremaining: 1.79s\n",
      "31:\tlearn: 0.1875890\ttotal: 828ms\tremaining: 1.76s\n",
      "32:\tlearn: 0.1835713\ttotal: 849ms\tremaining: 1.72s\n",
      "33:\tlearn: 0.1792124\ttotal: 873ms\tremaining: 1.69s\n",
      "34:\tlearn: 0.1741902\ttotal: 897ms\tremaining: 1.67s\n",
      "35:\tlearn: 0.1713859\ttotal: 920ms\tremaining: 1.64s\n",
      "36:\tlearn: 0.1679437\ttotal: 944ms\tremaining: 1.61s\n",
      "37:\tlearn: 0.1643572\ttotal: 967ms\tremaining: 1.58s\n",
      "38:\tlearn: 0.1606499\ttotal: 991ms\tremaining: 1.55s\n",
      "39:\tlearn: 0.1571241\ttotal: 1.02s\tremaining: 1.53s\n",
      "40:\tlearn: 0.1542137\ttotal: 1.05s\tremaining: 1.5s\n",
      "41:\tlearn: 0.1522725\ttotal: 1.07s\tremaining: 1.48s\n",
      "42:\tlearn: 0.1498013\ttotal: 1.09s\tremaining: 1.45s\n",
      "43:\tlearn: 0.1474954\ttotal: 1.12s\tremaining: 1.43s\n",
      "44:\tlearn: 0.1457451\ttotal: 1.15s\tremaining: 1.4s\n",
      "45:\tlearn: 0.1436644\ttotal: 1.17s\tremaining: 1.37s\n",
      "46:\tlearn: 0.1409044\ttotal: 1.2s\tremaining: 1.35s\n",
      "47:\tlearn: 0.1395994\ttotal: 1.22s\tremaining: 1.32s\n",
      "48:\tlearn: 0.1372661\ttotal: 1.25s\tremaining: 1.3s\n",
      "49:\tlearn: 0.1352730\ttotal: 1.27s\tremaining: 1.27s\n",
      "50:\tlearn: 0.1333959\ttotal: 1.3s\tremaining: 1.25s\n",
      "51:\tlearn: 0.1314597\ttotal: 1.32s\tremaining: 1.22s\n",
      "52:\tlearn: 0.1305725\ttotal: 1.35s\tremaining: 1.19s\n",
      "53:\tlearn: 0.1296806\ttotal: 1.37s\tremaining: 1.17s\n",
      "54:\tlearn: 0.1280069\ttotal: 1.39s\tremaining: 1.14s\n",
      "55:\tlearn: 0.1263427\ttotal: 1.42s\tremaining: 1.11s\n",
      "56:\tlearn: 0.1249594\ttotal: 1.44s\tremaining: 1.09s\n",
      "57:\tlearn: 0.1236144\ttotal: 1.47s\tremaining: 1.06s\n",
      "58:\tlearn: 0.1227841\ttotal: 1.48s\tremaining: 1.03s\n",
      "59:\tlearn: 0.1214793\ttotal: 1.51s\tremaining: 1s\n",
      "60:\tlearn: 0.1202532\ttotal: 1.53s\tremaining: 977ms\n",
      "61:\tlearn: 0.1193009\ttotal: 1.55s\tremaining: 950ms\n",
      "62:\tlearn: 0.1187127\ttotal: 1.57s\tremaining: 923ms\n",
      "63:\tlearn: 0.1175165\ttotal: 1.59s\tremaining: 897ms\n",
      "64:\tlearn: 0.1166672\ttotal: 1.62s\tremaining: 870ms\n",
      "65:\tlearn: 0.1159658\ttotal: 1.64s\tremaining: 843ms\n",
      "66:\tlearn: 0.1149712\ttotal: 1.66s\tremaining: 820ms\n",
      "67:\tlearn: 0.1141300\ttotal: 1.69s\tremaining: 794ms\n",
      "68:\tlearn: 0.1134371\ttotal: 1.71s\tremaining: 769ms\n",
      "69:\tlearn: 0.1130692\ttotal: 1.73s\tremaining: 743ms\n",
      "70:\tlearn: 0.1119736\ttotal: 1.76s\tremaining: 718ms\n",
      "71:\tlearn: 0.1108044\ttotal: 1.78s\tremaining: 693ms\n",
      "72:\tlearn: 0.1097826\ttotal: 1.81s\tremaining: 669ms\n",
      "73:\tlearn: 0.1088085\ttotal: 1.83s\tremaining: 644ms\n",
      "74:\tlearn: 0.1082213\ttotal: 1.85s\tremaining: 618ms\n",
      "75:\tlearn: 0.1078632\ttotal: 1.87s\tremaining: 592ms\n",
      "76:\tlearn: 0.1067164\ttotal: 1.9s\tremaining: 567ms\n",
      "77:\tlearn: 0.1058755\ttotal: 1.92s\tremaining: 543ms\n",
      "78:\tlearn: 0.1052708\ttotal: 1.95s\tremaining: 518ms\n",
      "79:\tlearn: 0.1045294\ttotal: 1.98s\tremaining: 494ms\n",
      "80:\tlearn: 0.1034154\ttotal: 2s\tremaining: 470ms\n",
      "81:\tlearn: 0.1028706\ttotal: 2.03s\tremaining: 446ms\n",
      "82:\tlearn: 0.1021694\ttotal: 2.06s\tremaining: 421ms\n",
      "83:\tlearn: 0.1018708\ttotal: 2.08s\tremaining: 396ms\n",
      "84:\tlearn: 0.1015850\ttotal: 2.1s\tremaining: 371ms\n",
      "85:\tlearn: 0.1008981\ttotal: 2.13s\tremaining: 347ms\n",
      "86:\tlearn: 0.1002893\ttotal: 2.16s\tremaining: 323ms\n",
      "87:\tlearn: 0.0999281\ttotal: 2.18s\tremaining: 297ms\n",
      "88:\tlearn: 0.0995287\ttotal: 2.2s\tremaining: 272ms\n",
      "89:\tlearn: 0.0989643\ttotal: 2.22s\tremaining: 247ms\n",
      "90:\tlearn: 0.0984377\ttotal: 2.25s\tremaining: 222ms\n",
      "91:\tlearn: 0.0978673\ttotal: 2.27s\tremaining: 198ms\n",
      "92:\tlearn: 0.0969289\ttotal: 2.29s\tremaining: 173ms\n",
      "93:\tlearn: 0.0964800\ttotal: 2.32s\tremaining: 148ms\n",
      "94:\tlearn: 0.0958393\ttotal: 2.34s\tremaining: 123ms\n",
      "95:\tlearn: 0.0952918\ttotal: 2.36s\tremaining: 98.5ms\n",
      "96:\tlearn: 0.0947778\ttotal: 2.39s\tremaining: 73.9ms\n",
      "97:\tlearn: 0.0943155\ttotal: 2.41s\tremaining: 49.3ms\n",
      "98:\tlearn: 0.0936491\ttotal: 2.44s\tremaining: 24.6ms\n",
      "99:\tlearn: 0.0932887\ttotal: 2.46s\tremaining: 0us\n",
      "0:\tlearn: 1.3072971\ttotal: 30.9ms\tremaining: 3.06s\n",
      "1:\tlearn: 1.1153226\ttotal: 55.2ms\tremaining: 2.71s\n",
      "2:\tlearn: 0.9753567\ttotal: 79.1ms\tremaining: 2.56s\n",
      "3:\tlearn: 0.8669056\ttotal: 103ms\tremaining: 2.48s\n",
      "4:\tlearn: 0.7759921\ttotal: 129ms\tremaining: 2.46s\n",
      "5:\tlearn: 0.7031276\ttotal: 154ms\tremaining: 2.41s\n",
      "6:\tlearn: 0.6430652\ttotal: 180ms\tremaining: 2.4s\n",
      "7:\tlearn: 0.5864127\ttotal: 207ms\tremaining: 2.38s\n",
      "8:\tlearn: 0.5413370\ttotal: 235ms\tremaining: 2.37s\n",
      "9:\tlearn: 0.5016872\ttotal: 262ms\tremaining: 2.35s\n",
      "10:\tlearn: 0.4665525\ttotal: 290ms\tremaining: 2.34s\n",
      "11:\tlearn: 0.4351775\ttotal: 314ms\tremaining: 2.3s\n",
      "12:\tlearn: 0.4074674\ttotal: 342ms\tremaining: 2.29s\n",
      "13:\tlearn: 0.3835881\ttotal: 369ms\tremaining: 2.27s\n",
      "14:\tlearn: 0.3605049\ttotal: 399ms\tremaining: 2.26s\n",
      "15:\tlearn: 0.3396482\ttotal: 427ms\tremaining: 2.24s\n",
      "16:\tlearn: 0.3217339\ttotal: 455ms\tremaining: 2.22s\n",
      "17:\tlearn: 0.3067651\ttotal: 484ms\tremaining: 2.2s\n",
      "18:\tlearn: 0.2939846\ttotal: 509ms\tremaining: 2.17s\n",
      "19:\tlearn: 0.2809672\ttotal: 537ms\tremaining: 2.15s\n",
      "20:\tlearn: 0.2693831\ttotal: 568ms\tremaining: 2.13s\n",
      "21:\tlearn: 0.2581658\ttotal: 599ms\tremaining: 2.12s\n",
      "22:\tlearn: 0.2480886\ttotal: 628ms\tremaining: 2.1s\n",
      "23:\tlearn: 0.2387674\ttotal: 655ms\tremaining: 2.07s\n",
      "24:\tlearn: 0.2305871\ttotal: 682ms\tremaining: 2.04s\n",
      "25:\tlearn: 0.2219189\ttotal: 709ms\tremaining: 2.02s\n",
      "26:\tlearn: 0.2141595\ttotal: 735ms\tremaining: 1.99s\n",
      "27:\tlearn: 0.2068608\ttotal: 759ms\tremaining: 1.95s\n",
      "28:\tlearn: 0.2008592\ttotal: 784ms\tremaining: 1.92s\n",
      "29:\tlearn: 0.1944361\ttotal: 810ms\tremaining: 1.89s\n",
      "30:\tlearn: 0.1893142\ttotal: 833ms\tremaining: 1.85s\n",
      "31:\tlearn: 0.1841922\ttotal: 857ms\tremaining: 1.82s\n",
      "32:\tlearn: 0.1791332\ttotal: 885ms\tremaining: 1.8s\n",
      "33:\tlearn: 0.1760032\ttotal: 908ms\tremaining: 1.76s\n",
      "34:\tlearn: 0.1718266\ttotal: 932ms\tremaining: 1.73s\n",
      "35:\tlearn: 0.1688975\ttotal: 958ms\tremaining: 1.7s\n",
      "36:\tlearn: 0.1657188\ttotal: 985ms\tremaining: 1.68s\n",
      "37:\tlearn: 0.1630171\ttotal: 1.01s\tremaining: 1.64s\n",
      "38:\tlearn: 0.1599115\ttotal: 1.03s\tremaining: 1.61s\n",
      "39:\tlearn: 0.1567109\ttotal: 1.06s\tremaining: 1.59s\n",
      "40:\tlearn: 0.1531543\ttotal: 1.09s\tremaining: 1.57s\n",
      "41:\tlearn: 0.1512307\ttotal: 1.11s\tremaining: 1.54s\n",
      "42:\tlearn: 0.1490361\ttotal: 1.13s\tremaining: 1.5s\n",
      "43:\tlearn: 0.1462242\ttotal: 1.16s\tremaining: 1.48s\n",
      "44:\tlearn: 0.1447597\ttotal: 1.18s\tremaining: 1.45s\n",
      "45:\tlearn: 0.1436384\ttotal: 1.21s\tremaining: 1.42s\n",
      "46:\tlearn: 0.1409807\ttotal: 1.24s\tremaining: 1.4s\n",
      "47:\tlearn: 0.1395225\ttotal: 1.26s\tremaining: 1.36s\n",
      "48:\tlearn: 0.1381717\ttotal: 1.28s\tremaining: 1.34s\n",
      "49:\tlearn: 0.1363995\ttotal: 1.31s\tremaining: 1.31s\n",
      "50:\tlearn: 0.1346029\ttotal: 1.33s\tremaining: 1.28s\n",
      "51:\tlearn: 0.1332824\ttotal: 1.35s\tremaining: 1.24s\n",
      "52:\tlearn: 0.1322044\ttotal: 1.36s\tremaining: 1.21s\n",
      "53:\tlearn: 0.1302887\ttotal: 1.38s\tremaining: 1.18s\n",
      "54:\tlearn: 0.1287745\ttotal: 1.4s\tremaining: 1.15s\n",
      "55:\tlearn: 0.1268164\ttotal: 1.42s\tremaining: 1.12s\n",
      "56:\tlearn: 0.1255607\ttotal: 1.45s\tremaining: 1.09s\n",
      "57:\tlearn: 0.1247998\ttotal: 1.47s\tremaining: 1.06s\n",
      "58:\tlearn: 0.1234047\ttotal: 1.49s\tremaining: 1.04s\n",
      "59:\tlearn: 0.1219280\ttotal: 1.52s\tremaining: 1.01s\n",
      "60:\tlearn: 0.1206933\ttotal: 1.55s\tremaining: 989ms\n",
      "61:\tlearn: 0.1196002\ttotal: 1.57s\tremaining: 965ms\n",
      "62:\tlearn: 0.1189367\ttotal: 1.6s\tremaining: 939ms\n",
      "63:\tlearn: 0.1181959\ttotal: 1.62s\tremaining: 914ms\n",
      "64:\tlearn: 0.1168544\ttotal: 1.65s\tremaining: 889ms\n",
      "65:\tlearn: 0.1161657\ttotal: 1.68s\tremaining: 864ms\n",
      "66:\tlearn: 0.1153985\ttotal: 1.7s\tremaining: 838ms\n",
      "67:\tlearn: 0.1142243\ttotal: 1.73s\tremaining: 813ms\n",
      "68:\tlearn: 0.1133235\ttotal: 1.75s\tremaining: 787ms\n",
      "69:\tlearn: 0.1121467\ttotal: 1.78s\tremaining: 762ms\n",
      "70:\tlearn: 0.1110525\ttotal: 1.81s\tremaining: 738ms\n",
      "71:\tlearn: 0.1101597\ttotal: 1.83s\tremaining: 714ms\n",
      "72:\tlearn: 0.1095425\ttotal: 1.86s\tremaining: 689ms\n",
      "73:\tlearn: 0.1088665\ttotal: 1.89s\tremaining: 664ms\n",
      "74:\tlearn: 0.1082879\ttotal: 1.92s\tremaining: 638ms\n",
      "75:\tlearn: 0.1075651\ttotal: 1.94s\tremaining: 612ms\n",
      "76:\tlearn: 0.1066618\ttotal: 1.96s\tremaining: 586ms\n",
      "77:\tlearn: 0.1058768\ttotal: 1.99s\tremaining: 560ms\n",
      "78:\tlearn: 0.1049311\ttotal: 2.01s\tremaining: 535ms\n",
      "79:\tlearn: 0.1043648\ttotal: 2.03s\tremaining: 509ms\n",
      "80:\tlearn: 0.1034791\ttotal: 2.06s\tremaining: 483ms\n",
      "81:\tlearn: 0.1027980\ttotal: 2.08s\tremaining: 457ms\n",
      "82:\tlearn: 0.1022212\ttotal: 2.1s\tremaining: 431ms\n",
      "83:\tlearn: 0.1019097\ttotal: 2.12s\tremaining: 405ms\n",
      "84:\tlearn: 0.1011389\ttotal: 2.15s\tremaining: 379ms\n",
      "85:\tlearn: 0.1005399\ttotal: 2.18s\tremaining: 354ms\n",
      "86:\tlearn: 0.1002497\ttotal: 2.2s\tremaining: 329ms\n",
      "87:\tlearn: 0.0996243\ttotal: 2.22s\tremaining: 303ms\n",
      "88:\tlearn: 0.0990975\ttotal: 2.25s\tremaining: 278ms\n",
      "89:\tlearn: 0.0987900\ttotal: 2.27s\tremaining: 253ms\n",
      "90:\tlearn: 0.0981178\ttotal: 2.3s\tremaining: 227ms\n",
      "91:\tlearn: 0.0973746\ttotal: 2.32s\tremaining: 202ms\n",
      "92:\tlearn: 0.0966996\ttotal: 2.35s\tremaining: 177ms\n",
      "93:\tlearn: 0.0962004\ttotal: 2.37s\tremaining: 151ms\n",
      "94:\tlearn: 0.0956162\ttotal: 2.4s\tremaining: 126ms\n",
      "95:\tlearn: 0.0951395\ttotal: 2.42s\tremaining: 101ms\n",
      "96:\tlearn: 0.0945695\ttotal: 2.45s\tremaining: 75.7ms\n",
      "97:\tlearn: 0.0942760\ttotal: 2.47s\tremaining: 50.4ms\n",
      "98:\tlearn: 0.0935322\ttotal: 2.5s\tremaining: 25.2ms\n",
      "99:\tlearn: 0.0931048\ttotal: 2.52s\tremaining: 0us\n",
      "0:\tlearn: 1.3161231\ttotal: 29.8ms\tremaining: 2.95s\n",
      "1:\tlearn: 1.1178996\ttotal: 55.7ms\tremaining: 2.73s\n",
      "2:\tlearn: 0.9764242\ttotal: 81.1ms\tremaining: 2.62s\n",
      "3:\tlearn: 0.8669848\ttotal: 105ms\tremaining: 2.53s\n",
      "4:\tlearn: 0.7748515\ttotal: 133ms\tremaining: 2.53s\n",
      "5:\tlearn: 0.7015684\ttotal: 159ms\tremaining: 2.49s\n",
      "6:\tlearn: 0.6400991\ttotal: 185ms\tremaining: 2.46s\n",
      "7:\tlearn: 0.5834801\ttotal: 211ms\tremaining: 2.42s\n",
      "8:\tlearn: 0.5372421\ttotal: 235ms\tremaining: 2.38s\n",
      "9:\tlearn: 0.4961353\ttotal: 261ms\tremaining: 2.35s\n",
      "10:\tlearn: 0.4625501\ttotal: 286ms\tremaining: 2.32s\n",
      "11:\tlearn: 0.4319567\ttotal: 311ms\tremaining: 2.28s\n",
      "12:\tlearn: 0.4057354\ttotal: 337ms\tremaining: 2.26s\n",
      "13:\tlearn: 0.3816141\ttotal: 361ms\tremaining: 2.22s\n",
      "14:\tlearn: 0.3600066\ttotal: 385ms\tremaining: 2.18s\n",
      "15:\tlearn: 0.3391398\ttotal: 409ms\tremaining: 2.15s\n",
      "16:\tlearn: 0.3222179\ttotal: 433ms\tremaining: 2.12s\n",
      "17:\tlearn: 0.3064268\ttotal: 456ms\tremaining: 2.08s\n",
      "18:\tlearn: 0.2932692\ttotal: 481ms\tremaining: 2.05s\n",
      "19:\tlearn: 0.2797345\ttotal: 508ms\tremaining: 2.03s\n",
      "20:\tlearn: 0.2679362\ttotal: 535ms\tremaining: 2.01s\n",
      "21:\tlearn: 0.2565421\ttotal: 562ms\tremaining: 1.99s\n",
      "22:\tlearn: 0.2467657\ttotal: 588ms\tremaining: 1.97s\n",
      "23:\tlearn: 0.2375547\ttotal: 615ms\tremaining: 1.95s\n",
      "24:\tlearn: 0.2283486\ttotal: 642ms\tremaining: 1.93s\n",
      "25:\tlearn: 0.2208547\ttotal: 667ms\tremaining: 1.9s\n",
      "26:\tlearn: 0.2131809\ttotal: 694ms\tremaining: 1.88s\n",
      "27:\tlearn: 0.2062991\ttotal: 722ms\tremaining: 1.86s\n",
      "28:\tlearn: 0.2005652\ttotal: 751ms\tremaining: 1.84s\n",
      "29:\tlearn: 0.1960489\ttotal: 779ms\tremaining: 1.82s\n",
      "30:\tlearn: 0.1905239\ttotal: 808ms\tremaining: 1.8s\n",
      "31:\tlearn: 0.1853849\ttotal: 837ms\tremaining: 1.78s\n",
      "32:\tlearn: 0.1808672\ttotal: 863ms\tremaining: 1.75s\n",
      "33:\tlearn: 0.1758215\ttotal: 889ms\tremaining: 1.73s\n",
      "34:\tlearn: 0.1708311\ttotal: 920ms\tremaining: 1.71s\n",
      "35:\tlearn: 0.1681234\ttotal: 946ms\tremaining: 1.68s\n",
      "36:\tlearn: 0.1647968\ttotal: 971ms\tremaining: 1.65s\n",
      "37:\tlearn: 0.1615628\ttotal: 996ms\tremaining: 1.63s\n",
      "38:\tlearn: 0.1585388\ttotal: 1.02s\tremaining: 1.6s\n",
      "39:\tlearn: 0.1558294\ttotal: 1.05s\tremaining: 1.58s\n",
      "40:\tlearn: 0.1527493\ttotal: 1.08s\tremaining: 1.55s\n",
      "41:\tlearn: 0.1508194\ttotal: 1.1s\tremaining: 1.52s\n",
      "42:\tlearn: 0.1481237\ttotal: 1.13s\tremaining: 1.5s\n",
      "43:\tlearn: 0.1461668\ttotal: 1.15s\tremaining: 1.47s\n",
      "44:\tlearn: 0.1444775\ttotal: 1.17s\tremaining: 1.43s\n",
      "45:\tlearn: 0.1426497\ttotal: 1.2s\tremaining: 1.4s\n",
      "46:\tlearn: 0.1400627\ttotal: 1.22s\tremaining: 1.37s\n",
      "47:\tlearn: 0.1381227\ttotal: 1.24s\tremaining: 1.35s\n",
      "48:\tlearn: 0.1364971\ttotal: 1.27s\tremaining: 1.32s\n",
      "49:\tlearn: 0.1352205\ttotal: 1.29s\tremaining: 1.29s\n",
      "50:\tlearn: 0.1340617\ttotal: 1.31s\tremaining: 1.26s\n",
      "51:\tlearn: 0.1329968\ttotal: 1.33s\tremaining: 1.23s\n",
      "52:\tlearn: 0.1313456\ttotal: 1.35s\tremaining: 1.2s\n",
      "53:\tlearn: 0.1301318\ttotal: 1.37s\tremaining: 1.17s\n",
      "54:\tlearn: 0.1284969\ttotal: 1.39s\tremaining: 1.14s\n",
      "55:\tlearn: 0.1273232\ttotal: 1.41s\tremaining: 1.11s\n",
      "56:\tlearn: 0.1251862\ttotal: 1.44s\tremaining: 1.09s\n",
      "57:\tlearn: 0.1236421\ttotal: 1.47s\tremaining: 1.06s\n",
      "58:\tlearn: 0.1226743\ttotal: 1.49s\tremaining: 1.04s\n",
      "59:\tlearn: 0.1216355\ttotal: 1.51s\tremaining: 1.01s\n",
      "60:\tlearn: 0.1203940\ttotal: 1.54s\tremaining: 984ms\n",
      "61:\tlearn: 0.1193061\ttotal: 1.56s\tremaining: 958ms\n",
      "62:\tlearn: 0.1179077\ttotal: 1.58s\tremaining: 931ms\n",
      "63:\tlearn: 0.1169855\ttotal: 1.61s\tremaining: 905ms\n",
      "64:\tlearn: 0.1158368\ttotal: 1.63s\tremaining: 880ms\n",
      "65:\tlearn: 0.1144990\ttotal: 1.66s\tremaining: 854ms\n",
      "66:\tlearn: 0.1134657\ttotal: 1.68s\tremaining: 829ms\n",
      "67:\tlearn: 0.1128130\ttotal: 1.71s\tremaining: 803ms\n",
      "68:\tlearn: 0.1122200\ttotal: 1.73s\tremaining: 778ms\n",
      "69:\tlearn: 0.1110555\ttotal: 1.76s\tremaining: 753ms\n",
      "70:\tlearn: 0.1102536\ttotal: 1.78s\tremaining: 728ms\n",
      "71:\tlearn: 0.1094407\ttotal: 1.81s\tremaining: 704ms\n",
      "72:\tlearn: 0.1089773\ttotal: 1.83s\tremaining: 678ms\n",
      "73:\tlearn: 0.1080050\ttotal: 1.86s\tremaining: 653ms\n",
      "74:\tlearn: 0.1075190\ttotal: 1.88s\tremaining: 628ms\n",
      "75:\tlearn: 0.1068231\ttotal: 1.91s\tremaining: 602ms\n",
      "76:\tlearn: 0.1057433\ttotal: 1.93s\tremaining: 578ms\n",
      "77:\tlearn: 0.1051999\ttotal: 1.96s\tremaining: 552ms\n",
      "78:\tlearn: 0.1046491\ttotal: 1.98s\tremaining: 526ms\n",
      "79:\tlearn: 0.1041706\ttotal: 2s\tremaining: 500ms\n",
      "80:\tlearn: 0.1034120\ttotal: 2.02s\tremaining: 474ms\n",
      "81:\tlearn: 0.1030491\ttotal: 2.04s\tremaining: 448ms\n",
      "82:\tlearn: 0.1023841\ttotal: 2.07s\tremaining: 423ms\n",
      "83:\tlearn: 0.1021100\ttotal: 2.09s\tremaining: 398ms\n",
      "84:\tlearn: 0.1013449\ttotal: 2.11s\tremaining: 372ms\n",
      "85:\tlearn: 0.1008287\ttotal: 2.13s\tremaining: 348ms\n",
      "86:\tlearn: 0.1002563\ttotal: 2.16s\tremaining: 323ms\n",
      "87:\tlearn: 0.0996502\ttotal: 2.19s\tremaining: 298ms\n",
      "88:\tlearn: 0.0988431\ttotal: 2.21s\tremaining: 273ms\n",
      "89:\tlearn: 0.0982366\ttotal: 2.24s\tremaining: 249ms\n",
      "90:\tlearn: 0.0975586\ttotal: 2.26s\tremaining: 224ms\n",
      "91:\tlearn: 0.0970776\ttotal: 2.29s\tremaining: 199ms\n",
      "92:\tlearn: 0.0963347\ttotal: 2.31s\tremaining: 174ms\n",
      "93:\tlearn: 0.0961466\ttotal: 2.34s\tremaining: 149ms\n",
      "94:\tlearn: 0.0955709\ttotal: 2.36s\tremaining: 124ms\n",
      "95:\tlearn: 0.0952136\ttotal: 2.38s\tremaining: 99.4ms\n",
      "96:\tlearn: 0.0947245\ttotal: 2.41s\tremaining: 74.4ms\n",
      "97:\tlearn: 0.0944926\ttotal: 2.43s\tremaining: 49.6ms\n",
      "98:\tlearn: 0.0937234\ttotal: 2.45s\tremaining: 24.8ms\n",
      "99:\tlearn: 0.0933670\ttotal: 2.47s\tremaining: 0us\n",
      "0:\tlearn: 1.3062139\ttotal: 29.8ms\tremaining: 2.95s\n",
      "1:\tlearn: 1.1120977\ttotal: 55.8ms\tremaining: 2.73s\n",
      "2:\tlearn: 0.9721889\ttotal: 82.5ms\tremaining: 2.67s\n",
      "3:\tlearn: 0.8637787\ttotal: 107ms\tremaining: 2.56s\n",
      "4:\tlearn: 0.7729277\ttotal: 133ms\tremaining: 2.52s\n",
      "5:\tlearn: 0.6991085\ttotal: 157ms\tremaining: 2.46s\n",
      "6:\tlearn: 0.6360588\ttotal: 182ms\tremaining: 2.42s\n",
      "7:\tlearn: 0.5811807\ttotal: 209ms\tremaining: 2.4s\n",
      "8:\tlearn: 0.5378724\ttotal: 236ms\tremaining: 2.38s\n",
      "9:\tlearn: 0.4986860\ttotal: 260ms\tremaining: 2.34s\n",
      "10:\tlearn: 0.4642252\ttotal: 284ms\tremaining: 2.3s\n",
      "11:\tlearn: 0.4337424\ttotal: 303ms\tremaining: 2.22s\n",
      "12:\tlearn: 0.4025737\ttotal: 327ms\tremaining: 2.19s\n",
      "13:\tlearn: 0.3783161\ttotal: 352ms\tremaining: 2.16s\n",
      "14:\tlearn: 0.3566539\ttotal: 376ms\tremaining: 2.13s\n",
      "15:\tlearn: 0.3363822\ttotal: 401ms\tremaining: 2.1s\n",
      "16:\tlearn: 0.3200881\ttotal: 424ms\tremaining: 2.07s\n",
      "17:\tlearn: 0.3050281\ttotal: 446ms\tremaining: 2.03s\n",
      "18:\tlearn: 0.2910670\ttotal: 470ms\tremaining: 2s\n",
      "19:\tlearn: 0.2785523\ttotal: 493ms\tremaining: 1.97s\n",
      "20:\tlearn: 0.2681279\ttotal: 517ms\tremaining: 1.94s\n",
      "21:\tlearn: 0.2564655\ttotal: 540ms\tremaining: 1.92s\n",
      "22:\tlearn: 0.2463606\ttotal: 562ms\tremaining: 1.88s\n",
      "23:\tlearn: 0.2356014\ttotal: 585ms\tremaining: 1.85s\n",
      "24:\tlearn: 0.2276111\ttotal: 605ms\tremaining: 1.82s\n",
      "25:\tlearn: 0.2207153\ttotal: 630ms\tremaining: 1.79s\n",
      "26:\tlearn: 0.2136629\ttotal: 655ms\tremaining: 1.77s\n",
      "27:\tlearn: 0.2081862\ttotal: 678ms\tremaining: 1.74s\n",
      "28:\tlearn: 0.2030349\ttotal: 698ms\tremaining: 1.71s\n",
      "29:\tlearn: 0.1967207\ttotal: 717ms\tremaining: 1.67s\n",
      "30:\tlearn: 0.1917608\ttotal: 734ms\tremaining: 1.63s\n",
      "31:\tlearn: 0.1876462\ttotal: 756ms\tremaining: 1.61s\n",
      "32:\tlearn: 0.1822097\ttotal: 780ms\tremaining: 1.58s\n",
      "33:\tlearn: 0.1782698\ttotal: 802ms\tremaining: 1.56s\n",
      "34:\tlearn: 0.1743574\ttotal: 828ms\tremaining: 1.54s\n",
      "35:\tlearn: 0.1711299\ttotal: 854ms\tremaining: 1.52s\n",
      "36:\tlearn: 0.1671468\ttotal: 881ms\tremaining: 1.5s\n",
      "37:\tlearn: 0.1637448\ttotal: 906ms\tremaining: 1.48s\n",
      "38:\tlearn: 0.1611407\ttotal: 932ms\tremaining: 1.46s\n",
      "39:\tlearn: 0.1584336\ttotal: 958ms\tremaining: 1.44s\n",
      "40:\tlearn: 0.1560158\ttotal: 983ms\tremaining: 1.41s\n",
      "41:\tlearn: 0.1538170\ttotal: 1s\tremaining: 1.39s\n",
      "42:\tlearn: 0.1509253\ttotal: 1.03s\tremaining: 1.36s\n",
      "43:\tlearn: 0.1491401\ttotal: 1.05s\tremaining: 1.34s\n",
      "44:\tlearn: 0.1471078\ttotal: 1.07s\tremaining: 1.31s\n",
      "45:\tlearn: 0.1448771\ttotal: 1.1s\tremaining: 1.29s\n",
      "46:\tlearn: 0.1434868\ttotal: 1.12s\tremaining: 1.26s\n",
      "47:\tlearn: 0.1421660\ttotal: 1.14s\tremaining: 1.24s\n",
      "48:\tlearn: 0.1410792\ttotal: 1.16s\tremaining: 1.21s\n",
      "49:\tlearn: 0.1387484\ttotal: 1.19s\tremaining: 1.19s\n",
      "50:\tlearn: 0.1364596\ttotal: 1.22s\tremaining: 1.17s\n",
      "51:\tlearn: 0.1353845\ttotal: 1.24s\tremaining: 1.14s\n",
      "52:\tlearn: 0.1336221\ttotal: 1.27s\tremaining: 1.12s\n",
      "53:\tlearn: 0.1319136\ttotal: 1.29s\tremaining: 1.1s\n",
      "54:\tlearn: 0.1307596\ttotal: 1.31s\tremaining: 1.07s\n",
      "55:\tlearn: 0.1294212\ttotal: 1.32s\tremaining: 1.04s\n",
      "56:\tlearn: 0.1279865\ttotal: 1.35s\tremaining: 1.01s\n",
      "57:\tlearn: 0.1264119\ttotal: 1.37s\tremaining: 991ms\n",
      "58:\tlearn: 0.1252247\ttotal: 1.39s\tremaining: 966ms\n",
      "59:\tlearn: 0.1237431\ttotal: 1.41s\tremaining: 943ms\n",
      "60:\tlearn: 0.1223572\ttotal: 1.44s\tremaining: 920ms\n",
      "61:\tlearn: 0.1212121\ttotal: 1.46s\tremaining: 896ms\n",
      "62:\tlearn: 0.1198915\ttotal: 1.49s\tremaining: 873ms\n",
      "63:\tlearn: 0.1188303\ttotal: 1.51s\tremaining: 849ms\n",
      "64:\tlearn: 0.1182061\ttotal: 1.53s\tremaining: 824ms\n",
      "65:\tlearn: 0.1172452\ttotal: 1.55s\tremaining: 800ms\n",
      "66:\tlearn: 0.1160291\ttotal: 1.58s\tremaining: 777ms\n",
      "67:\tlearn: 0.1152544\ttotal: 1.6s\tremaining: 753ms\n",
      "68:\tlearn: 0.1142732\ttotal: 1.62s\tremaining: 730ms\n",
      "69:\tlearn: 0.1133646\ttotal: 1.65s\tremaining: 706ms\n",
      "70:\tlearn: 0.1120991\ttotal: 1.67s\tremaining: 684ms\n",
      "71:\tlearn: 0.1115513\ttotal: 1.7s\tremaining: 660ms\n",
      "72:\tlearn: 0.1111976\ttotal: 1.72s\tremaining: 636ms\n",
      "73:\tlearn: 0.1102558\ttotal: 1.75s\tremaining: 613ms\n",
      "74:\tlearn: 0.1094865\ttotal: 1.77s\tremaining: 591ms\n",
      "75:\tlearn: 0.1088175\ttotal: 1.79s\tremaining: 567ms\n",
      "76:\tlearn: 0.1077997\ttotal: 1.82s\tremaining: 544ms\n",
      "77:\tlearn: 0.1072645\ttotal: 1.84s\tremaining: 520ms\n",
      "78:\tlearn: 0.1068121\ttotal: 1.87s\tremaining: 497ms\n",
      "79:\tlearn: 0.1058381\ttotal: 1.9s\tremaining: 474ms\n",
      "80:\tlearn: 0.1051365\ttotal: 1.92s\tremaining: 451ms\n",
      "81:\tlearn: 0.1047370\ttotal: 1.95s\tremaining: 428ms\n",
      "82:\tlearn: 0.1041631\ttotal: 1.97s\tremaining: 404ms\n",
      "83:\tlearn: 0.1038252\ttotal: 2s\tremaining: 380ms\n",
      "84:\tlearn: 0.1034824\ttotal: 2.02s\tremaining: 356ms\n",
      "85:\tlearn: 0.1027584\ttotal: 2.04s\tremaining: 332ms\n",
      "86:\tlearn: 0.1020373\ttotal: 2.07s\tremaining: 309ms\n",
      "87:\tlearn: 0.1013560\ttotal: 2.09s\tremaining: 285ms\n",
      "88:\tlearn: 0.1006699\ttotal: 2.12s\tremaining: 262ms\n",
      "89:\tlearn: 0.1001659\ttotal: 2.15s\tremaining: 238ms\n",
      "90:\tlearn: 0.0996784\ttotal: 2.17s\tremaining: 214ms\n",
      "91:\tlearn: 0.0991569\ttotal: 2.19s\tremaining: 191ms\n",
      "92:\tlearn: 0.0984641\ttotal: 2.22s\tremaining: 167ms\n",
      "93:\tlearn: 0.0977394\ttotal: 2.24s\tremaining: 143ms\n",
      "94:\tlearn: 0.0969958\ttotal: 2.26s\tremaining: 119ms\n",
      "95:\tlearn: 0.0967542\ttotal: 2.29s\tremaining: 95.3ms\n",
      "96:\tlearn: 0.0960341\ttotal: 2.31s\tremaining: 71.6ms\n",
      "97:\tlearn: 0.0956263\ttotal: 2.34s\tremaining: 47.7ms\n",
      "98:\tlearn: 0.0951856\ttotal: 2.36s\tremaining: 23.9ms\n",
      "99:\tlearn: 0.0947111\ttotal: 2.39s\tremaining: 0us\n",
      "0:\tlearn: 1.3182663\ttotal: 29.3ms\tremaining: 2.9s\n",
      "1:\tlearn: 1.1223623\ttotal: 53.4ms\tremaining: 2.62s\n",
      "2:\tlearn: 0.9809922\ttotal: 77.7ms\tremaining: 2.51s\n",
      "3:\tlearn: 0.8718933\ttotal: 101ms\tremaining: 2.43s\n",
      "4:\tlearn: 0.7843371\ttotal: 129ms\tremaining: 2.45s\n",
      "5:\tlearn: 0.7087070\ttotal: 154ms\tremaining: 2.41s\n",
      "6:\tlearn: 0.6462029\ttotal: 182ms\tremaining: 2.42s\n",
      "7:\tlearn: 0.5889066\ttotal: 209ms\tremaining: 2.4s\n",
      "8:\tlearn: 0.5433670\ttotal: 236ms\tremaining: 2.39s\n",
      "9:\tlearn: 0.5033793\ttotal: 264ms\tremaining: 2.38s\n",
      "10:\tlearn: 0.4686574\ttotal: 295ms\tremaining: 2.38s\n",
      "11:\tlearn: 0.4378817\ttotal: 320ms\tremaining: 2.35s\n",
      "12:\tlearn: 0.4126895\ttotal: 345ms\tremaining: 2.31s\n",
      "13:\tlearn: 0.3885067\ttotal: 373ms\tremaining: 2.29s\n",
      "14:\tlearn: 0.3664679\ttotal: 399ms\tremaining: 2.26s\n",
      "15:\tlearn: 0.3474107\ttotal: 424ms\tremaining: 2.23s\n",
      "16:\tlearn: 0.3283935\ttotal: 453ms\tremaining: 2.21s\n",
      "17:\tlearn: 0.3130622\ttotal: 478ms\tremaining: 2.18s\n",
      "18:\tlearn: 0.2991166\ttotal: 503ms\tremaining: 2.15s\n",
      "19:\tlearn: 0.2846048\ttotal: 529ms\tremaining: 2.12s\n",
      "20:\tlearn: 0.2725411\ttotal: 556ms\tremaining: 2.09s\n",
      "21:\tlearn: 0.2615765\ttotal: 584ms\tremaining: 2.07s\n",
      "22:\tlearn: 0.2519937\ttotal: 611ms\tremaining: 2.05s\n",
      "23:\tlearn: 0.2424278\ttotal: 637ms\tremaining: 2.02s\n",
      "24:\tlearn: 0.2331125\ttotal: 662ms\tremaining: 1.98s\n",
      "25:\tlearn: 0.2258395\ttotal: 686ms\tremaining: 1.95s\n",
      "26:\tlearn: 0.2176302\ttotal: 714ms\tremaining: 1.93s\n",
      "27:\tlearn: 0.2109627\ttotal: 740ms\tremaining: 1.9s\n",
      "28:\tlearn: 0.2057660\ttotal: 765ms\tremaining: 1.87s\n",
      "29:\tlearn: 0.2001241\ttotal: 789ms\tremaining: 1.84s\n",
      "30:\tlearn: 0.1950306\ttotal: 811ms\tremaining: 1.8s\n",
      "31:\tlearn: 0.1903624\ttotal: 835ms\tremaining: 1.77s\n",
      "32:\tlearn: 0.1866640\ttotal: 857ms\tremaining: 1.74s\n",
      "33:\tlearn: 0.1816722\ttotal: 883ms\tremaining: 1.71s\n",
      "34:\tlearn: 0.1767804\ttotal: 910ms\tremaining: 1.69s\n",
      "35:\tlearn: 0.1732011\ttotal: 934ms\tremaining: 1.66s\n",
      "36:\tlearn: 0.1695005\ttotal: 960ms\tremaining: 1.64s\n",
      "37:\tlearn: 0.1668923\ttotal: 985ms\tremaining: 1.61s\n",
      "38:\tlearn: 0.1634801\ttotal: 1.01s\tremaining: 1.58s\n",
      "39:\tlearn: 0.1598666\ttotal: 1.04s\tremaining: 1.56s\n",
      "40:\tlearn: 0.1565721\ttotal: 1.07s\tremaining: 1.53s\n",
      "41:\tlearn: 0.1545001\ttotal: 1.09s\tremaining: 1.5s\n",
      "42:\tlearn: 0.1522830\ttotal: 1.12s\tremaining: 1.48s\n",
      "43:\tlearn: 0.1498714\ttotal: 1.14s\tremaining: 1.46s\n",
      "44:\tlearn: 0.1471688\ttotal: 1.17s\tremaining: 1.43s\n",
      "45:\tlearn: 0.1447193\ttotal: 1.19s\tremaining: 1.4s\n",
      "46:\tlearn: 0.1430602\ttotal: 1.22s\tremaining: 1.37s\n",
      "47:\tlearn: 0.1410368\ttotal: 1.24s\tremaining: 1.34s\n",
      "48:\tlearn: 0.1390416\ttotal: 1.26s\tremaining: 1.31s\n",
      "49:\tlearn: 0.1374603\ttotal: 1.29s\tremaining: 1.29s\n",
      "50:\tlearn: 0.1352035\ttotal: 1.32s\tremaining: 1.26s\n",
      "51:\tlearn: 0.1337036\ttotal: 1.34s\tremaining: 1.24s\n",
      "52:\tlearn: 0.1318575\ttotal: 1.36s\tremaining: 1.21s\n",
      "53:\tlearn: 0.1302953\ttotal: 1.39s\tremaining: 1.18s\n",
      "54:\tlearn: 0.1288062\ttotal: 1.42s\tremaining: 1.16s\n",
      "55:\tlearn: 0.1273939\ttotal: 1.44s\tremaining: 1.13s\n",
      "56:\tlearn: 0.1258322\ttotal: 1.46s\tremaining: 1.1s\n",
      "57:\tlearn: 0.1241762\ttotal: 1.49s\tremaining: 1.08s\n",
      "58:\tlearn: 0.1229188\ttotal: 1.51s\tremaining: 1.05s\n",
      "59:\tlearn: 0.1220595\ttotal: 1.54s\tremaining: 1.02s\n",
      "60:\tlearn: 0.1208052\ttotal: 1.56s\tremaining: 996ms\n",
      "61:\tlearn: 0.1195910\ttotal: 1.58s\tremaining: 970ms\n",
      "62:\tlearn: 0.1189306\ttotal: 1.6s\tremaining: 942ms\n",
      "63:\tlearn: 0.1179608\ttotal: 1.63s\tremaining: 915ms\n",
      "64:\tlearn: 0.1172417\ttotal: 1.65s\tremaining: 886ms\n",
      "65:\tlearn: 0.1165302\ttotal: 1.67s\tremaining: 858ms\n",
      "66:\tlearn: 0.1155087\ttotal: 1.69s\tremaining: 832ms\n",
      "67:\tlearn: 0.1146657\ttotal: 1.71s\tremaining: 805ms\n",
      "68:\tlearn: 0.1135574\ttotal: 1.74s\tremaining: 780ms\n",
      "69:\tlearn: 0.1128810\ttotal: 1.76s\tremaining: 753ms\n",
      "70:\tlearn: 0.1116843\ttotal: 1.78s\tremaining: 728ms\n",
      "71:\tlearn: 0.1111284\ttotal: 1.8s\tremaining: 702ms\n",
      "72:\tlearn: 0.1106154\ttotal: 1.82s\tremaining: 675ms\n",
      "73:\tlearn: 0.1100323\ttotal: 1.85s\tremaining: 650ms\n",
      "74:\tlearn: 0.1096333\ttotal: 1.87s\tremaining: 623ms\n",
      "75:\tlearn: 0.1088507\ttotal: 1.89s\tremaining: 597ms\n",
      "76:\tlearn: 0.1078680\ttotal: 1.92s\tremaining: 572ms\n",
      "77:\tlearn: 0.1070811\ttotal: 1.94s\tremaining: 547ms\n",
      "78:\tlearn: 0.1066622\ttotal: 1.96s\tremaining: 521ms\n",
      "79:\tlearn: 0.1055592\ttotal: 1.98s\tremaining: 496ms\n",
      "80:\tlearn: 0.1048500\ttotal: 2.01s\tremaining: 472ms\n",
      "81:\tlearn: 0.1044562\ttotal: 2.03s\tremaining: 446ms\n",
      "82:\tlearn: 0.1037113\ttotal: 2.06s\tremaining: 421ms\n",
      "83:\tlearn: 0.1034295\ttotal: 2.08s\tremaining: 396ms\n",
      "84:\tlearn: 0.1025774\ttotal: 2.1s\tremaining: 371ms\n",
      "85:\tlearn: 0.1018973\ttotal: 2.13s\tremaining: 347ms\n",
      "86:\tlearn: 0.1014990\ttotal: 2.15s\tremaining: 322ms\n",
      "87:\tlearn: 0.1008208\ttotal: 2.18s\tremaining: 297ms\n",
      "88:\tlearn: 0.1000845\ttotal: 2.2s\tremaining: 272ms\n",
      "89:\tlearn: 0.0996939\ttotal: 2.23s\tremaining: 248ms\n",
      "90:\tlearn: 0.0993537\ttotal: 2.25s\tremaining: 223ms\n",
      "91:\tlearn: 0.0986091\ttotal: 2.28s\tremaining: 198ms\n",
      "92:\tlearn: 0.0981481\ttotal: 2.3s\tremaining: 173ms\n",
      "93:\tlearn: 0.0976957\ttotal: 2.32s\tremaining: 148ms\n",
      "94:\tlearn: 0.0970283\ttotal: 2.35s\tremaining: 124ms\n",
      "95:\tlearn: 0.0965166\ttotal: 2.37s\tremaining: 98.8ms\n",
      "96:\tlearn: 0.0959331\ttotal: 2.4s\tremaining: 74.2ms\n",
      "97:\tlearn: 0.0951586\ttotal: 2.42s\tremaining: 49.5ms\n",
      "98:\tlearn: 0.0947393\ttotal: 2.45s\tremaining: 24.8ms\n",
      "99:\tlearn: 0.0941437\ttotal: 2.48s\tremaining: 0us\n",
      "0:\tlearn: 1.3067753\ttotal: 30.7ms\tremaining: 3.04s\n",
      "1:\tlearn: 1.1147650\ttotal: 56.3ms\tremaining: 2.76s\n",
      "2:\tlearn: 0.9749443\ttotal: 82ms\tremaining: 2.65s\n",
      "3:\tlearn: 0.8672241\ttotal: 107ms\tremaining: 2.58s\n",
      "4:\tlearn: 0.7775479\ttotal: 135ms\tremaining: 2.56s\n",
      "5:\tlearn: 0.7030737\ttotal: 159ms\tremaining: 2.5s\n",
      "6:\tlearn: 0.6430352\ttotal: 186ms\tremaining: 2.48s\n",
      "7:\tlearn: 0.5877598\ttotal: 215ms\tremaining: 2.47s\n",
      "8:\tlearn: 0.5396726\ttotal: 242ms\tremaining: 2.45s\n",
      "9:\tlearn: 0.4992373\ttotal: 270ms\tremaining: 2.43s\n",
      "10:\tlearn: 0.4675956\ttotal: 295ms\tremaining: 2.39s\n",
      "11:\tlearn: 0.4373714\ttotal: 320ms\tremaining: 2.35s\n",
      "12:\tlearn: 0.4104062\ttotal: 349ms\tremaining: 2.34s\n",
      "13:\tlearn: 0.3866142\ttotal: 376ms\tremaining: 2.31s\n",
      "14:\tlearn: 0.3645458\ttotal: 402ms\tremaining: 2.28s\n",
      "15:\tlearn: 0.3434077\ttotal: 427ms\tremaining: 2.24s\n",
      "16:\tlearn: 0.3265041\ttotal: 453ms\tremaining: 2.21s\n",
      "17:\tlearn: 0.3109584\ttotal: 479ms\tremaining: 2.18s\n",
      "18:\tlearn: 0.2981651\ttotal: 502ms\tremaining: 2.14s\n",
      "19:\tlearn: 0.2851095\ttotal: 528ms\tremaining: 2.11s\n",
      "20:\tlearn: 0.2720264\ttotal: 555ms\tremaining: 2.09s\n",
      "21:\tlearn: 0.2611355\ttotal: 582ms\tremaining: 2.06s\n",
      "22:\tlearn: 0.2500232\ttotal: 606ms\tremaining: 2.03s\n",
      "23:\tlearn: 0.2404171\ttotal: 631ms\tremaining: 2s\n",
      "24:\tlearn: 0.2320380\ttotal: 656ms\tremaining: 1.97s\n",
      "25:\tlearn: 0.2245971\ttotal: 681ms\tremaining: 1.94s\n",
      "26:\tlearn: 0.2162426\ttotal: 706ms\tremaining: 1.91s\n",
      "27:\tlearn: 0.2110187\ttotal: 730ms\tremaining: 1.88s\n",
      "28:\tlearn: 0.2045315\ttotal: 756ms\tremaining: 1.85s\n",
      "29:\tlearn: 0.1983660\ttotal: 781ms\tremaining: 1.82s\n",
      "30:\tlearn: 0.1926777\ttotal: 808ms\tremaining: 1.8s\n",
      "31:\tlearn: 0.1883879\ttotal: 833ms\tremaining: 1.77s\n",
      "32:\tlearn: 0.1829197\ttotal: 861ms\tremaining: 1.75s\n",
      "33:\tlearn: 0.1784453\ttotal: 886ms\tremaining: 1.72s\n",
      "34:\tlearn: 0.1738615\ttotal: 914ms\tremaining: 1.7s\n",
      "35:\tlearn: 0.1706787\ttotal: 937ms\tremaining: 1.67s\n",
      "36:\tlearn: 0.1667341\ttotal: 963ms\tremaining: 1.64s\n",
      "37:\tlearn: 0.1628034\ttotal: 987ms\tremaining: 1.61s\n",
      "38:\tlearn: 0.1596607\ttotal: 1.01s\tremaining: 1.58s\n",
      "39:\tlearn: 0.1566949\ttotal: 1.03s\tremaining: 1.55s\n",
      "40:\tlearn: 0.1540556\ttotal: 1.06s\tremaining: 1.53s\n",
      "41:\tlearn: 0.1522075\ttotal: 1.08s\tremaining: 1.5s\n",
      "42:\tlearn: 0.1507688\ttotal: 1.11s\tremaining: 1.47s\n",
      "43:\tlearn: 0.1488232\ttotal: 1.13s\tremaining: 1.43s\n",
      "44:\tlearn: 0.1461899\ttotal: 1.15s\tremaining: 1.4s\n",
      "45:\tlearn: 0.1442303\ttotal: 1.17s\tremaining: 1.37s\n",
      "46:\tlearn: 0.1425724\ttotal: 1.18s\tremaining: 1.33s\n",
      "47:\tlearn: 0.1404594\ttotal: 1.2s\tremaining: 1.3s\n",
      "48:\tlearn: 0.1383186\ttotal: 1.22s\tremaining: 1.27s\n",
      "49:\tlearn: 0.1363330\ttotal: 1.24s\tremaining: 1.24s\n",
      "50:\tlearn: 0.1345982\ttotal: 1.26s\tremaining: 1.21s\n",
      "51:\tlearn: 0.1336201\ttotal: 1.28s\tremaining: 1.19s\n",
      "52:\tlearn: 0.1324605\ttotal: 1.3s\tremaining: 1.16s\n",
      "53:\tlearn: 0.1303971\ttotal: 1.33s\tremaining: 1.13s\n",
      "54:\tlearn: 0.1286923\ttotal: 1.35s\tremaining: 1.11s\n",
      "55:\tlearn: 0.1274924\ttotal: 1.38s\tremaining: 1.08s\n",
      "56:\tlearn: 0.1259712\ttotal: 1.4s\tremaining: 1.06s\n",
      "57:\tlearn: 0.1244095\ttotal: 1.42s\tremaining: 1.03s\n",
      "58:\tlearn: 0.1230541\ttotal: 1.45s\tremaining: 1.01s\n",
      "59:\tlearn: 0.1220822\ttotal: 1.48s\tremaining: 984ms\n",
      "60:\tlearn: 0.1211131\ttotal: 1.5s\tremaining: 960ms\n",
      "61:\tlearn: 0.1200628\ttotal: 1.53s\tremaining: 936ms\n",
      "62:\tlearn: 0.1186995\ttotal: 1.55s\tremaining: 910ms\n",
      "63:\tlearn: 0.1177919\ttotal: 1.58s\tremaining: 887ms\n",
      "64:\tlearn: 0.1169559\ttotal: 1.6s\tremaining: 863ms\n",
      "65:\tlearn: 0.1157356\ttotal: 1.63s\tremaining: 838ms\n",
      "66:\tlearn: 0.1144660\ttotal: 1.65s\tremaining: 814ms\n",
      "67:\tlearn: 0.1134779\ttotal: 1.68s\tremaining: 789ms\n",
      "68:\tlearn: 0.1126772\ttotal: 1.7s\tremaining: 764ms\n",
      "69:\tlearn: 0.1118813\ttotal: 1.72s\tremaining: 739ms\n",
      "70:\tlearn: 0.1108370\ttotal: 1.75s\tremaining: 715ms\n",
      "71:\tlearn: 0.1098401\ttotal: 1.77s\tremaining: 689ms\n",
      "72:\tlearn: 0.1093829\ttotal: 1.79s\tremaining: 663ms\n",
      "73:\tlearn: 0.1088320\ttotal: 1.82s\tremaining: 639ms\n",
      "74:\tlearn: 0.1081029\ttotal: 1.84s\tremaining: 614ms\n",
      "75:\tlearn: 0.1075316\ttotal: 1.86s\tremaining: 589ms\n",
      "76:\tlearn: 0.1069880\ttotal: 1.89s\tremaining: 564ms\n",
      "77:\tlearn: 0.1064262\ttotal: 1.91s\tremaining: 539ms\n",
      "78:\tlearn: 0.1058099\ttotal: 1.94s\tremaining: 515ms\n",
      "79:\tlearn: 0.1052742\ttotal: 1.96s\tremaining: 490ms\n",
      "80:\tlearn: 0.1044917\ttotal: 1.99s\tremaining: 466ms\n",
      "81:\tlearn: 0.1040566\ttotal: 2.01s\tremaining: 442ms\n",
      "82:\tlearn: 0.1036333\ttotal: 2.04s\tremaining: 418ms\n",
      "83:\tlearn: 0.1033588\ttotal: 2.06s\tremaining: 393ms\n",
      "84:\tlearn: 0.1024876\ttotal: 2.09s\tremaining: 368ms\n",
      "85:\tlearn: 0.1020134\ttotal: 2.11s\tremaining: 344ms\n",
      "86:\tlearn: 0.1013139\ttotal: 2.13s\tremaining: 319ms\n",
      "87:\tlearn: 0.1008171\ttotal: 2.16s\tremaining: 294ms\n",
      "88:\tlearn: 0.1000484\ttotal: 2.18s\tremaining: 270ms\n",
      "89:\tlearn: 0.0997865\ttotal: 2.2s\tremaining: 245ms\n",
      "90:\tlearn: 0.0991002\ttotal: 2.23s\tremaining: 220ms\n",
      "91:\tlearn: 0.0986997\ttotal: 2.25s\tremaining: 196ms\n",
      "92:\tlearn: 0.0977336\ttotal: 2.27s\tremaining: 171ms\n",
      "93:\tlearn: 0.0972960\ttotal: 2.3s\tremaining: 147ms\n",
      "94:\tlearn: 0.0966942\ttotal: 2.32s\tremaining: 122ms\n",
      "95:\tlearn: 0.0960611\ttotal: 2.35s\tremaining: 97.7ms\n",
      "96:\tlearn: 0.0957000\ttotal: 2.37s\tremaining: 73.3ms\n",
      "97:\tlearn: 0.0949619\ttotal: 2.39s\tremaining: 48.9ms\n",
      "98:\tlearn: 0.0945052\ttotal: 2.42s\tremaining: 24.4ms\n",
      "99:\tlearn: 0.0942643\ttotal: 2.44s\tremaining: 0us\n",
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3    4\n",
      "0  22434.0    186.0   198.0  189.0  0.0\n",
      "1    212.0  15809.0    70.0   10.0  0.0\n",
      "2    183.0     27.0  4055.0   12.0  0.0\n",
      "3    226.0      8.0    22.0  882.0  0.0\n",
      "4     19.0      0.0     0.0   14.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9691175150372565\n",
      "Precision total:  0.7376962175164319\n",
      "Recall total:  0.736019482475269\n",
      "F1 total:  0.7368148051101371\n",
      "BACC total:  0.736019482475269\n",
      "MCC total:  0.9478922377661022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "import catboost\n",
    "start = time.time()\n",
    "\n",
    "bag_cat = catboost.CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='MultiClass', custom_metric='Accuracy')\n",
    "\n",
    "base_classifier = bag_cat\n",
    "\n",
    "# Define the BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the BaggingClassifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('--------------------------------------------------------------------------', file = f)\n",
    "\n",
    "name = 'bag_cat'\n",
    "\n",
    "pred_label = y_pred\n",
    "\n",
    "\n",
    "metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "Acc = metrics[0]\n",
    "Precision = metrics[1]\n",
    "Recall = metrics[2]\n",
    "F1 = metrics[3]\n",
    "BACC = metrics[4]\n",
    "MCC = metrics[5]    \n",
    "\n",
    "\n",
    "globals()[f\"{name}_acc_00\"] = Acc\n",
    "globals()[f\"{name}_pre_00\"] = Precision\n",
    "globals()[f\"{name}_rec_00\"] = Recall\n",
    "globals()[f\"{name}_f1_00\"] = F1\n",
    "globals()[f\"{name}_bacc_00\"] = BACC\n",
    "globals()[f\"{name}_mcc_00\"] = MCC\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "globals()[f\"{name}_time_00\"] = time_taken\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3049306\ttest: 1.3039542\tbest: 1.3039542 (0)\ttotal: 29.3ms\tremaining: 2.9s\n",
      "10:\tlearn: 0.4641097\ttest: 0.4634997\tbest: 0.4634997 (10)\ttotal: 286ms\tremaining: 2.31s\n",
      "20:\tlearn: 0.2651970\ttest: 0.2660280\tbest: 0.2660280 (20)\ttotal: 527ms\tremaining: 1.98s\n",
      "30:\tlearn: 0.1914871\ttest: 0.1932211\tbest: 0.1932211 (30)\ttotal: 753ms\tremaining: 1.68s\n",
      "40:\tlearn: 0.1547691\ttest: 0.1573027\tbest: 0.1573027 (40)\ttotal: 1s\tremaining: 1.44s\n",
      "50:\tlearn: 0.1365355\ttest: 0.1395252\tbest: 0.1395252 (50)\ttotal: 1.22s\tremaining: 1.18s\n",
      "60:\tlearn: 0.1222282\ttest: 0.1256268\tbest: 0.1256268 (60)\ttotal: 1.43s\tremaining: 915ms\n",
      "70:\tlearn: 0.1114527\ttest: 0.1153250\tbest: 0.1153250 (70)\ttotal: 1.66s\tremaining: 680ms\n",
      "80:\tlearn: 0.1043892\ttest: 0.1085262\tbest: 0.1085262 (80)\ttotal: 1.89s\tremaining: 442ms\n",
      "90:\tlearn: 0.0984946\ttest: 0.1030729\tbest: 0.1030729 (90)\ttotal: 2.11s\tremaining: 209ms\n",
      "99:\tlearn: 0.0933431\ttest: 0.0984391\tbest: 0.0984391 (99)\ttotal: 2.33s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.09843905549\n",
      "bestIteration = 99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 1.7359 - accuracy: 0.5281 - val_loss: 0.6717 - val_accuracy: 0.8226\n",
      "Epoch 2/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.8476 - accuracy: 0.7213 - val_loss: 0.5754 - val_accuracy: 0.8253\n",
      "Epoch 3/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.7461 - accuracy: 0.7563 - val_loss: 0.5403 - val_accuracy: 0.8283\n",
      "Epoch 4/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.6896 - accuracy: 0.7791 - val_loss: 0.5245 - val_accuracy: 0.8283\n",
      "Epoch 5/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.6467 - accuracy: 0.7970 - val_loss: 0.5173 - val_accuracy: 0.8293\n",
      "Epoch 6/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.6266 - accuracy: 0.8059 - val_loss: 0.5167 - val_accuracy: 0.8293\n",
      "Epoch 7/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.6178 - accuracy: 0.8104 - val_loss: 0.5167 - val_accuracy: 0.8293\n",
      "Epoch 8/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.6076 - accuracy: 0.8125 - val_loss: 0.5146 - val_accuracy: 0.8292\n",
      "Epoch 9/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.6041 - accuracy: 0.8138 - val_loss: 0.5138 - val_accuracy: 0.8308\n",
      "Epoch 10/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.6020 - accuracy: 0.8113 - val_loss: 0.5143 - val_accuracy: 0.8298\n",
      "Epoch 11/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.5984 - accuracy: 0.8137 - val_loss: 0.5133 - val_accuracy: 0.8298\n",
      "Epoch 12/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.6017 - accuracy: 0.8125 - val_loss: 0.5144 - val_accuracy: 0.8299\n",
      "Epoch 13/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.6002 - accuracy: 0.8121 - val_loss: 0.5147 - val_accuracy: 0.8299\n",
      "Epoch 14/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.6010 - accuracy: 0.8123 - val_loss: 0.5150 - val_accuracy: 0.8283\n",
      "Epoch 15/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.5977 - accuracy: 0.8138 - val_loss: 0.5152 - val_accuracy: 0.8302\n",
      "Epoch 16/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.5983 - accuracy: 0.8126 - val_loss: 0.5153 - val_accuracy: 0.8297\n",
      "Epoch 17/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.5946 - accuracy: 0.8136 - val_loss: 0.5145 - val_accuracy: 0.8285\n",
      "Epoch 18/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.5973 - accuracy: 0.8132 - val_loss: 0.5141 - val_accuracy: 0.8286\n",
      "Epoch 19/100\n",
      "650/650 [==============================] - 2s 3ms/step - loss: 0.5976 - accuracy: 0.8138 - val_loss: 0.5140 - val_accuracy: 0.8303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       model_0  model_1  model_2  model_3  model_4  model_5  model_6  model_7  \\\n",
      "0            1        1        1        1        1        1        1        1   \n",
      "1            0        1        0        0        0        0        0        0   \n",
      "2            0        0        0        0        0        0        0        0   \n",
      "3            0        1        0        0        0        0        0        0   \n",
      "4            1        1        1        1        1        1        1        1   \n",
      "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "44551        0        0        0        0        0        0        0        0   \n",
      "44552        0        0        0        0        0        0        0        0   \n",
      "44553        1        1        1        1        1        1        1        1   \n",
      "44554        1        2        2        2        2        2        2        1   \n",
      "44555        0        0        0        0        0        0        0        0   \n",
      "\n",
      "       model_8  model_9  \n",
      "0            1      1.0  \n",
      "1            0      0.0  \n",
      "2            0      0.0  \n",
      "3            0      0.0  \n",
      "4            1      1.0  \n",
      "...        ...      ...  \n",
      "44551        0      0.0  \n",
      "44552        0      0.0  \n",
      "44553        1      1.0  \n",
      "44554        1      2.0  \n",
      "44555        0      0.0  \n",
      "\n",
      "[44556 rows x 10 columns]\n",
      "       model_0  model_1  model_2  model_3  model_4  model_5  model_6  model_7  \\\n",
      "0            1        1        1        1        1        1        1        1   \n",
      "1            0        1        0        0        0        0        0        0   \n",
      "2            0        0        0        0        0        0        0        0   \n",
      "3            0        1        0        0        0        0        0        0   \n",
      "4            1        1        1        1        1        1        1        1   \n",
      "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "44551        0        0        0        0        0        0        0        0   \n",
      "44552        0        0        0        0        0        0        0        0   \n",
      "44553        1        1        1        1        1        1        1        1   \n",
      "44554        1        2        2        2        2        2        2        1   \n",
      "44555        0        0        0        0        0        0        0        0   \n",
      "\n",
      "       model_8  model_9  ensemble  \n",
      "0            1      1.0         1  \n",
      "1            0      0.0         0  \n",
      "2            0      0.0         0  \n",
      "3            0      0.0         0  \n",
      "4            1      1.0         1  \n",
      "...        ...      ...       ...  \n",
      "44551        0      0.0         0  \n",
      "44552        0      0.0         0  \n",
      "44553        1      1.0         1  \n",
      "44554        1      2.0         2  \n",
      "44555        0      0.0         0  \n",
      "\n",
      "[44556 rows x 11 columns]\n",
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3    4\n",
      "0  22601.0    139.0   237.0   30.0  0.0\n",
      "1    452.0  15598.0    48.0    3.0  0.0\n",
      "2    256.0     59.0  3954.0    8.0  0.0\n",
      "3    703.0      4.0    21.0  410.0  0.0\n",
      "4     30.0      0.0     1.0    2.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9552697728700961\n",
      "Precision total:  0.7520613720855989\n",
      "Recall total:  0.6471747743684023\n",
      "F1 total:  0.6760509564298951\n",
      "BACC total:  0.6471747743684023\n",
      "MCC total:  0.9241542070711088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "### Bagging with many models\n",
    "##### do bootstrapping \n",
    "##### 1. Multiple subsets are created from the original dataset, selecting observations with replacement.\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "num_bootstraps = 10  # Adjust the number of bootstraps as needed\n",
    "\n",
    "original_data_df = X_train.assign(label = y_train)\n",
    "boot_df = []\n",
    "for i in range(0,num_bootstraps): \n",
    "    boot_df.append(original_data_df.sample(frac = 1, replace=True).reset_index(drop=True))\n",
    "\n",
    "# boot_df[5]\n",
    "\n",
    "#### 2.A base model (weak model) is created on each of these subsets.\n",
    "bag_comb_pred = []\n",
    "\n",
    "# SVM\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(\n",
    "    loss='hinge',           # hinge loss for linear SVM\n",
    "    penalty='l2',           # L2 regularization to prevent overfitting\n",
    "    alpha=1e-4,             # Learning rate (small value for fine-grained updates)\n",
    "    max_iter=1000,          # Number of passes over the training data\n",
    "    random_state=42,        # Seed for reproducible results\n",
    "    learning_rate='optimal' # Automatically adjusts the learning rate based on the training data\n",
    ")\n",
    "y_train_boot = boot_df[0].pop('label')\n",
    "X_train_boot = boot_df[0]\n",
    "clf.fit(X_train_boot, y_train_boot)\n",
    "preds_svm_00 = clf.predict(X_test)\n",
    "bag_comb_pred.append(preds_svm_00)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ADA\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(n_estimators=50, learning_rate=1.0)\n",
    "ada = abc.fit(X_train, y_train)\n",
    "y_train_boot = boot_df[1].pop('label')\n",
    "X_train_boot = boot_df[1]\n",
    "preds_ada_00 = ada.predict(X_test)\n",
    "bag_comb_pred.append(preds_ada_00)\n",
    "\n",
    "#Catboost\n",
    "import catboost\n",
    "cat_00 = catboost.CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='MultiClass', custom_metric='Accuracy')\n",
    "y_train_boot = boot_df[2].pop('label')\n",
    "X_train_boot = boot_df[2]\n",
    "cat_00.fit(X_train_boot, y_train_boot, eval_set=(X_test, y_test), verbose=10)\n",
    "preds_cat = cat_00.predict(X_test)\n",
    "preds_cat = np.squeeze(preds_cat)\n",
    "pred_label = preds_cat\n",
    "bag_comb_pred.append(preds_cat)\n",
    "\n",
    "#MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=200, random_state=1)\n",
    "y_train_boot = boot_df[3].pop('label')\n",
    "X_train_boot = boot_df[3]\n",
    "if 1 == 1 and 0 == 0:\n",
    "    MLP = mlp.fit(X_train_boot, y_train_boot)\n",
    "    y_pred = MLP.predict_proba(X_test)\n",
    "    preds_mlp_00 = np.argmax(y_pred,axis = 1)\n",
    "\n",
    "bag_comb_pred.append(preds_mlp_00)\n",
    "\n",
    "#LGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "y_train_boot = boot_df[4].pop('label')\n",
    "X_train_boot = boot_df[4]\n",
    "\n",
    "if 1 == 1 and 0 == 0:\n",
    "    lgbm.fit(X_train_boot, y_train_boot)\n",
    "    preds_lgbm_00 = lgbm.predict(X_test)\n",
    "    bag_comb_pred.append(preds_lgbm_00)\n",
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf_00=KNeighborsClassifier(n_neighbors = 5)\n",
    "y_train_boot = boot_df[5].pop('label')\n",
    "X_train_boot = boot_df[5]\n",
    "\n",
    "if 1 == 1 and 0 == 0:\n",
    "    knn_clf_00.fit(X_train_boot,y_train_boot)\n",
    "if use_model_knn == 1:\n",
    "    preds_knn =knn_clf_00.predict(X_test)\n",
    "    bag_comb_pred.append(preds_knn)\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_depth = 5,  n_estimators = 10, min_samples_split = 2, n_jobs = -1)\n",
    "y_train_boot = boot_df[6].pop('label')\n",
    "X_train_boot = boot_df[6]\n",
    "\n",
    "if True == True:\n",
    "    model_rf_00 = rf.fit(X_train_boot,y_train_boot)\n",
    "    preds_rf_00 = model_rf_00.predict(X_test)\n",
    "    bag_comb_pred.append(preds_rf_00)\n",
    "#DNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "#Model Parameters\n",
    "y_train_boot = boot_df[7].pop('label')\n",
    "X_train_boot = boot_df[7]\n",
    "\n",
    "\n",
    "dropout_rate = 0.2\n",
    "nodes = 3\n",
    "out_layer = 5\n",
    "optimizer='adam'\n",
    "loss='sparse_categorical_crossentropy'\n",
    "epochs=100\n",
    "batch_size=128\n",
    "num_columns = X_train_boot.shape[1]\n",
    "dnn_00 = tf.keras.Sequential()\n",
    "# Input layer\n",
    "dnn_00.add(tf.keras.Input(shape=(num_columns,)))\n",
    "# Dense layers with dropout\n",
    "dnn_00.add(tf.keras.layers.Dense(nodes))\n",
    "dnn_00.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "dnn_00.add(tf.keras.layers.Dense(nodes))\n",
    "dnn_00.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "dnn_00.add(tf.keras.layers.Dense(nodes))\n",
    "dnn_00.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "dnn_00.add(tf.keras.layers.Dense(nodes))\n",
    "dnn_00.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "dnn_00.add(tf.keras.layers.Dense(nodes))\n",
    "dnn_00.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "# Output layer\n",
    "# dnn_00.add(tf.keras.layers.Dense(out_layer))\n",
    "dnn_00.add(tf.keras.layers.Dense(out_layer, activation='softmax'))\n",
    "dnn_00.compile(optimizer=optimizer, loss=loss,metrics=['accuracy'])\n",
    "from keras.callbacks import EarlyStopping\n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "dnn_00.fit(X_train_boot, y_train_boot, epochs=epochs, batch_size=batch_size,validation_split=0.2, callbacks=[early_stopping])\n",
    "pred_dnn = dnn_00.predict(X_test)\n",
    "preds_dnn_00 = np.argmax(pred_dnn,axis = 1)\n",
    "bag_comb_pred.append(preds_dnn_00)\n",
    "#LogReg\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_00 = LogisticRegression()\n",
    "y_train_boot = boot_df[8].pop('label')\n",
    "X_train_boot = boot_df[8]\n",
    "\n",
    "logreg_00.fit(X_train_boot,y_train_boot)\n",
    "preds_logreg =logreg_00.predict(X_test)\n",
    "bag_comb_pred.append(preds_logreg)\n",
    "import xgboost as xgb\n",
    "y_train_boot = boot_df[9].pop('label')\n",
    "X_train_boot = boot_df[9]\n",
    "\n",
    "# Create a DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train_boot, label=y_train_boot)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "# Set XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # for multi-class classification\n",
    "    'num_class': 5,  # specify the number of classes\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'eval_metric': 'mlogloss'  # metric for multi-class classification\n",
    "}\n",
    "# Train the XGBoost model\n",
    "num_round = 100\n",
    "xgb_00 = xgb.train(params, dtrain, num_round)\n",
    "preds_xgb_00 = xgb_00.predict(dtest)\n",
    "bag_comb_pred.append(preds_xgb_00)\n",
    "### 3. The models run in parallel and are independent of each other.\n",
    "bag_vot_df = pd.DataFrame()\n",
    "for i in range(0,len(bag_comb_pred)):\n",
    "    bag_vot_df[f'model_{i}'] =  bag_comb_pred[i]\n",
    "print(bag_vot_df)\n",
    "# Voting start\n",
    "from scipy.stats import mode\n",
    "# bag_comb_pred_df = pd.DataFrame(bag_comb_pred)\n",
    "# Extract predictions columns\n",
    "\n",
    "# predictions = df[['dnn', 'rf', 'lgbm', 'ada', 'knn', 'mlp', 'svm','cat','xgb']]\n",
    "    # selected_columns = df.loc[:, ~df.columns.isin(['rf'])]\n",
    "predictions = bag_vot_df \n",
    "\n",
    "# predictions = bag_comb_pred_df.loc[:, ~df.columns.isin(['label'])] #df[column_features]\n",
    "\n",
    "# Use the mode function along axis 1 to get the most common prediction for each row\n",
    "ensemble_predictions, _ = mode(predictions.values, axis=1)\n",
    "\n",
    "# Add the ensemble predictions to the DataFrame\n",
    "bag_vot_df['ensemble'] = ensemble_predictions.astype(int)\n",
    "\n",
    "# Display the DataFrame with ensemble predictions\n",
    "print(bag_vot_df)\n",
    "\n",
    "pred_label = bag_vot_df ['ensemble'].values\n",
    "bag_vot_df.pop('ensemble')\n",
    "\n",
    "\n",
    "name='bag_comb'\n",
    "metrics = confusion_metrics(name, pred_label, y_test)\n",
    "\n",
    "Acc = metrics[0]\n",
    "Precision = metrics[1]\n",
    "Recall = metrics[2]\n",
    "F1 = metrics[3]\n",
    "BACC = metrics[4]\n",
    "MCC = metrics[5]    \n",
    "\n",
    "\n",
    "globals()[f\"{name}_acc_00\"] = Acc\n",
    "globals()[f\"{name}_pre_00\"] = Precision\n",
    "globals()[f\"{name}_rec_00\"] = Recall\n",
    "globals()[f\"{name}_f1_00\"] = F1\n",
    "globals()[f\"{name}_bacc_00\"] = BACC\n",
    "globals()[f\"{name}_mcc_00\"] = MCC\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "globals()[f\"{name}_time_00\"] = time_taken\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating new dataset for level 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44556 44556\n"
     ]
    }
   ],
   "source": [
    "print(len(preds_dnn_prob), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116749    1\n",
      "12479     0\n",
      "116681    0\n",
      "122439    0\n",
      "11327     1\n",
      "         ..\n",
      "125765    0\n",
      "85435     0\n",
      "34168     1\n",
      "102278    2\n",
      "47605     0\n",
      "Name: Label, Length: 44556, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        index  Label\n",
      "0      116749      1\n",
      "1       12479      0\n",
      "2      116681      0\n",
      "3      122439      0\n",
      "4       11327      1\n",
      "...       ...    ...\n",
      "44551  125765      0\n",
      "44552   85435      0\n",
      "44553   34168      1\n",
      "44554  102278      2\n",
      "44555   47605      0\n",
      "\n",
      "[44556 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        116749\n",
       "1         12479\n",
       "2        116681\n",
       "3        122439\n",
       "4         11327\n",
       "          ...  \n",
       "44551    125765\n",
       "44552     85435\n",
       "44553     34168\n",
       "44554    102278\n",
       "44555     47605\n",
       "Name: index, Length: 44556, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_series = y_test.to_frame()\n",
    "y_test_reset_index = df_from_series.reset_index()\n",
    "# y_test2 = y_test.reset_index(inplace=True)\n",
    "print(y_test_reset_index)\n",
    "y_test_reset_index.pop('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_reset_index.values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dnn_2 = []\n",
    "preds_svm_2 = []\n",
    "preds_rf_2 = []\n",
    "preds_mlp_2 = []\n",
    "preds_ada_2 = []\n",
    "preds_knn_2 = []\n",
    "preds_lgbm_2 = []\n",
    "preds_cat_2 = []\n",
    "preds_xgb_2 = []\n",
    "\n",
    "preds_lr_2 = []\n",
    "preds_dt_2 = []\n",
    "\n",
    "for i in range(0,len(preds_dnn_prob)):  \n",
    "    # print(i)\n",
    "    # print(preds_dnn_prob[i][y_test_reset_index.values[i][0]])\n",
    "    preds_dnn_2.append(preds_dnn_prob[i][y_test_reset_index.values[i][0]])\n",
    "    preds_svm_2.append(preds_svm_prob[i][y_test_reset_index.values[i][0]])\n",
    "    preds_rf_2.append(preds_rf_prob[i][y_test_reset_index.values[i][0]])\n",
    "    preds_mlp_2.append(preds_mlp_prob[i][y_test_reset_index.values[i][0]])\n",
    "    preds_ada_2.append(preds_ada_prob[i][y_test_reset_index.values[i][0]])\n",
    "    preds_knn_2.append(preds_knn_prob[i][y_test_reset_index.values[i][0]])\n",
    "    preds_lgbm_2.append(preds_lgbm_prob[i][y_test_reset_index.values[i][0]])\n",
    "    preds_cat_2.append(preds_cat_prob[i][y_test_reset_index.values[i][0]])\n",
    "    preds_xgb_2.append(preds_xgb_prob[i][y_test_reset_index.values[i][0]])\n",
    "    preds_lr_2.append(preds_lr_prob[i][y_test_reset_index.values[i][0]])\n",
    "    preds_dt_2.append(preds_dt_prob[i][y_test_reset_index.values[i][0]])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 2. 2. ... 2. 1. 2.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0.18495913 0.99566424 1.         ... 0.99535084 0.97001687 1.        ]\n",
      " [1.26331687 0.90148319 0.99954063 ... 0.99473733 0.97803335 0.        ]\n",
      " [2.15649462 0.95238536 0.99744784 ... 0.95716333 0.92120772 0.        ]\n",
      " ...\n",
      " [0.18928634 0.99566424 1.         ... 0.99535084 0.97168964 1.        ]\n",
      " [0.03016039 0.79127666 1.         ... 0.98627687 0.41109639 2.        ]\n",
      " [2.55233359 0.98269546 0.99944934 ... 0.99259925 0.97037767 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "with open(output_file_name, \"a\") as f: print('------------------------------------------------------------------', file = f)\n",
    "with open(output_file_name, \"a\") as f: print('------------------------------------------------------------------', file = f)\n",
    "with open(output_file_name, \"a\") as f: print('------------------------------------------------------------------', file = f)\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('------------START of STRONGER LEARNER - STACK 01 -----------------', file = f)\n",
    "\n",
    "\n",
    "# Stack the vectors horizontally to create a matrix\n",
    "column_features = ['dnn','rf','lgbm','ada','knn','mlp','svm','cat','xgb','lr','dt','label']\n",
    "training_matrix2 = np.column_stack((\n",
    "                          preds_dnn_2,\n",
    "                          preds_rf_2,\n",
    "                          preds_lgbm_2,\n",
    "                          preds_ada_2,\n",
    "                          preds_knn_2, \n",
    "                          preds_mlp_2,\n",
    "                          preds_svm_2,\n",
    "                          preds_cat_2,\n",
    "                          preds_xgb_2,\n",
    "                          preds_lr_2,\n",
    "                          preds_dt_2,\n",
    "                          y_test\n",
    "                          ))\n",
    "\n",
    "training_matrix = np.column_stack((\n",
    "                          preds_dnn,\n",
    "                          preds_rf,\n",
    "                          preds_lgbm,\n",
    "                          preds_ada,\n",
    "                          preds_knn, \n",
    "                          preds_mlp,\n",
    "                          preds_svm,\n",
    "                          preds_cat,\n",
    "                          preds_xgb,\n",
    "                          preds_lr,\n",
    "                          preds_dt,\n",
    "                        #   preds\n",
    "                          y_test\n",
    "                          ))\n",
    "# Print the resulting matrix\n",
    "print(training_matrix)\n",
    "print(training_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_level_00_0 = pd.DataFrame(training_matrix, columns=column_features)\n",
    "df_level_00_1 = pd.DataFrame(training_matrix2, columns=column_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming df is your DataFrame\n",
    "if feature_selection_bit == 1:\n",
    "\n",
    "    df_level_00_1.to_csv('base_models_prob_feature_selection.csv', index=False)\n",
    "    df_level_00_0.to_csv('base_models_class_feature_selection.csv', index=False)\n",
    "    \n",
    "if feature_selection_bit == 0:\n",
    "\n",
    "    df_level_00_1.to_csv('base_models_prob_all_features.csv', index=False)\n",
    "    df_level_00_0.to_csv('base_models_class_all_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dnn</th>\n",
       "      <th>rf</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>ada</th>\n",
       "      <th>knn</th>\n",
       "      <th>mlp</th>\n",
       "      <th>svm</th>\n",
       "      <th>cat</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lr</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.184959</td>\n",
       "      <td>0.995664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.091581</td>\n",
       "      <td>0.998595</td>\n",
       "      <td>0.995351</td>\n",
       "      <td>0.970017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.263317</td>\n",
       "      <td>0.901483</td>\n",
       "      <td>0.999541</td>\n",
       "      <td>0.256679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.262305</td>\n",
       "      <td>0.997341</td>\n",
       "      <td>0.994737</td>\n",
       "      <td>0.978033</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.156495</td>\n",
       "      <td>0.952385</td>\n",
       "      <td>0.997448</td>\n",
       "      <td>0.227039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992756</td>\n",
       "      <td>0.016995</td>\n",
       "      <td>0.975448</td>\n",
       "      <td>0.957163</td>\n",
       "      <td>0.921208</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.361415</td>\n",
       "      <td>0.773010</td>\n",
       "      <td>0.908986</td>\n",
       "      <td>0.240320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993737</td>\n",
       "      <td>0.954099</td>\n",
       "      <td>0.888607</td>\n",
       "      <td>0.795008</td>\n",
       "      <td>0.965679</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.176913</td>\n",
       "      <td>0.995534</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>0.270092</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022950</td>\n",
       "      <td>0.998703</td>\n",
       "      <td>0.995351</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44551</th>\n",
       "      <td>2.543204</td>\n",
       "      <td>0.982695</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.269643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998290</td>\n",
       "      <td>0.968287</td>\n",
       "      <td>0.996241</td>\n",
       "      <td>0.993117</td>\n",
       "      <td>0.971517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44552</th>\n",
       "      <td>2.522557</td>\n",
       "      <td>0.991618</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.269643</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.674171</td>\n",
       "      <td>0.997375</td>\n",
       "      <td>0.993117</td>\n",
       "      <td>0.977973</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44553</th>\n",
       "      <td>0.189286</td>\n",
       "      <td>0.995664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.027936</td>\n",
       "      <td>0.998696</td>\n",
       "      <td>0.995351</td>\n",
       "      <td>0.971690</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44554</th>\n",
       "      <td>0.030160</td>\n",
       "      <td>0.791277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.265837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.993283</td>\n",
       "      <td>0.986277</td>\n",
       "      <td>0.411096</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44555</th>\n",
       "      <td>2.552334</td>\n",
       "      <td>0.982695</td>\n",
       "      <td>0.999449</td>\n",
       "      <td>0.275797</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315625</td>\n",
       "      <td>0.996528</td>\n",
       "      <td>0.992599</td>\n",
       "      <td>0.970378</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44556 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            dnn        rf      lgbm       ada  knn       mlp       svm  \\\n",
       "0      0.184959  0.995664  1.000000  0.269449  1.0  0.999999  0.091581   \n",
       "1      1.263317  0.901483  0.999541  0.256679  1.0  1.000000  0.262305   \n",
       "2      2.156495  0.952385  0.997448  0.227039  1.0  0.992756  0.016995   \n",
       "3      2.361415  0.773010  0.908986  0.240320  1.0  0.993737  0.954099   \n",
       "4      0.176913  0.995534  0.999906  0.270092  1.0  1.000000  0.022950   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "44551  2.543204  0.982695  0.999375  0.269643  1.0  0.998290  0.968287   \n",
       "44552  2.522557  0.991618  0.999552  0.269643  1.0  0.999442  0.674171   \n",
       "44553  0.189286  0.995664  1.000000  0.269449  1.0  0.999999  0.027936   \n",
       "44554  0.030160  0.791277  1.000000  0.265837  1.0  0.999998  0.001068   \n",
       "44555  2.552334  0.982695  0.999449  0.275797  1.0  1.000000  0.315625   \n",
       "\n",
       "            cat       xgb        lr  label  \n",
       "0      0.998595  0.995351  0.970017    1.0  \n",
       "1      0.997341  0.994737  0.978033    0.0  \n",
       "2      0.975448  0.957163  0.921208    0.0  \n",
       "3      0.888607  0.795008  0.965679    0.0  \n",
       "4      0.998703  0.995351  0.978102    1.0  \n",
       "...         ...       ...       ...    ...  \n",
       "44551  0.996241  0.993117  0.971517    0.0  \n",
       "44552  0.997375  0.993117  0.977973    0.0  \n",
       "44553  0.998696  0.995351  0.971690    1.0  \n",
       "44554  0.993283  0.986277  0.411096    2.0  \n",
       "44555  0.996528  0.992599  0.970378    0.0  \n",
       "\n",
       "[44556 rows x 11 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_level_00_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dnn</th>\n",
       "      <th>rf</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>ada</th>\n",
       "      <th>knn</th>\n",
       "      <th>mlp</th>\n",
       "      <th>svm</th>\n",
       "      <th>cat</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lr</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44551</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44552</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44553</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44554</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44556 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dnn   rf  lgbm  ada  knn  mlp  svm  cat  xgb   lr  label\n",
       "0      1.0  1.0   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0    1.0\n",
       "1      0.0  0.0   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0\n",
       "2      0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0\n",
       "3      0.0  0.0   0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0\n",
       "4      1.0  1.0   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0    1.0\n",
       "...    ...  ...   ...  ...  ...  ...  ...  ...  ...  ...    ...\n",
       "44551  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0\n",
       "44552  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0\n",
       "44553  1.0  1.0   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0    1.0\n",
       "44554  1.0  2.0   2.0  2.0  2.0  2.0  1.0  2.0  2.0  1.0    2.0\n",
       "44555  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0\n",
       "\n",
       "[44556 rows x 11 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_level_00_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_01 = df_level_01.pop('label')\n",
    "# X_01 = df_level_01\n",
    "# df_level_01 = df_level_01.assign(label = y_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_level_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split = 0.7\n",
    "\n",
    "# X_train_01,X_test_01, y_train_01, y_test_01 = sklearn.model_selection.train_test_split(X_01, y_01, train_size=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tabulate import tabulate\n",
    "\n",
    "# # Assuming data is a 110x4 list, where each row is a sublist\n",
    "# # data =  [[\"Row {} Col {}\".format(i + 1, j + 1) for j in range(4)] for i in range(110)]\n",
    "# data = [[\"\" for _ in range(3)] for _ in range(12)]\n",
    "\n",
    "# # Manually insert data at specific row and column\n",
    "# # data[0][0] = \"ADA\"\n",
    "# # data[1][0] = \"DNN\"\n",
    "# # data[2][0] = \"SVM\"\n",
    "# # data[3][0] = \"ADA\"\n",
    "# # data[4][0] = \"DNN\"\n",
    "# # data[2][0] = \"SVM\"\n",
    "\n",
    "\n",
    "# names_models = ['ADA',\n",
    "#                 'SVM',\n",
    "#                 'DNN',\n",
    "#                 'MLP',\n",
    "#                 'KNN',\n",
    "#                 'CAT',\n",
    "#                 'XGB',\n",
    "#                 'LGBM',\n",
    "#                 'RF',\n",
    "#                 'LR',\n",
    "#                 'VOTING'\n",
    "#                 ]\n",
    "# level_00_f1 = [ada_f1_00,\n",
    "#                 svm_f1_00,\n",
    "#                 dnn_f1_00,\n",
    "#                 mlp_f1_00,\n",
    "#                 knn_f1_00,\n",
    "#                 cat_f1_00,\n",
    "#                 xgb_f1_00,\n",
    "#                 lgbm_f1_00,\n",
    "#                 rf_f1_00,\n",
    "#                 lr_f1_00,\n",
    "#                 voting_f1_00]  \n",
    "\n",
    "                 \n",
    "\n",
    "# for i in range(0,len(names_models)):\n",
    "#     data[i][0] =  names_models[i]\n",
    "#     data[i][1] = level_00_f1[i]\n",
    "#     data[i][2] = level_01_f1[i]\n",
    "\n",
    "\n",
    " \n",
    "# # data[0][1] = ada_acc_00\n",
    "# # data\n",
    "\n",
    "# # Define column headers\n",
    "# headers = [\"F1\", \"Level 00\", \"Level 01\"]\n",
    "\n",
    "# # Print the table\n",
    "# table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "# print(table)\n",
    "# with open(output_file_name, \"a\") as f: print(table, file = f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_acc_00 = 0 \n",
    "# voting_acc_00 = 0\n",
    "\n",
    "# lr_pre_00 = 0 \n",
    "# voting_pre_00 = 0\n",
    "\n",
    "# lr_rec_00 = 0 \n",
    "# voting_rec_00 = 0\n",
    "\n",
    "# lr_f1_00 = 0 \n",
    "# voting_f1_00 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+\n",
      "| Models   |   ACC-00 |   PRE-00 |   REC-00 |    F1-00 |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| ADA      | 0.757474 | 0.49015  | 0.518571 | 0.495145 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| SVM      | 0.866909 | 0.518517 | 0.488025 | 0.486543 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| DNN      | 0.839662 | 0.336971 | 0.380104 | 0.356995 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| MLP      | 0.966626 | 0.726111 | 0.743367 | 0.734398 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| KNN      | 0.976412 | 0.847044 | 0.765066 | 0.764238 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| CAT      | 0.968601 | 0.735253 | 0.734851 | 0.735038 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| XGB      | 0.95206  | 0.714165 | 0.689462 | 0.700174 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| LGBM     | 0.975514 | 0.758973 | 0.783135 | 0.767766 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| RF       | 0.926901 | 0.703671 | 0.55448  | 0.555154 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| LR       | 0.858829 | 0.519563 | 0.469184 | 0.475063 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_svm  | 0.865405 | 0.564775 | 0.484479 | 0.484568 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_knn  | 0.976546 | 0.779105 | 0.765777 | 0.762737 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_DT   | 0.979352 | 0.81605  | 0.789263 | 0.798081 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_LR   | 0.859009 | 0.520372 | 0.469559 | 0.475378 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_mlp  | 0.969005 | 0.73386  | 0.739233 | 0.736423 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_rf   | 0.929662 | 0.737676 | 0.563716 | 0.571188 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_ada  | 0.738352 | 0.545722 | 0.547741 | 0.537939 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_lgbm | 0.980811 | 0.790636 | 0.774846 | 0.777762 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_cat  | 0.969118 | 0.737696 | 0.736019 | 0.736815 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_comb | 0.95527  | 0.752061 | 0.647175 | 0.676051 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Assuming data is a 110x4 list, where each row is a sublist\n",
    "# data =  [[\"Row {} Col {}\".format(i + 1, j + 1) for j in range(4)] for i in range(110)]\n",
    "data = [[\"\" for _ in range(5)] for _ in range(20)]\n",
    "\n",
    "# Manually insert data at specific row and column\n",
    "# data[0][0] = \"ADA\"\n",
    "# data[1][0] = \"DNN\"\n",
    "# data[2][0] = \"SVM\"\n",
    "# data[3][0] = \"ADA\"\n",
    "# data[4][0] = \"DNN\"\n",
    "# data[2][0] = \"SVM\"\n",
    "\n",
    "\n",
    "# names_models = ['ADA',\n",
    "#                 'SVM',\n",
    "#                 'DNN',\n",
    "#                 'MLP',\n",
    "#                 'KNN',\n",
    "#                 'CAT',\n",
    "#                 'XGB',\n",
    "#                 'LGBM',\n",
    "#                 'RF',\n",
    "#                 'LR',\n",
    "#                 'VOTING',\n",
    "#                 '   '\n",
    "#                 ]\n",
    "\n",
    "# names_models = ['ADA',\n",
    "#                 'SVM',\n",
    "#                 'DNN',\n",
    "#                 'MLP',\n",
    "#                 'KNN',\n",
    "#                 'CAT',\n",
    "#                 'XGB',\n",
    "#                 'LGBM',\n",
    "#                 'RF',\n",
    "#                 'LR',\n",
    "#                 'DT',\n",
    "#                 # 'VOTING',\n",
    "#                 'Bag_svm',\n",
    "#                 'Bag_knn',\n",
    "#                 'Bag_DT',\n",
    "#                 'Bag_LR',\n",
    "#                 'Bag_mlp',\n",
    "#                 # 'avg',\n",
    "#                 # 'weighed_avg'\n",
    "#                 ]\n",
    "\n",
    "names_models = ['ADA',\n",
    "                'SVM',\n",
    "                'DNN',\n",
    "                'MLP',\n",
    "                'KNN',\n",
    "                'CAT',\n",
    "                'XGB',\n",
    "                'LGBM',\n",
    "                'RF',\n",
    "                'LR',\n",
    "                'DT',\n",
    "                # 'VOTING',\n",
    "                'Bag_svm',\n",
    "                'Bag_knn',\n",
    "                'Bag_DT',\n",
    "                'Bag_LR',\n",
    "                'Bag_mlp',\n",
    "\n",
    "                'Bag_rf',\n",
    "                'Bag_ada',\n",
    "                'Bag_lgbm',\n",
    "                # 'Bag_xgb',\n",
    "                'Bag_cat',\n",
    "                'Bag_comb',\n",
    "\n",
    "                # 'avg',\n",
    "                # 'weighed_avg'\n",
    "                ]\n",
    "\n",
    "\n",
    "level_00_acc = [ada_acc_00,\n",
    "                svm_acc_00,\n",
    "                dnn_acc_00,\n",
    "                mlp_acc_00,\n",
    "                knn_acc_00,\n",
    "                cat_acc_00,\n",
    "                xgb_acc_00,\n",
    "                lgbm_acc_00,\n",
    "                rf_acc_00,\n",
    "                lr_acc_00,\n",
    "                dt_acc_00,\n",
    "                # voting_acc_00,\n",
    "                bag_svm_acc_00,\n",
    "                bag_knn_acc_00,\n",
    "                bag_dt_acc_00,\n",
    "                bag_lr_acc_00,\n",
    "                bag_mlp_acc_00,\n",
    "               \n",
    "                bag_rf_acc_00,\n",
    "                bag_ada_acc_00,\n",
    "                bag_lgbm_acc_00,\n",
    "\n",
    "                bag_cat_acc_00,\n",
    "                bag_comb_acc_00,\n",
    "               \n",
    "               \n",
    "                \n",
    "                # avg_acc_00,\n",
    "                # weighed_avg_acc_00\n",
    "                ]  \n",
    "\n",
    "                # ]  \n",
    "\n",
    "level_00_pre = [ada_pre_00,\n",
    "                svm_pre_00,\n",
    "                dnn_pre_00,\n",
    "                mlp_pre_00,\n",
    "                knn_pre_00,\n",
    "                cat_pre_00,\n",
    "                xgb_pre_00,\n",
    "                lgbm_pre_00,\n",
    "                rf_pre_00,\n",
    "                lr_pre_00,\n",
    "                dt_pre_00,\n",
    "                # voting_pre_00,\n",
    "                bag_svm_pre_00,\n",
    "                bag_knn_pre_00,\n",
    "                bag_dt_pre_00,\n",
    "                bag_lr_pre_00,\n",
    "                bag_mlp_pre_00,\n",
    "\n",
    "                bag_rf_pre_00,\n",
    "                bag_ada_pre_00,\n",
    "                bag_lgbm_pre_00,\n",
    "\n",
    "                bag_cat_pre_00,\n",
    "                bag_comb_pre_00,\n",
    "               \n",
    "                # avg_pre_00,\n",
    "                # weighed_avg_pre_00\n",
    "                ]  \n",
    "\n",
    "level_00_rec = [ada_rec_00,\n",
    "                svm_rec_00,\n",
    "                dnn_rec_00,\n",
    "                mlp_rec_00,\n",
    "                knn_rec_00,\n",
    "                cat_rec_00,\n",
    "                xgb_rec_00,\n",
    "                lgbm_rec_00,\n",
    "                rf_rec_00,\n",
    "                lr_rec_00,\n",
    "                dt_rec_00,\n",
    "                # voting_rec_00,\n",
    "                bag_svm_rec_00,\n",
    "                bag_knn_rec_00,\n",
    "                bag_dt_rec_00,\n",
    "                bag_lr_rec_00,\n",
    "                bag_mlp_rec_00,\n",
    "\n",
    "                bag_rf_rec_00,\n",
    "                bag_ada_rec_00,\n",
    "                bag_lgbm_rec_00,\n",
    "\n",
    "                bag_cat_rec_00,\n",
    "                bag_comb_rec_00,\n",
    "               \n",
    "                # avg_rec_00,\n",
    "                # weighed_avg_rec_00\n",
    "                ]  \n",
    "\n",
    "level_00_f1 = [ada_f1_00,\n",
    "                svm_f1_00,\n",
    "                dnn_f1_00,\n",
    "                mlp_f1_00,\n",
    "                knn_f1_00,\n",
    "                cat_f1_00,\n",
    "                xgb_f1_00,\n",
    "                lgbm_f1_00,\n",
    "                rf_f1_00,\n",
    "                lr_f1_00,\n",
    "                dt_rec_00,\n",
    "                # voting_f1_00,\n",
    "                bag_svm_f1_00,\n",
    "                bag_knn_f1_00,\n",
    "                bag_dt_f1_00,\n",
    "                bag_lr_f1_00,\n",
    "                bag_mlp_f1_00,\n",
    "\n",
    "                bag_rf_f1_00,\n",
    "                bag_ada_f1_00,\n",
    "                bag_lgbm_f1_00,\n",
    "\n",
    "                bag_cat_f1_00,\n",
    "                bag_comb_f1_00,\n",
    "               \n",
    "                # avg_f1_00,\n",
    "                # weighed_avg_f1_00\n",
    "                ]                   \n",
    "\n",
    "for i in range(0,len(names_models)):\n",
    "    data[i][0] =  names_models[i]\n",
    "\n",
    "    data[i][1] = level_00_acc[i]\n",
    "    # data[i][2] = level_01_acc[i]\n",
    "\n",
    "    data[i][2] = level_00_pre[i] \n",
    "    # data[i][4] = level_01_pre[i]\n",
    "\n",
    "    data[i][3] = level_00_rec[i] \n",
    "    # data[i][6] = level_01_rec[i]\n",
    "\n",
    "    data[i][4] = level_00_f1[i]\n",
    "    # data[i][8] = level_01_f1[i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "# data[0][1] = ada_acc_00\n",
    "# data\n",
    "\n",
    "# Define column headers\n",
    "# headers = [\"Models\", \"ACC-00\", \" ACC-01\",\"PRE-00\", \" PRE-01\",\"REC-00\", \" REC-01\",\"F1-00\", \" F1-01\",]\n",
    "headers = [\"Models\", \"ACC-00\",\"PRE-00\",\"REC-00\",\"F1-00\"]\n",
    "\n",
    "\n",
    "# Print the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "print(table)\n",
    "with open(output_file_name, \"a\") as f: print(table, file = f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+\n",
      "| Models   |   ACC-00 |   PRE-00 |   REC-00 |    F1-00 |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| Bag_DT   | 0.979352 | 0.81605  | 0.789263 | 0.798081 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_lgbm | 0.980811 | 0.790636 | 0.774846 | 0.777762 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| LGBM     | 0.975514 | 0.758973 | 0.783135 | 0.767766 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| KNN      | 0.976412 | 0.847044 | 0.765066 | 0.764238 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_knn  | 0.976546 | 0.779105 | 0.765777 | 0.762737 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_cat  | 0.969118 | 0.737696 | 0.736019 | 0.736815 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_mlp  | 0.969005 | 0.73386  | 0.739233 | 0.736423 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| CAT      | 0.968601 | 0.735253 | 0.734851 | 0.735038 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| MLP      | 0.966626 | 0.726111 | 0.743367 | 0.734398 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| XGB      | 0.95206  | 0.714165 | 0.689462 | 0.700174 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_comb | 0.95527  | 0.752061 | 0.647175 | 0.676051 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_rf   | 0.929662 | 0.737676 | 0.563716 | 0.571188 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| RF       | 0.926901 | 0.703671 | 0.55448  | 0.555154 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_ada  | 0.738352 | 0.545722 | 0.547741 | 0.537939 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| ADA      | 0.757474 | 0.49015  | 0.518571 | 0.495145 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| SVM      | 0.866909 | 0.518517 | 0.488025 | 0.486543 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_svm  | 0.865405 | 0.564775 | 0.484479 | 0.484568 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| Bag_LR   | 0.859009 | 0.520372 | 0.469559 | 0.475378 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| LR       | 0.858829 | 0.519563 | 0.469184 | 0.475063 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| DNN      | 0.839662 | 0.336971 | 0.380104 | 0.356995 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Combine data into a list of tuples for sorting\n",
    "model_data = list(zip(names_models, level_00_acc, level_00_pre, level_00_rec, level_00_f1))\n",
    "\n",
    "# Sort by F1-00 score in descending order\n",
    "model_data_sorted = sorted(model_data, key=lambda x: x[4], reverse=True)\n",
    "\n",
    "# Separate the sorted data back into individual lists\n",
    "sorted_names_models, sorted_level_00_acc, sorted_level_00_pre, sorted_level_00_rec, sorted_level_00_f1 = zip(*model_data_sorted)\n",
    "\n",
    "# Assign the sorted data to the table\n",
    "for i in range(len(sorted_names_models)):\n",
    "    data[i][0] = sorted_names_models[i]\n",
    "    data[i][1] = sorted_level_00_acc[i]\n",
    "    data[i][2] = sorted_level_00_pre[i] \n",
    "    data[i][3] = sorted_level_00_rec[i] \n",
    "    data[i][4] = sorted_level_00_f1[i]\n",
    "\n",
    "# Define column headers\n",
    "headers = [\"Models\", \"ACC-00\", \"PRE-00\", \"REC-00\", \"F1-00\"]\n",
    "\n",
    "# Print the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "with open(output_file_name, \"a\") as f: print('Summary table - LEVEL 00', file = f)\n",
    "\n",
    "if feature_selection_bit == 1: \n",
    "    with open(output_file_name, \"a\") as f: print('Feature Selection was applied', file = f)\n",
    "else:\n",
    "    with open(output_file_name, \"a\") as f: print('All features were used', file = f)\n",
    "\n",
    "\n",
    "    \n",
    "print(table)\n",
    "with open(output_file_name, \"a\") as f: print(table, file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "| Models   | time-00(sec)       |\n",
      "+==========+====================+\n",
      "| RF       | 0.334575891494751  |\n",
      "+----------+--------------------+\n",
      "| LGBM     | 1.205275058746338  |\n",
      "+----------+--------------------+\n",
      "| Bag_knn  | 1.236325740814209  |\n",
      "+----------+--------------------+\n",
      "| ADA      | 2.2060389518737793 |\n",
      "+----------+--------------------+\n",
      "| CAT      | 2.634706974029541  |\n",
      "+----------+--------------------+\n",
      "| LR       | 3.022087335586548  |\n",
      "+----------+--------------------+\n",
      "| KNN      | 3.2511746883392334 |\n",
      "+----------+--------------------+\n",
      "| SVM      | 3.336155652999878  |\n",
      "+----------+--------------------+\n",
      "| Bag_mlp  | 4.391276597976685  |\n",
      "+----------+--------------------+\n",
      "| VOTING   | 5.176404714584351  |\n",
      "+----------+--------------------+\n",
      "| Bag_ada  | 10.407995462417603 |\n",
      "+----------+--------------------+\n",
      "| XGB      | 10.638646364212036 |\n",
      "+----------+--------------------+\n",
      "| Bag_svm  | 16.19873547554016  |\n",
      "+----------+--------------------+\n",
      "| Bag_rf   | 17.417508840560913 |\n",
      "+----------+--------------------+\n",
      "| Bag_lgbm | 26.665705919265747 |\n",
      "+----------+--------------------+\n",
      "| Bag_DT   | 31.71561074256897  |\n",
      "+----------+--------------------+\n",
      "| MLP      | 58.90101766586304  |\n",
      "+----------+--------------------+\n",
      "| DNN      | 74.72684073448181  |\n",
      "+----------+--------------------+\n",
      "| Bag_cat  | 106.44133281707764 |\n",
      "+----------+--------------------+\n",
      "| Bag_LR   | 565.8933959007263  |\n",
      "+----------+--------------------+\n",
      "|          |                    |\n",
      "+----------+--------------------+\n",
      "|          |                    |\n",
      "+----------+--------------------+\n",
      "|          |                    |\n",
      "+----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# implement time table\n",
    "from tabulate import tabulate\n",
    "\n",
    "names_models = ['ADA',\n",
    "                'SVM',\n",
    "                'DNN',\n",
    "                'MLP',\n",
    "                'KNN',\n",
    "                'CAT',\n",
    "                'XGB',\n",
    "                'LGBM',\n",
    "                'RF',\n",
    "                'LR',\n",
    "                'DT',\n",
    "                # 'VOTING',\n",
    "                'Bag_svm',\n",
    "                'Bag_knn',\n",
    "                'Bag_DT',\n",
    "                'Bag_LR',\n",
    "                'Bag_mlp',\n",
    "\n",
    "                'Bag_rf',\n",
    "                'Bag_ada',\n",
    "                'Bag_lgbm',\n",
    "                # 'Bag_xgb',\n",
    "                'Bag_cat',\n",
    "                'Bag_comb',\n",
    "                # 'avg',\n",
    "                # 'weighed_avg'\n",
    "                ]\n",
    "\n",
    "data = [[\"\" for _ in range(2)] for _ in range(len(names_models))]\n",
    "\n",
    "level_00_time = [\n",
    "                ada_time_00,\n",
    "                svm_time_00,\n",
    "                dnn_time_00,\n",
    "                mlp_time_00,\n",
    "                knn_time_00,\n",
    "                cat_time_00,\n",
    "                xgb_time_00,\n",
    "                lgbm_time_00,\n",
    "                rf_time_00,\n",
    "                lr_time_00,\n",
    "                dt_time_00,\n",
    "                # voting_time_00,\n",
    "                bag_svm_time_00,\n",
    "                bag_knn_time_00,\n",
    "                bag_dt_time_00,\n",
    "                bag_lr_time_00,\n",
    "                bag_mlp_time_00,\n",
    "\n",
    "                bag_rf_time_00,\n",
    "                bag_ada_time_00,\n",
    "                bag_lgbm_time_00,\n",
    "                # bag_xgb_time_00,\n",
    "                bag_cat_time_00,\n",
    "                bag_comb_time_00,\n",
    "\n",
    "                # avg_time_00,\n",
    "                # weighed_avg_time_00\n",
    "                ]  \n",
    "\n",
    "\n",
    "# Combine data into a list of tuples for sorting\n",
    "model_data = list(zip(names_models, level_00_time))\n",
    "\n",
    "# Sort by F1-00 score in descending order\n",
    "model_data_sorted = sorted(model_data, key=lambda x: x[1], reverse=False)\n",
    "\n",
    "# Separate the sorted data back into individual lists\n",
    "sorted_names_models, sorted_level_00_time = zip(*model_data_sorted)\n",
    "\n",
    "# Assign the sorted data to the table\n",
    "for i in range(len(sorted_names_models)):\n",
    "    data[i][0] = sorted_names_models[i]\n",
    "    data[i][1] = sorted_level_00_time[i]\n",
    "\n",
    "# Define column headers\n",
    "headers = [\"Models\", \"time-00(sec)\"]\n",
    "\n",
    "\n",
    "# Print the table\n",
    "table = tabulate(data, headers=headers, tablefmt=\"grid\")\n",
    "with open(output_file_name, \"a\") as f: print('Time is counted is seconds', file = f)\n",
    "print(table)\n",
    "with open(output_file_name, \"a\") as f: print(table, file = f)\n",
    "end_program = time.time()\n",
    "time_program = end_program - start_program\n",
    "with open(output_file_name, \"a\") as f: print('Running time of entire program is:', time_program ,' seconds',file = f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
