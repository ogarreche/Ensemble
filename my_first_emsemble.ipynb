{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First ensemble with NSL-KDD\n",
    "# Parameters\n",
    "\n",
    "#----------------------------------------------\n",
    "# 0 for not using it as base learner\n",
    "# 1 for using it as base learner\n",
    "\n",
    "use_model_ada = 1 \n",
    "use_model_dnn = 1 \n",
    "use_model_mlp = 1 \n",
    "use_model_lgbm = 1 \n",
    "use_model_rf = 1 \n",
    "use_model_svm = 1\n",
    "use_model_knn = 1 \n",
    "#----------------------------------------------\n",
    "# 0 for training the model\n",
    "# 1 for using the saved version of the model\n",
    "\n",
    "load_model_ada = 0 \n",
    "load_model_dnn = 0 \n",
    "load_model_mlp = 0 \n",
    "load_model_lgbm = 0 \n",
    "load_model_rf = 0 \n",
    "load_model_svm = 0\n",
    "load_model_knn = 0 \n",
    "#----------------------------------------------\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the name of the output text file\n",
    "output_file_name = \"My_fst_ensemble.txt\"\n",
    "with open(output_file_name, \"w\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "with open(output_file_name, \"a\") as f: print('---- Start Ensemble Model Info - v0 ----', file = f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "# importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle # saving and loading trained model\n",
    "from os import path\n",
    "\n",
    "\n",
    "# importing required libraries for normalizing data\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import (StandardScaler, OrdinalEncoder,LabelEncoder, MinMaxScaler, OneHotEncoder)\n",
    "from sklearn.preprocessing import Normalizer, MaxAbsScaler , RobustScaler, PowerTransformer\n",
    "\n",
    "# importing library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score # for calculating accuracy of model\n",
    "from sklearn.model_selection import train_test_split # for splitting the dataset for training and testing\n",
    "from sklearn.metrics import classification_report # for generating a classification report of model\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Dense # importing dense layer\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "# representation of model layers\n",
    "#from keras.utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import shap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "#Defining metric functions\n",
    "def ACC(TP,TN,FP,FN):\n",
    "    Acc = (TP+TN)/(TP+FP+FN+TN)\n",
    "    return Acc\n",
    "def ACC_2 (TP, FN):\n",
    "    ac = (TP/(TP+FN))\n",
    "    return ac\n",
    "def PRECISION(TP,FP):\n",
    "    eps = 1e-7\n",
    "    Precision = TP/(TP+FP+eps)\n",
    "    \n",
    "\n",
    "    return Precision\n",
    "def RECALL(TP,FN):\n",
    "    Recall = TP/(TP+FN)\n",
    "    return Recall\n",
    "def F1(Recall, Precision):\n",
    "    F1 = 2 * Recall * Precision / (Recall + Precision)\n",
    "    return F1\n",
    "def BACC(TP,TN,FP,FN):\n",
    "    BACC =(TP/(TP+FN)+ TN/(TN+FP))*0.5\n",
    "    return BACC\n",
    "def MCC(TP,TN,FP,FN):\n",
    "    eps = 1e-7\n",
    "    MCC = (TN*TP-FN*FP)/(((TP+FP+eps)*(TP+FN+eps)*(TN+FP+eps)*(TN+FN+eps))**.5)\n",
    "    return MCC\n",
    "def AUC_ROC(y_test_bin,y_score):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    auc_avg = 0\n",
    "    counting = 0\n",
    "    for i in range(n_classes):\n",
    "      fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "     # plt.plot(fpr[i], tpr[i], color='darkorange', lw=2)\n",
    "      #print('AUC for Class {}: {}'.format(i+1, auc(fpr[i], tpr[i])))\n",
    "      auc_avg += auc(fpr[i], tpr[i])\n",
    "      counting = i+1\n",
    "    return auc_avg/counting\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "# attach the column names to the dataset\n",
    "feature=[\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\n",
    "          \"num_failed_logins\",\"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\"num_shells\",\n",
    "          \"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\n",
    "          \"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\", \n",
    "          \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\n",
    "          \"dst_host_srv_serror_rate\",\"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\",\"difficulty\"]\n",
    "# KDDTrain+_2.csv & KDDTest+_2.csv are the datafiles without the last column about the difficulty score\n",
    "# these have already been removed.\n",
    "\n",
    "train='KDDTrain+.txt'\n",
    "test='KDDTest+.txt'\n",
    "\n",
    "df=pd.read_csv(train,names=feature)\n",
    "df_test=pd.read_csv(test,names=feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Training set: (125973, 43)\n",
      "Dimensions of the Test set: (22544, 43)\n",
      "Label distribution Training set:\n",
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Label distribution Test set:\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "loadmodule            2\n",
      "sqlattack             2\n",
      "worm                  2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "perl                  2\n",
      "imap                  1\n",
      "Name: label, dtype: int64\n",
      "Training set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'service' has 70 categories\n",
      "Feature 'flag' has 11 categories\n",
      "Feature 'label' has 23 categories\n",
      "\n",
      "Distribution of categories in service:\n",
      "http        40338\n",
      "private     21853\n",
      "domain_u     9043\n",
      "smtp         7313\n",
      "ftp_data     6860\n",
      "Name: service, dtype: int64\n",
      "Test set:\n",
      "Feature 'protocol_type' has 3 categories\n",
      "Feature 'service' has 64 categories\n",
      "Feature 'flag' has 11 categories\n",
      "Feature 'label' has 38 categories\n",
      "['Protocol_type_icmp', 'Protocol_type_tcp', 'Protocol_type_udp', 'service_IRC', 'service_X11', 'service_Z39_50', 'service_aol', 'service_auth', 'service_bgp', 'service_courier', 'service_csnet_ns', 'service_ctf', 'service_daytime', 'service_discard', 'service_domain', 'service_domain_u', 'service_echo', 'service_eco_i', 'service_ecr_i', 'service_efs', 'service_exec', 'service_finger', 'service_ftp', 'service_ftp_data', 'service_gopher', 'service_harvest', 'service_hostnames', 'service_http', 'service_http_2784', 'service_http_443', 'service_http_8001', 'service_imap4', 'service_iso_tsap', 'service_klogin', 'service_kshell', 'service_ldap', 'service_link', 'service_login', 'service_mtp', 'service_name', 'service_netbios_dgm', 'service_netbios_ns', 'service_netbios_ssn', 'service_netstat', 'service_nnsp', 'service_nntp', 'service_ntp_u', 'service_other', 'service_pm_dump', 'service_pop_2', 'service_pop_3', 'service_printer', 'service_private', 'service_red_i', 'service_remote_job', 'service_rje', 'service_shell', 'service_smtp', 'service_sql_net', 'service_ssh', 'service_sunrpc', 'service_supdup', 'service_systat', 'service_telnet', 'service_tftp_u', 'service_tim_i', 'service_time', 'service_urh_i', 'service_urp_i', 'service_uucp', 'service_uucp_path', 'service_vmnet', 'service_whois', 'flag_OTH', 'flag_REJ', 'flag_RSTO', 'flag_RSTOS0', 'flag_RSTR', 'flag_S0', 'flag_S1', 'flag_S2', 'flag_S3', 'flag_SF', 'flag_SH']\n",
      "   protocol_type  service  flag\n",
      "0              1       20     9\n",
      "1              2       44     9\n",
      "2              1       49     5\n",
      "3              1       24     9\n",
      "4              1       24     9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125973, 123)\n",
      "(22544, 123)\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: label, dtype: int64\n",
      "X_train has shape: (125973, 122) \n",
      "y_train has shape: (125973, 1)\n",
      "X_test has shape: (22544, 122) \n",
      "y_test has shape: (22544, 1)\n",
      "Counter({0: 67343, 1: 45927, 2: 11656, 3: 995, 4: 52})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# shape, this gives the dimensions of the dataset\n",
    "print('Dimensions of the Training set:',df.shape)\n",
    "print('Dimensions of the Test set:',df_test.shape)\n",
    "\n",
    "\n",
    "df.drop(['difficulty'],axis=1,inplace=True)\n",
    "df_test.drop(['difficulty'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "print('Label distribution Training set:')\n",
    "print(df['label'].value_counts())\n",
    "print()\n",
    "print('Label distribution Test set:')\n",
    "print(df_test['label'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# colums that are categorical and not binary yet: protocol_type (column 2), service (column 3), flag (column 4).\n",
    "# explore categorical features\n",
    "print('Training set:')\n",
    "for col_name in df.columns:\n",
    "    if df[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "#see how distributed the feature service is, it is evenly distributed and therefore we need to make dummies for all.\n",
    "print()\n",
    "print('Distribution of categories in service:')\n",
    "print(df['service'].value_counts().sort_values(ascending=False).head())\n",
    "\n",
    "\n",
    "\n",
    "# Test set\n",
    "print('Test set:')\n",
    "for col_name in df_test.columns:\n",
    "    if df_test[col_name].dtypes == 'object' :\n",
    "        unique_cat = len(df_test[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} categories\".format(col_name=col_name, unique_cat=unique_cat))\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "categorical_columns=['protocol_type', 'service', 'flag']\n",
    "# insert code to get a list of categorical columns into a variable, categorical_columns\n",
    "categorical_columns=['protocol_type', 'service', 'flag'] \n",
    " # Get the categorical values into a 2D numpy array\n",
    "df_categorical_values = df[categorical_columns]\n",
    "testdf_categorical_values = df_test[categorical_columns]\n",
    "df_categorical_values.head()\n",
    "\n",
    "\n",
    "# protocol type\n",
    "unique_protocol=sorted(df.protocol_type.unique())\n",
    "string1 = 'Protocol_type_'\n",
    "unique_protocol2=[string1 + x for x in unique_protocol]\n",
    "# service\n",
    "unique_service=sorted(df.service.unique())\n",
    "string2 = 'service_'\n",
    "unique_service2=[string2 + x for x in unique_service]\n",
    "# flag\n",
    "unique_flag=sorted(df.flag.unique())\n",
    "string3 = 'flag_'\n",
    "unique_flag2=[string3 + x for x in unique_flag]\n",
    "# put together\n",
    "dumcols=unique_protocol2 + unique_service2 + unique_flag2\n",
    "print(dumcols)\n",
    "\n",
    "#do same for test set\n",
    "unique_service_test=sorted(df_test.service.unique())\n",
    "unique_service2_test=[string2 + x for x in unique_service_test]\n",
    "testdumcols=unique_protocol2 + unique_service2_test + unique_flag2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_categorical_values_enc=df_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "print(df_categorical_values_enc.head())\n",
    "# test set\n",
    "testdf_categorical_values_enc=testdf_categorical_values.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "df_categorical_values_encenc = enc.fit_transform(df_categorical_values_enc)\n",
    "df_cat_data = pd.DataFrame(df_categorical_values_encenc.toarray(),columns=dumcols)\n",
    "# test set\n",
    "testdf_categorical_values_encenc = enc.fit_transform(testdf_categorical_values_enc)\n",
    "testdf_cat_data = pd.DataFrame(testdf_categorical_values_encenc.toarray(),columns=testdumcols)\n",
    "\n",
    "df_cat_data.head()\n",
    "\n",
    "\n",
    "trainservice=df['service'].tolist()\n",
    "testservice= df_test['service'].tolist()\n",
    "difference=list(set(trainservice) - set(testservice))\n",
    "string = 'service_'\n",
    "difference=[string + x for x in difference]\n",
    "difference\n",
    "\n",
    "for col in difference:\n",
    "    testdf_cat_data[col] = 0\n",
    "\n",
    "testdf_cat_data.shape\n",
    "\n",
    "newdf=df.join(df_cat_data)\n",
    "newdf.drop('flag', axis=1, inplace=True)\n",
    "newdf.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf.drop('service', axis=1, inplace=True)\n",
    "# test data\n",
    "newdf_test=df_test.join(testdf_cat_data)\n",
    "newdf_test.drop('flag', axis=1, inplace=True)\n",
    "newdf_test.drop('protocol_type', axis=1, inplace=True)\n",
    "newdf_test.drop('service', axis=1, inplace=True)\n",
    "print(newdf.shape)\n",
    "print(newdf_test.shape)\n",
    "\n",
    "\n",
    "# take label column\n",
    "labeldf=newdf['label']\n",
    "labeldf_test=newdf_test['label']\n",
    "# change the label column\n",
    "newlabeldf=labeldf.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "newlabeldf_test=labeldf_test.replace({ 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4})\n",
    "# put the new label column back\n",
    "newdf['label'] = newlabeldf\n",
    "newdf_test['label'] = newlabeldf_test\n",
    "print(newdf['label'].head())\n",
    "\n",
    "\n",
    "# Specify your selected features. Note that you'll need to modify this list according to your final processed dataframe\n",
    "#Uncomment the below lines to use these top 20 features from shap analysis\n",
    "#selected_features = [\"root_shell\",\"service_telnet\",\"num_shells\",\"service_uucp\",\"dst_host_same_src_port_rate\"\n",
    "#                     ,\"dst_host_rerror_rate\",\"dst_host_srv_serror_rate\",\"dst_host_srv_count\",\"service_private\",\"logged_in\",\n",
    "#                    \"dst_host_serror_rate\",\"serror_rate\",\"srv_serror_rate\",\"flag_S0\",\"diff_srv_rate\",\"dst_host_srv_diff_host_rate\",\"num_file_creations\",\"flag_RSTR\"#,\"dst_host_same_srv_rate\",\"service_Idap\",\"label\"]\n",
    "                     \n",
    "\n",
    "# Select those features from your dataframe\n",
    "#newdf = newdf[selected_features]\n",
    "#newdf_test = newdf_test[selected_features]\n",
    "\n",
    "# Now your dataframe only contains your selected features.\n",
    "\n",
    "# creating a dataframe with multi-class labels (Dos,Probe,R2L,U2R,normal)\n",
    "multi_data = newdf.copy()\n",
    "multi_label = pd.DataFrame(multi_data.label)\n",
    "\n",
    "multi_data_test=newdf_test.copy()\n",
    "multi_label_test = pd.DataFrame(multi_data_test.label)\n",
    "\n",
    "\n",
    "# using standard scaler for normalizing\n",
    "std_scaler = StandardScaler()\n",
    "def standardization(df,col):\n",
    "    for i in col:\n",
    "        arr = df[i]\n",
    "        arr = np.array(arr)\n",
    "        df[i] = std_scaler.fit_transform(arr.reshape(len(arr),1))\n",
    "    return df\n",
    "\n",
    "numeric_col = multi_data.select_dtypes(include='number').columns\n",
    "data = standardization(multi_data,numeric_col)\n",
    "numeric_col_test = multi_data_test.select_dtypes(include='number').columns\n",
    "data_test = standardization(multi_data_test,numeric_col_test)\n",
    "\n",
    "# label encoding (0,1,2,3,4) multi-class labels (Dos,normal,Probe,R2L,U2R)\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2_test = preprocessing.LabelEncoder()\n",
    "enc_label = multi_label.apply(le2.fit_transform)\n",
    "enc_label_test = multi_label_test.apply(le2_test.fit_transform)\n",
    "multi_data = multi_data.copy()\n",
    "multi_data_test = multi_data_test.copy()\n",
    "\n",
    "multi_data['intrusion'] = enc_label\n",
    "multi_data_test['intrusion'] = enc_label_test\n",
    "\n",
    "#y_mul = multi_data['intrusion']\n",
    "multi_data\n",
    "multi_data_test\n",
    "\n",
    "\n",
    "\n",
    "multi_data.drop(labels= [ 'label'], axis=1, inplace=True)\n",
    "multi_data\n",
    "multi_data_test.drop(labels= [ 'label'], axis=1, inplace=True)\n",
    "multi_data_test\n",
    "\n",
    "\n",
    "y_train_multi= multi_data[['intrusion']]\n",
    "X_train_multi= multi_data.drop(labels=['intrusion'], axis=1)\n",
    "\n",
    "print('X_train has shape:',X_train_multi.shape,'\\ny_train has shape:',y_train_multi.shape)\n",
    "\n",
    "y_test_multi= multi_data_test[['intrusion']]\n",
    "X_test_multi= multi_data_test.drop(labels=['intrusion'], axis=1)\n",
    "\n",
    "print('X_test has shape:',X_test_multi.shape,'\\ny_test has shape:',y_test_multi.shape)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "label_counts = Counter(y_train_multi['intrusion'])\n",
    "print(label_counts)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "y_train_multi = LabelBinarizer().fit_transform(y_train_multi)\n",
    "\n",
    "y_test_multi = LabelBinarizer().fit_transform(y_test_multi)\n",
    "\n",
    "\n",
    "Y_train=y_train_multi.copy()\n",
    "X_train=X_train_multi.copy()\n",
    "\n",
    "Y_test=y_test_multi.copy()\n",
    "X_test=X_test_multi.copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.feature_selection import SelectKBest, f_classif\\n\\n# Number of best features you want to select\\nk = 15\\n\\n# Initialize a dataframe to store the scores for each feature against each class\\nfeature_scores = pd.DataFrame(index=X_train.columns)\\n\\n# Loop through each class\\nfor class_index in range(Y_train.shape[1]):\\n    \\n    # Get the current class labels\\n    y_train_current_class = Y_train[:, class_index]\\n    \\n    # Select K best features for the current class\\n    best_features = SelectKBest(score_func=f_classif, k=\\'all\\')\\n    fit = best_features.fit(X_train, y_train_current_class)\\n\\n    # Get the scores\\n    df_scores = pd.DataFrame(fit.scores_, index=X_train.columns, columns=[f\"class_{class_index}\"])\\n    \\n    # Concatenate the scores to the main dataframe\\n    feature_scores = pd.concat([feature_scores, df_scores],axis=1)\\n\\n# Get the sum of the scores for each feature\\nfeature_scores[\\'total\\'] = feature_scores.sum(axis=1)\\n\\n# Get the top k features in a list\\ntop_k_features = feature_scores.nlargest(k, \\'total\\').index.tolist()\\n\\nprint(top_k_features)\\n\\n'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# In[24]:\n",
    "\n",
    "'''\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Number of best features you want to select\n",
    "k = 15\n",
    "\n",
    "# Initialize a dataframe to store the scores for each feature against each class\n",
    "feature_scores = pd.DataFrame(index=X_train.columns)\n",
    "\n",
    "# Loop through each class\n",
    "for class_index in range(Y_train.shape[1]):\n",
    "    \n",
    "    # Get the current class labels\n",
    "    y_train_current_class = Y_train[:, class_index]\n",
    "    \n",
    "    # Select K best features for the current class\n",
    "    best_features = SelectKBest(score_func=f_classif, k='all')\n",
    "    fit = best_features.fit(X_train, y_train_current_class)\n",
    "\n",
    "    # Get the scores\n",
    "    df_scores = pd.DataFrame(fit.scores_, index=X_train.columns, columns=[f\"class_{class_index}\"])\n",
    "    \n",
    "    # Concatenate the scores to the main dataframe\n",
    "    feature_scores = pd.concat([feature_scores, df_scores],axis=1)\n",
    "\n",
    "# Get the sum of the scores for each feature\n",
    "feature_scores['total'] = feature_scores.sum(axis=1)\n",
    "\n",
    "# Get the top k features in a list\n",
    "top_k_features = feature_scores.nlargest(k, 'total').index.tolist()\n",
    "\n",
    "print(top_k_features)\n",
    "\n",
    "'''\n",
    "# In[32]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " ...\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 1 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.10249223e-01, -7.67859947e-03, -4.91864438e-03, ...,\n",
       "        -1.97262160e-02,  8.25150071e-01, -4.64315895e-02],\n",
       "       [-1.10249223e-01, -7.73736981e-03, -4.91864438e-03, ...,\n",
       "        -1.97262160e-02,  8.25150071e-01, -4.64315895e-02],\n",
       "       [-1.10249223e-01, -7.76224074e-03, -4.91864438e-03, ...,\n",
       "        -1.97262160e-02, -1.21190076e+00, -4.64315895e-02],\n",
       "       ...,\n",
       "       [-9.29714678e-02, -7.36430591e-03, -3.87394518e-03, ...,\n",
       "        -1.97262160e-02,  8.25150071e-01, -4.64315895e-02],\n",
       "       [-8.68282658e-02, -7.36430591e-03, -3.87568593e-03, ...,\n",
       "        -1.97262160e-02,  8.25150071e-01, -4.64315895e-02],\n",
       "       [ 1.61587463e-01, -7.46804833e-03,  1.06953862e-03, ...,\n",
       "        -1.97262160e-02,  8.25150071e-01, -4.64315895e-02]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Assuming you have features X and labels Y\n",
    "# X, Y = make_classification()\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy='minority', random_state=100)\n",
    "\n",
    "X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "print(Y_test)\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "X_train.values\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_class_train = np.argmax(y_train_multi, axis=1)\n",
    "single_class_test = np.argmax(y_test_multi, axis=1)\n",
    "\n",
    "\n",
    "df1 = X_train_multi.assign(Label = single_class_train)\n",
    "df2 =  X_test_multi.assign(Label = single_class_test)\n",
    "\n",
    "frames = [df1,  df2]\n",
    "\n",
    "df = pd.concat(frames,ignore_index=True)\n",
    "\n",
    "y = df.pop('Label')\n",
    "X = df\n",
    "\n",
    "y1, y2 = pd.factorize(y)\n",
    "\n",
    "y_0 = pd.DataFrame(y1)\n",
    "y_1 = pd.DataFrame(y1)\n",
    "y_2 = pd.DataFrame(y1)\n",
    "y_3 = pd.DataFrame(y1)\n",
    "y_4 = pd.DataFrame(y1)\n",
    "\n",
    "\n",
    "# y_0 = y_0.replace(0, 0)\n",
    "# y_0 = y_0.replace(1, 1)\n",
    "y_0 = y_0.replace(2, 1)\n",
    "y_0 = y_0.replace(3, 1)\n",
    "y_0 = y_0.replace(4, 1)\n",
    "\n",
    "\n",
    "y_1 = y_1.replace(1, 999)\n",
    "y_1 = y_1.replace(0, 1)\n",
    "# y_1 = y_1.replace(1, 0)\n",
    "y_1 = y_1.replace(2, 1)\n",
    "y_1 = y_1.replace(3, 1)\n",
    "y_1 = y_1.replace(4, 1)\n",
    "y_1 = y_1.replace(999, 1)\n",
    "\n",
    "\n",
    "y_2 = y_2.replace(0, 1)\n",
    "y_2 = y_2.replace(1, 1)\n",
    "y_2 = y_2.replace(2, 0)\n",
    "y_2 = y_2.replace(3, 1)\n",
    "y_2 = y_2.replace(4, 1)\n",
    "\n",
    "\n",
    "y_3 = y_3.replace(0, 1)\n",
    "# y_3 = y_3.replace(1, 1)\n",
    "y_3 = y_3.replace(2, 1)\n",
    "y_3 = y_3.replace(3, 0)\n",
    "y_3 = y_3.replace(4, 1)\n",
    "\n",
    "\n",
    "y_4 = y_4.replace(0, 1)\n",
    "# y_4 = y_4.replace(1, 1)\n",
    "y_4 = y_4.replace(2, 1)\n",
    "y_4 = y_4.replace(3, 1)\n",
    "y_4 = y_4.replace(4, 0)\n",
    "\n",
    "\n",
    "\n",
    "df = df.assign(Label = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the dataset between level 00 and level 01\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "split = 0.6 # 0.7\n",
    "\n",
    "# X_00,X_01, y_00, y_01 = sklearn.model_selection.train_test_split(X, y, train_size=split)\n",
    "X_train,X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, train_size=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 77054, 1: 53387, 2: 14077, 3: 3880, 4: 119})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "label_counts2 = Counter(y)\n",
    "print(label_counts2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base learner Split\n",
    "# split = 0.7\n",
    "\n",
    "# X_train,X_test, y_train, y_test = sklearn.model_selection.train_test_split(X_00, y_00, train_size=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTOS0</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>flag_SH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>1.616978</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-1.211901</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89149</th>\n",
       "      <td>-0.109865</td>\n",
       "      <td>-0.007463</td>\n",
       "      <td>-0.004828</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>-0.618438</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>0.825150</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44682</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>1.616978</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-1.211901</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97916</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>1.616978</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-1.211901</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105826</th>\n",
       "      <td>-0.052657</td>\n",
       "      <td>-0.007733</td>\n",
       "      <td>0.030866</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>0.030104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>-0.618438</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>0.825150</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42108</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>1.616978</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-1.211901</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39197</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007707</td>\n",
       "      <td>-0.004289</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>-0.618438</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>0.825150</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35922</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>1.616978</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>-1.211901</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11744</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007714</td>\n",
       "      <td>-0.004659</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.312889</td>\n",
       "      <td>-0.11205</td>\n",
       "      <td>-0.028606</td>\n",
       "      <td>-0.139982</td>\n",
       "      <td>-0.618438</td>\n",
       "      <td>-0.053906</td>\n",
       "      <td>-0.031767</td>\n",
       "      <td>-0.019726</td>\n",
       "      <td>0.825150</td>\n",
       "      <td>-0.046432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132542</th>\n",
       "      <td>-0.155534</td>\n",
       "      <td>-0.021988</td>\n",
       "      <td>-0.096896</td>\n",
       "      <td>-0.017624</td>\n",
       "      <td>-0.059104</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>-0.113521</td>\n",
       "      <td>-0.143999</td>\n",
       "      <td>-0.890373</td>\n",
       "      <td>-0.016494</td>\n",
       "      <td>...</td>\n",
       "      <td>2.203539</td>\n",
       "      <td>-0.18843</td>\n",
       "      <td>-0.009419</td>\n",
       "      <td>-0.174880</td>\n",
       "      <td>-0.313124</td>\n",
       "      <td>-0.030535</td>\n",
       "      <td>-0.025803</td>\n",
       "      <td>-0.105681</td>\n",
       "      <td>-1.392705</td>\n",
       "      <td>-0.056997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89110 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  src_bytes  dst_bytes      land  wrong_fragment    urgent  \\\n",
       "4157   -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "89149  -0.109865  -0.007463  -0.004828 -0.014089       -0.089486 -0.007736   \n",
       "44682  -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "97916  -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "105826 -0.052657  -0.007733   0.030866 -0.014089       -0.089486 -0.007736   \n",
       "...          ...        ...        ...       ...             ...       ...   \n",
       "42108  -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "39197  -0.110249  -0.007707  -0.004289 -0.014089       -0.089486 -0.007736   \n",
       "35922  -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "11744  -0.110249  -0.007714  -0.004659 -0.014089       -0.089486 -0.007736   \n",
       "132542 -0.155534  -0.021988  -0.096896 -0.017624       -0.059104 -0.019459   \n",
       "\n",
       "             hot  num_failed_logins  logged_in  num_compromised  ...  \\\n",
       "4157   -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "89149  -0.095076          -0.027023   1.235694        -0.011664  ...   \n",
       "44682  -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "97916  -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "105826 -0.095076          -0.027023   1.235694         0.030104  ...   \n",
       "...          ...                ...        ...              ...  ...   \n",
       "42108  -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "39197  -0.095076          -0.027023   1.235694        -0.011664  ...   \n",
       "35922  -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "11744  -0.095076          -0.027023   1.235694        -0.011664  ...   \n",
       "132542 -0.113521          -0.143999  -0.890373        -0.016494  ...   \n",
       "\n",
       "        flag_REJ  flag_RSTO  flag_RSTOS0  flag_RSTR   flag_S0   flag_S1  \\\n",
       "4157   -0.312889   -0.11205    -0.028606  -0.139982  1.616978 -0.053906   \n",
       "89149  -0.312889   -0.11205    -0.028606  -0.139982 -0.618438 -0.053906   \n",
       "44682  -0.312889   -0.11205    -0.028606  -0.139982  1.616978 -0.053906   \n",
       "97916  -0.312889   -0.11205    -0.028606  -0.139982  1.616978 -0.053906   \n",
       "105826 -0.312889   -0.11205    -0.028606  -0.139982 -0.618438 -0.053906   \n",
       "...          ...        ...          ...        ...       ...       ...   \n",
       "42108  -0.312889   -0.11205    -0.028606  -0.139982  1.616978 -0.053906   \n",
       "39197  -0.312889   -0.11205    -0.028606  -0.139982 -0.618438 -0.053906   \n",
       "35922  -0.312889   -0.11205    -0.028606  -0.139982  1.616978 -0.053906   \n",
       "11744  -0.312889   -0.11205    -0.028606  -0.139982 -0.618438 -0.053906   \n",
       "132542  2.203539   -0.18843    -0.009419  -0.174880 -0.313124 -0.030535   \n",
       "\n",
       "         flag_S2   flag_S3   flag_SF   flag_SH  \n",
       "4157   -0.031767 -0.019726 -1.211901 -0.046432  \n",
       "89149  -0.031767 -0.019726  0.825150 -0.046432  \n",
       "44682  -0.031767 -0.019726 -1.211901 -0.046432  \n",
       "97916  -0.031767 -0.019726 -1.211901 -0.046432  \n",
       "105826 -0.031767 -0.019726  0.825150 -0.046432  \n",
       "...          ...       ...       ...       ...  \n",
       "42108  -0.031767 -0.019726 -1.211901 -0.046432  \n",
       "39197  -0.031767 -0.019726  0.825150 -0.046432  \n",
       "35922  -0.031767 -0.019726 -1.211901 -0.046432  \n",
       "11744  -0.031767 -0.019726  0.825150 -0.046432  \n",
       "132542 -0.025803 -0.105681 -1.392705 -0.056997  \n",
       "\n",
       "[89110 rows x 122 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4157      1\n",
       "89149     0\n",
       "44682     1\n",
       "97916     1\n",
       "105826    0\n",
       "         ..\n",
       "42108     1\n",
       "39197     0\n",
       "35922     1\n",
       "11744     0\n",
       "132542    1\n",
       "Name: Label, Length: 89110, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEVEL 0 - Weak models - Base Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Defining RF Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Defining ADA Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Defining LGBM Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Defining KNN Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Defining SVM Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Defining MLP Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Defining DNN Model\n",
      "---------------------------------------------------------------------------------\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open(output_file_name, \"a\") as f: print('------------START of WEAK LEARNERS (BASE MODELS) - STACK 00 -----------------', file = f)\n",
    "\n",
    "#Defining Basemodels\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining RF Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "rf = RandomForestClassifier(max_depth = 5,  n_estimators = 10, min_samples_split = 2, n_jobs = -1)\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining ADA Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "#ADA\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import time\n",
    "abc = AdaBoostClassifier(n_estimators=50, learning_rate=1.0)\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining LGBM Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "#LGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm = LGBMClassifier()\n",
    "\n",
    "\n",
    "\n",
    "#KNN\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining KNN Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf=KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "\n",
    "#SVM\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining SVM Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Instantiate the SGDClassifier with additional hyperparameters\n",
    "clf = SGDClassifier(\n",
    "    loss='hinge',           # hinge loss for linear SVM\n",
    "    penalty='l2',           # L2 regularization to prevent overfitting\n",
    "    alpha=1e-4,             # Learning rate (small value for fine-grained updates)\n",
    "    max_iter=1000,          # Number of passes over the training data\n",
    "    random_state=42,        # Seed for reproducible results\n",
    "    learning_rate='optimal' # Automatically adjusts the learning rate based on the training data\n",
    ")\n",
    "\n",
    "\n",
    "#MLP\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining MLP Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import time\n",
    "\n",
    "# create MLPClassifier instance\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=200, random_state=1)\n",
    "\n",
    "\n",
    "#DNN\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining DNN Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#Model Parameters\n",
    "dropout_rate = 0.01\n",
    "nodes = 70\n",
    "out_layer = 5\n",
    "optimizer='adam'\n",
    "loss='sparse_categorical_crossentropy'\n",
    "epochs=1\n",
    "batch_size=2*256\n",
    "\n",
    "\n",
    "num_columns = X_train.shape[1]\n",
    "\n",
    "dnn = tf.keras.Sequential()\n",
    "\n",
    "# Input layer\n",
    "dnn.add(tf.keras.Input(shape=(num_columns,)))\n",
    "\n",
    "# Dense layers with dropout\n",
    "dnn.add(tf.keras.layers.Dense(nodes))\n",
    "dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "dnn.add(tf.keras.layers.Dense(nodes))\n",
    "dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "dnn.add(tf.keras.layers.Dense(nodes))\n",
    "dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "dnn.add(tf.keras.layers.Dense(nodes))\n",
    "dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "dnn.add(tf.keras.layers.Dense(nodes))\n",
    "dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "# Output layer\n",
    "dnn.add(tf.keras.layers.Dense(out_layer))\n",
    "\n",
    "\n",
    "\n",
    "dnn.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "dnn.summary()\n",
    "\n",
    "\n",
    "\n",
    "# dnn = Sequential()\n",
    "# dnn.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))  # Input layer\n",
    "# dnn.add(Dense(64, activation='relu'))  # Hidden layer\n",
    "# dnn.add(Dense(5))  # Output layer\n",
    "\n",
    "# dnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# # summary of model layers\n",
    "# dnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #SVM\n",
    "# # Wrap SGDClassifier with MultiOutputClassifier\n",
    "# multi_target_clf = MultiOutputClassifier(clf)\n",
    "\n",
    "# # Fit the model on the training data\n",
    "# multi_target_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Training Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Training ADA\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.80888789 0.82751655 0.82269106 0.59852991 0.73291438]\n",
      "Mean accuracy: 0.75810795645831\n",
      "---------------------------------------------------------------------------------\n",
      "Training RF\n",
      "---------------------------------------------------------------------------------\n",
      "Cross-validation scores: [0.94529234 0.93956907 0.94226237 0.94428235 0.9381102 ]\n",
      "Mean accuracy: 0.9419032656267534\n",
      "---------------------------------------------------------------------------------\n",
      "Training SVM\n",
      "---------------------------------------------------------------------------------\n",
      "Cross-validation scores: [0.96835372 0.96919538 0.96812928 0.96627763 0.96711929]\n",
      "Mean accuracy: 0.9678150600381551\n",
      "---------------------------------------------------------------------------------\n",
      "Training KNN\n",
      "---------------------------------------------------------------------------------\n",
      "Cross-validation scores: [0.98905847 0.98776793 0.98877791 0.98984401 0.98990012]\n",
      "Mean accuracy: 0.9890696891482437\n",
      "---------------------------------------------------------------------------------\n",
      "Training LGBM\n",
      "---------------------------------------------------------------------------------\n",
      "Cross-validation scores: [0.9698687  0.97519919 0.97996858 0.97261811 0.98485019]\n",
      "Mean accuracy: 0.9765009538772305\n",
      "---------------------------------------------------------------------------------\n",
      "Training MLP\n",
      "---------------------------------------------------------------------------------\n",
      "Cross-validation scores: [0.99287398 0.99231287 0.99231287 0.99321064 0.99051734]\n",
      "Mean accuracy: 0.9922455392211873\n",
      "---------------------------------------------------------------------------------\n",
      "Training DNN\n",
      "---------------------------------------------------------------------------------\n",
      "175/175 [==============================] - 1s 7ms/step - loss: 1.6195\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<keras.engine.sequential.Sequential object at 0x7f9762adf358>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/HITL/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HITL/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-6fad66aaa2a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0mstratified_kfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;31m# Perform cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratified_kfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;31m# Print the cross-validation scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cross-validation scores:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HITL/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HITL/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    404\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HITL/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HITL/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 248\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HITL/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HITL/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    834\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m                 \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HITL/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 248\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HITL/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/HITL/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     80\u001b[0m                                 \u001b[0;34m\"estimator as it does not implement a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                                 \u001b[0;34m\"'get_params' method.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                                 % (repr(estimator), type(estimator)))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object '<keras.engine.sequential.Sequential object at 0x7f9762adf358>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "#Training Basemodels\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "n_splits = 5  # You can adjust the number of folds as needed\n",
    "\n",
    "\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Training Model')\n",
    "with open(output_file_name, \"a\") as f: print('Training weak models - level 0', file = f)\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_ada == 1 and load_model_ada == 0:\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training ADA')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training ADA', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #ADA\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    ada = abc.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(ada, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "\n",
    "    # Assuming 'model' is your trained model\n",
    "    joblib.dump(ada, 'ada_base_model.joblib')\n",
    "\n",
    "\n",
    "if use_model_rf == 1 and load_model_rf == 0:\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training RF')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Training RF', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #RF\n",
    "    start = time.time()\n",
    "    model_rf = rf.fit(X_train,y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model_rf, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    joblib.dump(model_rf, 'rf_base_model.joblib')\n",
    "\n",
    "if use_model_svm == 1 and load_model_svm == 0:\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training SVM')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training SVM', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #SVM\n",
    "\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    # clf.score(X_train, y_train)\n",
    "    time_taken = end - start\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(clf, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    joblib.dump(clf, 'svm_base_model.joblib')\n",
    "\n",
    "\n",
    "if use_model_knn == 1 and load_model_knn == 0:\n",
    "\n",
    "    #KNN\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training KNN')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training KNN', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    start = time.time()\n",
    "    knn_clf.fit(X_train,y_train)\n",
    "    end = time.time()\n",
    "\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(knn_clf, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    joblib.dump(knn_clf, 'knn_base_model.joblib')\n",
    "\n",
    "\n",
    "if use_model_lgbm == 1 and load_model_lgbm == 0:\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training LGBM')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training LGBM', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    start = time.time()\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(lgbm, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    joblib.dump(lgbm, 'lgbm_base_model.joblib')\n",
    "\n",
    "if use_model_mlp == 1 and load_model_mlp == 0:\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training MLP')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training MLP', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "    start = time.time()\n",
    "    MLP = mlp.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(MLP, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    joblib.dump(MLP, 'mlp_base_model.joblib')\n",
    "\n",
    "\n",
    "if use_model_dnn == 1 and load_model_dnn == 0:\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Training DNN')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Training DNN', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    # Convert Y_test back to its original format\n",
    "    # y_test = np.argmax(Y_test, axis=1)\n",
    "\n",
    "    # Start the timer\n",
    "    start = time.time()\n",
    "    dnn.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    # End the timer\n",
    "    end = time.time()\n",
    "\n",
    "    # Create the StratifiedKFold object\n",
    "    stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(dnn, X_train, y_train, cv=stratified_kfold, scoring='accuracy')\n",
    "    # Print the cross-validation scores\n",
    "    print(\"Cross-validation scores:\", cv_scores)\n",
    "    print(\"Mean accuracy:\", cv_scores.mean())\n",
    "    with open(output_file_name, \"a\") as f: print('mean accuracy', cv_scores.mean() , file = f)\n",
    "\n",
    "\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "    dnn.save(\"DNN_base_model.h5\")\n",
    "\n",
    "    # Calculate the time taken and print it out\n",
    "    # print(f'Time taken for training: {time_taken} seconds')\n",
    "\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_72 (Dense)             (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_96 (Dense)             (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_108 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_98 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_120 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_102 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_126 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_132 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_138 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_144 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_150 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_127 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_129 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_156 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_130 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_131 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_132 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_133 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_134 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_162 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_136 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_168 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_174 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_180 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_152 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_153 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_154 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_186 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_155 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_157 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_159 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_192 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_161 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_162 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_163 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_164 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_198 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_165 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_166 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_167 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_168 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_169 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_204 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_170 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_171 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_172 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_173 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_174 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_210 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_175 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_176 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_178 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_179 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_216 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_180 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_181 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_182 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_183 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_184 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_222 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_185 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_186 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_187 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_188 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_189 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_228 (Dense)            (None, 70)                8610      \n",
      "_________________________________________________________________\n",
      "dropout_190 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_191 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_192 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_193 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_194 (Dropout)        (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 28,845\n",
      "Trainable params: 28,845\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Best Parameters:  {'hidden_layer_size': 16, 'optimizer': 'adam'}\n",
      "Best Accuracy:  0.3431489170687914\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define your Keras model as a function\n",
    "def create_model(optimizer='adam', hidden_layer_size=16):\n",
    "    # model = Sequential()\n",
    "    # model.add(Dense(hidden_layer_size, input_dim=input_size, activation='relu'))\n",
    "    # model.add(Dense(1, activation='sigmoid'))\n",
    "    # model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        \n",
    "    dnn = tf.keras.Sequential()\n",
    "\n",
    "    # Input layer\n",
    "    dnn.add(tf.keras.Input(shape=(num_columns,)))\n",
    "\n",
    "    # Dense layers with dropout\n",
    "    dnn.add(tf.keras.layers.Dense(nodes))\n",
    "    dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    dnn.add(tf.keras.layers.Dense(nodes))\n",
    "    dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    dnn.add(tf.keras.layers.Dense(nodes))\n",
    "    dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    dnn.add(tf.keras.layers.Dense(nodes))\n",
    "    dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    dnn.add(tf.keras.layers.Dense(nodes))\n",
    "    dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer\n",
    "    dnn.add(tf.keras.layers.Dense(out_layer))\n",
    "\n",
    "\n",
    "\n",
    "    dnn.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    dnn.summary()\n",
    "    return dnn\n",
    "\n",
    "# Create a KerasClassifier\n",
    "dnn = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'hidden_layer_size': [8, 16, 32]\n",
    "}\n",
    "\n",
    "# Create the StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid = GridSearchCV(estimator=dnn, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best accuracy\n",
    "print(\"Best Parameters: \", grid_result.best_params_)\n",
    "print(\"Best Accuracy: \", grid_result.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stratified_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Models\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "if load_model_ada == 1:\n",
    "    ada = loaded_model = joblib.load('ada_base_model.joblib')\n",
    "\n",
    "if load_model_svm == 1:\n",
    "    clf = loaded_model = joblib.load('svm_base_model.joblib')\n",
    "\n",
    "if load_model_dnn == 1:\n",
    "    dnn = load_model(\"DNN_base_model.h5\")\n",
    "\n",
    "if load_model_knn == 1:\n",
    "    knn_clf = loaded_model = joblib.load('knn_base_model.joblib')\n",
    "\n",
    "if load_model_mlp == 1:\n",
    "    MLP = loaded_model = joblib.load('mlp_base_model.joblib')\n",
    "\n",
    "if load_model_rf == 1:\n",
    "    model_rf = loaded_model = joblib.load('rf_base_model.joblib')\n",
    "\n",
    "if load_model_lgbm == 1:\n",
    "    lgbm = loaded_model = joblib.load('lgbm_base_model.joblib')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "# preds_svm = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# y_scores = y_pred\n",
    "# y_true = y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base leaners predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Prediction RF\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Prediction SVM\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Prediction LGBM\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Prediction DNN\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Prediction ADA\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Prediction MLP\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "Prediction KNN\n",
      "---------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with open(output_file_name, \"a\") as f: print('Generating Predictions', file = f)\n",
    "\n",
    "if use_model_rf == 1:\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Prediction RF')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction RF', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #RF\n",
    "    start = time.time()\n",
    "    preds_rf = rf.predict(X_test)\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_svm == 1:\n",
    "\n",
    "    print('Prediction SVM')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction SVM', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #SVM\n",
    "    start = time.time()\n",
    "    preds_svm = clf.predict(X_test)\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_lgbm == 1:\n",
    "\n",
    "    print('Prediction LGBM')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction LGBM', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #LGBM\n",
    "    start = time.time()\n",
    "    preds_lgbm = lgbm.predict(X_test)\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_dnn == 1:\n",
    "\n",
    "    print('Prediction DNN')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction DNN', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #DNN\n",
    "    start = time.time()\n",
    "    pred_dnn = dnn.predict(X_test)\n",
    "    preds_dnn = np.argmax(pred_dnn,axis = 1)\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_ada == 1:\n",
    "\n",
    "    print('Prediction ADA')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction ADA', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    #ADA\n",
    "    start = time.time()\n",
    "    preds_ada = ada.predict(X_test)\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Prediction MLP')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction MLP', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_mlp == 1:\n",
    "\n",
    "    #MLP\n",
    "    start = time.time()\n",
    "    y_pred = MLP.predict_proba(X_test)\n",
    "    preds_mlp = np.argmax(y_pred,axis = 1)\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('Prediction KNN')\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Prediction KNN', file = f)\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "if use_model_knn == 1:\n",
    "\n",
    "    #KNN\n",
    "    start = time.time()\n",
    "    preds_knn =knn_clf.predict(X_test)\n",
    "    preds_knn\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METRICS - Base Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "# >>> \n",
    "# >>> roc_auc_score(y, clf.predict_proba(X)[:, 1])\n",
    "# 0.99...\n",
    "# >>> roc_auc_score(y, clf.decision_function(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test\n",
    "# pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3    4\n",
      "0  30589.0    125.0    50.0    0.0  0.0\n",
      "1   1168.0  20127.0    14.0    0.0  0.0\n",
      "2    868.0     71.0  4768.0    0.0  0.0\n",
      "3   1209.0     47.0    19.0  308.0  0.0\n",
      "4     44.0      0.0     0.0    0.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9391485851835643\n",
      "Precision total:  0.774775432966692\n",
      "Recall total:  0.5937749017028259\n",
      "F1 total:  0.6282355205511393\n",
      "BACC total:  0.5937749017028259\n",
      "MCC total:  0.8974246859100513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "if use_model_rf == 1:\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('RF base model', file = f)\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('CONFUSION MATRIX')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    pred_label = preds_rf\n",
    "    # pred_label = label[ypred]\n",
    "\n",
    "    confusion_matrix = pd.crosstab(y_test, pred_label,rownames=['Actual ALERT'],colnames = ['Predicted ALERT'], dropna=False).sort_index(axis=0).sort_index(axis=1)\n",
    "    all_unique_values = sorted(set(pred_label) | set(y_test))\n",
    "    z = np.zeros((len(all_unique_values), len(all_unique_values)))\n",
    "    rows, cols = confusion_matrix.shape\n",
    "    z[:rows, :cols] = confusion_matrix\n",
    "    confusion_matrix  = pd.DataFrame(z, columns=all_unique_values, index=all_unique_values)\n",
    "    # confusion_matrix.to_csv('Ensemble_conf_matrix.csv')\n",
    "    # with open(output_file_name, \"a\") as f:print(confusion_matrix,file=f)\n",
    "    print(confusion_matrix)\n",
    "    with open(output_file_name, \"a\") as f: print('Confusion Matrix', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print(confusion_matrix, file = f)\n",
    "\n",
    "\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "    TP_total = sum(TP)\n",
    "    TN_total = sum(TN)\n",
    "    FP_total = sum(FP)\n",
    "    FN_total = sum(FN)\n",
    "\n",
    "    TP_total = np.array(TP_total,dtype=np.float64)\n",
    "    TN_total = np.array(TN_total,dtype=np.float64)\n",
    "    FP_total = np.array(FP_total,dtype=np.float64)\n",
    "    FN_total = np.array(FN_total,dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------------------------------------#----------------------------------------------------------------\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('METRICS')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "    # Acc = ACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # Precision = PRECISION(TP_total, FP_total)\n",
    "    # Recall = RECALL(TP_total, FN_total)\n",
    "    # F1 = F1(Recall,Precision)\n",
    "    # BACC = BACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # MCC = MCC(TP_total,TN_total, FP_total, FN_total)\n",
    "\n",
    "    Acc = accuracy_score(y_test, pred_label)\n",
    "    Precision = precision_score(y_test, pred_label, average='macro')\n",
    "    Recall = recall_score(y_test, pred_label, average='macro')\n",
    "    F1 =  f1_score(y_test, pred_label, average='macro')\n",
    "    BACC = balanced_accuracy_score(y_test, pred_label)\n",
    "    MCC = matthews_corrcoef(y_test, pred_label)\n",
    "\n",
    "    # with open(output_file_name, \"a\") as f:print('Accuracy total: ', Acc,file=f)\n",
    "    print('Accuracy total: ', Acc)\n",
    "    print('Precision total: ', Precision )\n",
    "    print('Recall total: ', Recall )\n",
    "    print('F1 total: ', F1 )\n",
    "    print('BACC total: ', BACC)\n",
    "    print('MCC total: ', MCC)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Accuracy total: ', Acc, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Precision total: ', Precision, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Recall total: ', Recall , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('F1 total: ', F1, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('BACC total: ', BACC , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('MCC total: ', MCC, file = f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3       4\n",
      "0  26866.0   2849.0   786.0  130.0   133.0\n",
      "1   1107.0  16468.0  1951.0  344.0  1439.0\n",
      "2   3182.0    380.0  2014.0   25.0   106.0\n",
      "3    279.0   1012.0   258.0   21.0    13.0\n",
      "4      6.0     12.0    19.0    1.0     6.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.7637988789199925\n",
      "Precision total:  0.4187330923884616\n",
      "Recall total:  0.42972839821586745\n",
      "F1 total:  0.40990190348146227\n",
      "BACC total:  0.42972839821586745\n",
      "MCC total:  0.6020474809587878\n"
     ]
    }
   ],
   "source": [
    "#DNN\n",
    "if use_model_dnn == 1:\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('DNN base model', file = f)\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('CONFUSION MATRIX')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    pred_label = preds_dnn\n",
    "    # pred_label = label[ypred]\n",
    "\n",
    "    confusion_matrix = pd.crosstab(y_test, pred_label,rownames=['Actual ALERT'],colnames = ['Predicted ALERT'], dropna=False).sort_index(axis=0).sort_index(axis=1)\n",
    "    all_unique_values = sorted(set(pred_label) | set(y_test))\n",
    "    z = np.zeros((len(all_unique_values), len(all_unique_values)))\n",
    "    rows, cols = confusion_matrix.shape\n",
    "    z[:rows, :cols] = confusion_matrix\n",
    "    confusion_matrix  = pd.DataFrame(z, columns=all_unique_values, index=all_unique_values)\n",
    "    # confusion_matrix.to_csv('Ensemble_conf_matrix.csv')\n",
    "    # with open(output_file_name, \"a\") as f:print(confusion_matrix,file=f)\n",
    "    print(confusion_matrix)\n",
    "    with open(output_file_name, \"a\") as f: print('Confusion Matrix', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print(confusion_matrix, file = f)\n",
    "\n",
    "\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "    TP_total = sum(TP)\n",
    "    TN_total = sum(TN)\n",
    "    FP_total = sum(FP)\n",
    "    FN_total = sum(FN)\n",
    "\n",
    "    TP_total = np.array(TP_total,dtype=np.float64)\n",
    "    TN_total = np.array(TN_total,dtype=np.float64)\n",
    "    FP_total = np.array(FP_total,dtype=np.float64)\n",
    "    FN_total = np.array(FN_total,dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------------------------------------#----------------------------------------------------------------\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('METRICS')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "    # Acc = ACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # Precision = PRECISION(TP_total, FP_total)\n",
    "    # Recall = RECALL(TP_total, FN_total)\n",
    "    # F1 = F1(Recall,Precision)\n",
    "    # BACC = BACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # MCC = MCC(TP_total,TN_total, FP_total, FN_total)\n",
    "\n",
    "    Acc = accuracy_score(y_test, pred_label)\n",
    "    Precision = precision_score(y_test, pred_label, average='macro')\n",
    "    Recall = recall_score(y_test, pred_label, average='macro')\n",
    "    F1 =  f1_score(y_test, pred_label, average='macro')\n",
    "    BACC = balanced_accuracy_score(y_test, pred_label)\n",
    "    MCC = matthews_corrcoef(y_test, pred_label)\n",
    "\n",
    "    # with open(output_file_name, \"a\") as f:print('Accuracy total: ', Acc,file=f)\n",
    "    print('Accuracy total: ', Acc)\n",
    "    print('Precision total: ', Precision )\n",
    "    print('Recall total: ', Recall )\n",
    "    print('F1 total: ', F1 )\n",
    "    print('BACC total: ', BACC)\n",
    "    print('MCC total: ', MCC)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Accuracy total: ', Acc, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Precision total: ', Precision, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Recall total: ', Recall , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('F1 total: ', F1, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('BACC total: ', BACC , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('MCC total: ', MCC, file = f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3     4\n",
      "0  29270.0    944.0   351.0  173.0  26.0\n",
      "1   1512.0  15605.0  4185.0    7.0   0.0\n",
      "2   2155.0    297.0  3247.0    8.0   0.0\n",
      "3    690.0      0.0    11.0  882.0   0.0\n",
      "4     17.0      0.0     1.0    5.0  21.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.8252394498964768\n",
      "Precision total:  0.6960294069942633\n",
      "Recall total:  0.6574298981875355\n",
      "F1 total:  0.6666067458843546\n",
      "BACC total:  0.6574298981875355\n",
      "MCC total:  0.710375854100207\n"
     ]
    }
   ],
   "source": [
    "#ADA\n",
    "if use_model_ada == 1:\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('ADA base model', file = f)\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('CONFUSION MATRIX')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    pred_label = preds_ada\n",
    "    # pred_label = label[ypred]\n",
    "\n",
    "    confusion_matrix = pd.crosstab(y_test, pred_label,rownames=['Actual ALERT'],colnames = ['Predicted ALERT'], dropna=False).sort_index(axis=0).sort_index(axis=1)\n",
    "    all_unique_values = sorted(set(pred_label) | set(y_test))\n",
    "    z = np.zeros((len(all_unique_values), len(all_unique_values)))\n",
    "    rows, cols = confusion_matrix.shape\n",
    "    z[:rows, :cols] = confusion_matrix\n",
    "    confusion_matrix  = pd.DataFrame(z, columns=all_unique_values, index=all_unique_values)\n",
    "    # confusion_matrix.to_csv('Ensemble_conf_matrix.csv')\n",
    "    # with open(output_file_name, \"a\") as f:print(confusion_matrix,file=f)\n",
    "    print(confusion_matrix)\n",
    "    with open(output_file_name, \"a\") as f: print('Confusion Matrix', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print(confusion_matrix, file = f)\n",
    "\n",
    "\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "    TP_total = sum(TP)\n",
    "    TN_total = sum(TN)\n",
    "    FP_total = sum(FP)\n",
    "    FN_total = sum(FN)\n",
    "\n",
    "    TP_total = np.array(TP_total,dtype=np.float64)\n",
    "    TN_total = np.array(TN_total,dtype=np.float64)\n",
    "    FP_total = np.array(FP_total,dtype=np.float64)\n",
    "    FN_total = np.array(FN_total,dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------------------------------------#----------------------------------------------------------------\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('METRICS')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "    # Acc = ACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # Precision = PRECISION(TP_total, FP_total)\n",
    "    # Recall = RECALL(TP_total, FN_total)\n",
    "    # F1 = F1(Recall,Precision)\n",
    "    # BACC = BACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # MCC = MCC(TP_total,TN_total, FP_total, FN_total)\n",
    "\n",
    "    Acc = accuracy_score(y_test, pred_label)\n",
    "    Precision = precision_score(y_test, pred_label, average='macro')\n",
    "    Recall = recall_score(y_test, pred_label, average='macro')\n",
    "    F1 =  f1_score(y_test, pred_label, average='macro')\n",
    "    BACC = balanced_accuracy_score(y_test, pred_label)\n",
    "    MCC = matthews_corrcoef(y_test, pred_label)\n",
    "\n",
    "    # with open(output_file_name, \"a\") as f:print('Accuracy total: ', Acc,file=f)\n",
    "    print('Accuracy total: ', Acc)\n",
    "    print('Precision total: ', Precision )\n",
    "    print('Recall total: ', Recall )\n",
    "    print('F1 total: ', F1 )\n",
    "    print('BACC total: ', BACC)\n",
    "    print('MCC total: ', MCC)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Accuracy total: ', Acc, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Precision total: ', Precision, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Recall total: ', Recall , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('F1 total: ', F1, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('BACC total: ', BACC , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('MCC total: ', MCC, file = f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2      3     4\n",
      "0  30314.0    178.0   183.0   87.0   2.0\n",
      "1    409.0  20862.0    37.0    1.0   0.0\n",
      "2    252.0     85.0  5354.0   16.0   0.0\n",
      "3    596.0      2.0     8.0  977.0   0.0\n",
      "4     25.0      0.0     0.0    6.0  13.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9682360664568148\n",
      "Precision total:  0.9343014383933239\n",
      "Recall total:  0.7630357415812434\n",
      "F1 total:  0.8152989443588116\n",
      "BACC total:  0.7630357415812434\n",
      "MCC total:  0.9462063278330396\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "if use_model_svm == 1:\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('SVM base model', file = f)\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('CONFUSION MATRIX')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    pred_label = preds_svm\n",
    "    # pred_label = label[ypred]\n",
    "\n",
    "    confusion_matrix = pd.crosstab(y_test, pred_label,rownames=['Actual ALERT'],colnames = ['Predicted ALERT'], dropna=False).sort_index(axis=0).sort_index(axis=1)\n",
    "    all_unique_values = sorted(set(pred_label) | set(y_test))\n",
    "    z = np.zeros((len(all_unique_values), len(all_unique_values)))\n",
    "    rows, cols = confusion_matrix.shape\n",
    "    z[:rows, :cols] = confusion_matrix\n",
    "    confusion_matrix  = pd.DataFrame(z, columns=all_unique_values, index=all_unique_values)\n",
    "    # confusion_matrix.to_csv('Ensemble_conf_matrix.csv')\n",
    "    # with open(output_file_name, \"a\") as f:print(confusion_matrix,file=f)\n",
    "    print(confusion_matrix)\n",
    "    with open(output_file_name, \"a\") as f: print('Confusion Matrix', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print(confusion_matrix, file = f)\n",
    "\n",
    "\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "    TP_total = sum(TP)\n",
    "    TN_total = sum(TN)\n",
    "    FP_total = sum(FP)\n",
    "    FN_total = sum(FN)\n",
    "\n",
    "    TP_total = np.array(TP_total,dtype=np.float64)\n",
    "    TN_total = np.array(TN_total,dtype=np.float64)\n",
    "    FP_total = np.array(FP_total,dtype=np.float64)\n",
    "    FN_total = np.array(FN_total,dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------------------------------------#----------------------------------------------------------------\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('METRICS')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "    # Acc = ACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # Precision = PRECISION(TP_total, FP_total)\n",
    "    # Recall = RECALL(TP_total, FN_total)\n",
    "    # F1 = F1(Recall,Precision)\n",
    "    # BACC = BACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # MCC = MCC(TP_total,TN_total, FP_total, FN_total)\n",
    "\n",
    "    Acc = accuracy_score(y_test, pred_label)\n",
    "    Precision = precision_score(y_test, pred_label, average='macro')\n",
    "    Recall = recall_score(y_test, pred_label, average='macro')\n",
    "    F1 =  f1_score(y_test, pred_label, average='macro')\n",
    "    BACC = balanced_accuracy_score(y_test, pred_label)\n",
    "    MCC = matthews_corrcoef(y_test, pred_label)\n",
    "\n",
    "    # with open(output_file_name, \"a\") as f:print('Accuracy total: ', Acc,file=f)\n",
    "    print('Accuracy total: ', Acc)\n",
    "    print('Precision total: ', Precision )\n",
    "    print('Recall total: ', Recall )\n",
    "    print('F1 total: ', F1 )\n",
    "    print('BACC total: ', BACC)\n",
    "    print('MCC total: ', MCC)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Accuracy total: ', Acc, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Precision total: ', Precision, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Recall total: ', Recall , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('F1 total: ', F1, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('BACC total: ', BACC , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('MCC total: ', MCC, file = f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2       3     4\n",
      "0  30590.0     27.0    51.0    94.0   2.0\n",
      "1     41.0  21267.0     1.0     0.0   0.0\n",
      "2    101.0    141.0  5460.0     5.0   0.0\n",
      "3     98.0      7.0     2.0  1474.0   2.0\n",
      "4     13.0      0.0     0.0     3.0  28.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9901021765111856\n",
      "Precision total:  0.9568243096961192\n",
      "Recall total:  0.9033199786116558\n",
      "F1 total:  0.9262434354690277\n",
      "BACC total:  0.9033199786116558\n",
      "MCC total:  0.9832985858386466\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "if use_model_knn == 1:\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('KNN base model', file = f)\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('CONFUSION MATRIX')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    pred_label = preds_knn\n",
    "    # pred_label = label[ypred]\n",
    "\n",
    "    confusion_matrix = pd.crosstab(y_test, pred_label,rownames=['Actual ALERT'],colnames = ['Predicted ALERT'], dropna=False).sort_index(axis=0).sort_index(axis=1)\n",
    "    all_unique_values = sorted(set(pred_label) | set(y_test))\n",
    "    z = np.zeros((len(all_unique_values), len(all_unique_values)))\n",
    "    rows, cols = confusion_matrix.shape\n",
    "    z[:rows, :cols] = confusion_matrix\n",
    "    confusion_matrix  = pd.DataFrame(z, columns=all_unique_values, index=all_unique_values)\n",
    "    # confusion_matrix.to_csv('Ensemble_conf_matrix.csv')\n",
    "    # with open(output_file_name, \"a\") as f:print(confusion_matrix,file=f)\n",
    "    print(confusion_matrix)\n",
    "    with open(output_file_name, \"a\") as f: print('Confusion Matrix', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print(confusion_matrix, file = f)\n",
    "\n",
    "\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "    TP_total = sum(TP)\n",
    "    TN_total = sum(TN)\n",
    "    FP_total = sum(FP)\n",
    "    FN_total = sum(FN)\n",
    "\n",
    "    TP_total = np.array(TP_total,dtype=np.float64)\n",
    "    TN_total = np.array(TN_total,dtype=np.float64)\n",
    "    FP_total = np.array(FP_total,dtype=np.float64)\n",
    "    FN_total = np.array(FN_total,dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------------------------------------#----------------------------------------------------------------\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('METRICS')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "    # Acc = ACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # Precision = PRECISION(TP_total, FP_total)\n",
    "    # Recall = RECALL(TP_total, FN_total)\n",
    "    # F1 = F1(Recall,Precision)\n",
    "    # BACC = BACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # MCC = MCC(TP_total,TN_total, FP_total, FN_total)\n",
    "\n",
    "    Acc = accuracy_score(y_test, pred_label)\n",
    "    Precision = precision_score(y_test, pred_label, average='macro')\n",
    "    Recall = recall_score(y_test, pred_label, average='macro')\n",
    "    F1 =  f1_score(y_test, pred_label, average='macro')\n",
    "    BACC = balanced_accuracy_score(y_test, pred_label)\n",
    "    MCC = matthews_corrcoef(y_test, pred_label)\n",
    "\n",
    "    # with open(output_file_name, \"a\") as f:print('Accuracy total: ', Acc,file=f)\n",
    "    print('Accuracy total: ', Acc)\n",
    "    print('Precision total: ', Precision )\n",
    "    print('Recall total: ', Recall )\n",
    "    print('F1 total: ', F1 )\n",
    "    print('BACC total: ', BACC)\n",
    "    print('MCC total: ', MCC)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Accuracy total: ', Acc, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Precision total: ', Precision, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Recall total: ', Recall , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('F1 total: ', F1, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('BACC total: ', BACC , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('MCC total: ', MCC, file = f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2       3     4\n",
      "0  30579.0     23.0    32.0   125.0   5.0\n",
      "1     28.0  21275.0     6.0     0.0   0.0\n",
      "2    130.0     20.0  5548.0     9.0   0.0\n",
      "3     45.0      0.0     0.0  1537.0   1.0\n",
      "4     15.0      0.0     0.0     6.0  23.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9925093002508122\n",
      "Precision total:  0.9387445263596114\n",
      "Recall total:  0.891639781821078\n",
      "F1 total:  0.9094569235433629\n",
      "BACC total:  0.891639781821078\n",
      "MCC total:  0.9873749014621037\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "if use_model_mlp == 1:\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('MLP base model', file = f)\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('CONFUSION MATRIX')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    pred_label = preds_mlp\n",
    "    # pred_label = label[ypred]\n",
    "\n",
    "    confusion_matrix = pd.crosstab(y_test, pred_label,rownames=['Actual ALERT'],colnames = ['Predicted ALERT'], dropna=False).sort_index(axis=0).sort_index(axis=1)\n",
    "    all_unique_values = sorted(set(pred_label) | set(y_test))\n",
    "    z = np.zeros((len(all_unique_values), len(all_unique_values)))\n",
    "    rows, cols = confusion_matrix.shape\n",
    "    z[:rows, :cols] = confusion_matrix\n",
    "    confusion_matrix  = pd.DataFrame(z, columns=all_unique_values, index=all_unique_values)\n",
    "    # confusion_matrix.to_csv('Ensemble_conf_matrix.csv')\n",
    "    # with open(output_file_name, \"a\") as f:print(confusion_matrix,file=f)\n",
    "    print(confusion_matrix)\n",
    "    with open(output_file_name, \"a\") as f: print('Confusion Matrix', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print(confusion_matrix, file = f)\n",
    "\n",
    "\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "    TP_total = sum(TP)\n",
    "    TN_total = sum(TN)\n",
    "    FP_total = sum(FP)\n",
    "    FN_total = sum(FN)\n",
    "\n",
    "    TP_total = np.array(TP_total,dtype=np.float64)\n",
    "    TN_total = np.array(TN_total,dtype=np.float64)\n",
    "    FP_total = np.array(FP_total,dtype=np.float64)\n",
    "    FN_total = np.array(FN_total,dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------------------------------------#----------------------------------------------------------------\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('METRICS')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "    # Acc = ACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # Precision = PRECISION(TP_total, FP_total)\n",
    "    # Recall = RECALL(TP_total, FN_total)\n",
    "    # F1 = F1(Recall,Precision)\n",
    "    # BACC = BACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # MCC = MCC(TP_total,TN_total, FP_total, FN_total)\n",
    "\n",
    "    Acc = accuracy_score(y_test, pred_label)\n",
    "    Precision = precision_score(y_test, pred_label, average='macro')\n",
    "    Recall = recall_score(y_test, pred_label, average='macro')\n",
    "    F1 =  f1_score(y_test, pred_label, average='macro')\n",
    "    BACC = balanced_accuracy_score(y_test, pred_label)\n",
    "    MCC = matthews_corrcoef(y_test, pred_label)\n",
    "\n",
    "    # with open(output_file_name, \"a\") as f:print('Accuracy total: ', Acc,file=f)\n",
    "    print('Accuracy total: ', Acc)\n",
    "    print('Precision total: ', Precision )\n",
    "    print('Recall total: ', Recall )\n",
    "    print('F1 total: ', F1 )\n",
    "    print('BACC total: ', BACC)\n",
    "    print('MCC total: ', MCC)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Accuracy total: ', Acc, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Precision total: ', Precision, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Recall total: ', Recall , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('F1 total: ', F1, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('BACC total: ', BACC , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('MCC total: ', MCC, file = f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "         0        1       2       3     4\n",
      "0  30418.0    128.0    83.0    82.0  53.0\n",
      "1    343.0  20863.0    85.0    17.0   1.0\n",
      "2     85.0     31.0  5563.0    28.0   0.0\n",
      "3     81.0      3.0     0.0  1492.0   7.0\n",
      "4     24.0      2.0     0.0     9.0   9.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9821233188008147\n",
      "Precision total:  0.7981397650068244\n",
      "Recall total:  0.8179300923297955\n",
      "F1 total:  0.8062542642352568\n",
      "BACC total:  0.8179300923297955\n",
      "MCC total:  0.969893387766871\n"
     ]
    }
   ],
   "source": [
    "#lgbm\n",
    "\n",
    "if use_model_lgbm == 1:\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('LGBM base model', file = f)\n",
    "\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('CONFUSION MATRIX')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "    pred_label = preds_lgbm\n",
    "    # pred_label = label[ypred]\n",
    "\n",
    "    confusion_matrix = pd.crosstab(y_test, pred_label,rownames=['Actual ALERT'],colnames = ['Predicted ALERT'], dropna=False).sort_index(axis=0).sort_index(axis=1)\n",
    "    all_unique_values = sorted(set(pred_label) | set(y_test))\n",
    "    z = np.zeros((len(all_unique_values), len(all_unique_values)))\n",
    "    rows, cols = confusion_matrix.shape\n",
    "    z[:rows, :cols] = confusion_matrix\n",
    "    confusion_matrix  = pd.DataFrame(z, columns=all_unique_values, index=all_unique_values)\n",
    "    # confusion_matrix.to_csv('Ensemble_conf_matrix.csv')\n",
    "    # with open(output_file_name, \"a\") as f:print(confusion_matrix,file=f)\n",
    "    print(confusion_matrix)\n",
    "    with open(output_file_name, \"a\") as f: print('Confusion Matrix', file = f)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print(confusion_matrix, file = f)\n",
    "\n",
    "\n",
    "    FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "    FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "    TP = np.diag(confusion_matrix)\n",
    "    TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "    TP_total = sum(TP)\n",
    "    TN_total = sum(TN)\n",
    "    FP_total = sum(FP)\n",
    "    FN_total = sum(FN)\n",
    "\n",
    "    TP_total = np.array(TP_total,dtype=np.float64)\n",
    "    TN_total = np.array(TN_total,dtype=np.float64)\n",
    "    FP_total = np.array(FP_total,dtype=np.float64)\n",
    "    FN_total = np.array(FN_total,dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "    #----------------------------------------------------------------#----------------------------------------------------------------\n",
    "\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "    print('METRICS')\n",
    "    print('---------------------------------------------------------------------------------')\n",
    "\n",
    "    # Acc = ACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # Precision = PRECISION(TP_total, FP_total)\n",
    "    # Recall = RECALL(TP_total, FN_total)\n",
    "    # F1 = F1(Recall,Precision)\n",
    "    # BACC = BACC(TP_total,TN_total, FP_total, FN_total)\n",
    "    # MCC = MCC(TP_total,TN_total, FP_total, FN_total)\n",
    "\n",
    "    Acc = accuracy_score(y_test, pred_label)\n",
    "    Precision = precision_score(y_test, pred_label, average='macro')\n",
    "    Recall = recall_score(y_test, pred_label, average='macro')\n",
    "    F1 =  f1_score(y_test, pred_label, average='macro')\n",
    "    BACC = balanced_accuracy_score(y_test, pred_label)\n",
    "    MCC = matthews_corrcoef(y_test, pred_label)\n",
    "\n",
    "    # with open(output_file_name, \"a\") as f:print('Accuracy total: ', Acc,file=f)\n",
    "    print('Accuracy total: ', Acc)\n",
    "    print('Precision total: ', Precision )\n",
    "    print('Recall total: ', Recall )\n",
    "    print('F1 total: ', F1 )\n",
    "    print('BACC total: ', BACC)\n",
    "    print('MCC total: ', MCC)\n",
    "\n",
    "    with open(output_file_name, \"a\") as f: print('Accuracy total: ', Acc, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Precision total: ', Precision, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('Recall total: ', Recall , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('F1 total: ', F1, file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('BACC total: ', BACC , file = f)\n",
    "    with open(output_file_name, \"a\") as f: print('MCC total: ', MCC, file = f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the stronger model - STACK level 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "with open(output_file_name, \"a\") as f: print('------------START of STRONGER LEARNER - STACK 01 -----------------', file = f)\n",
    "\n",
    "\n",
    "# Stack the vectors horizontally to create a matrix\n",
    "column_features = ['dnn','rf','lgbm','ada','knn','mlp','svm','label']\n",
    "training_matrix = np.column_stack((\n",
    "                          preds_dnn,\n",
    "                          preds_rf,\n",
    "                          preds_lgbm,\n",
    "                          preds_ada,\n",
    "                          preds_knn, \n",
    "                          preds_mlp,\n",
    "                          preds_svm,\n",
    "                          y_test\n",
    "                          ))\n",
    "\n",
    "# Print the resulting matrix\n",
    "print(training_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_level_01 = pd.DataFrame(training_matrix, columns=column_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_01 = df_level_01.pop('label')\n",
    "X_01 = df_level_01\n",
    "df_level_01 = df_level_01.assign(label = y_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dnn</th>\n",
       "      <th>rf</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>ada</th>\n",
       "      <th>knn</th>\n",
       "      <th>mlp</th>\n",
       "      <th>svm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59402</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59404</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59405</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59406</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59407 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dnn  rf  lgbm  ada  knn  mlp  svm\n",
       "0        0   0     0    0    0    0    0\n",
       "1        1   1     1    1    1    1    1\n",
       "2        0   0     0    0    0    0    0\n",
       "3        0   0     0    0    0    0    0\n",
       "4        0   0     0    0    0    0    0\n",
       "...    ...  ..   ...  ...  ...  ...  ...\n",
       "59402    1   1     1    1    1    1    1\n",
       "59403    0   0     0    0    0    0    0\n",
       "59404    0   0     0    0    0    0    0\n",
       "59405    0   0     0    0    0    0    0\n",
       "59406    0   0     0    0    0    0    0\n",
       "\n",
       "[59407 rows x 7 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "59402    1\n",
       "59403    0\n",
       "59404    0\n",
       "59405    0\n",
       "59406    0\n",
       "Name: label, Length: 59407, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dnn</th>\n",
       "      <th>rf</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>ada</th>\n",
       "      <th>knn</th>\n",
       "      <th>mlp</th>\n",
       "      <th>svm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59402</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59403</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59404</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59405</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59406</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59407 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dnn  rf  lgbm  ada  knn  mlp  svm  label\n",
       "0        0   0     0    0    0    0    0      0\n",
       "1        1   1     1    1    1    1    1      1\n",
       "2        0   0     0    0    0    0    0      0\n",
       "3        0   0     0    0    0    0    0      0\n",
       "4        0   0     0    0    0    0    0      0\n",
       "...    ...  ..   ...  ...  ...  ...  ...    ...\n",
       "59402    1   1     1    1    1    1    1      1\n",
       "59403    0   0     0    0    0    0    0      0\n",
       "59404    0   0     0    0    0    0    0      0\n",
       "59405    0   0     0    0    0    0    0      0\n",
       "59406    0   0     0    0    0    0    0      0\n",
       "\n",
       "[59407 rows x 8 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_level_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.7\n",
    "\n",
    "X_train_01,X_test_01, y_train_01, y_test_01 = sklearn.model_selection.train_test_split(X_01, y_01, train_size=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Defining DNN Model\n",
      "---------------------------------------------------------------------------------\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 70)                560       \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 5)                 355       \n",
      "=================================================================\n",
      "Total params: 15,825\n",
      "Trainable params: 15,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#DNN\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining DNN Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#Model Parameters\n",
    "dropout_rate = 0.01\n",
    "nodes = 70\n",
    "out_layer = 5\n",
    "optimizer='adam'\n",
    "loss='sparse_categorical_crossentropy'\n",
    "epochs=5\n",
    "batch_size=2*256\n",
    "\n",
    "\n",
    "num_columns = X_train_01.shape[1]\n",
    "\n",
    "dnn_01 = tf.keras.Sequential()\n",
    "\n",
    "# Input layer\n",
    "dnn_01.add(tf.keras.Input(shape=(num_columns,)))\n",
    "\n",
    "# Dense layers with dropout\n",
    "dnn_01.add(tf.keras.layers.Dense(nodes))\n",
    "dnn_01.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "dnn_01.add(tf.keras.layers.Dense(nodes))\n",
    "dnn_01.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "dnn_01.add(tf.keras.layers.Dense(nodes))\n",
    "dnn_01.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "dnn_01.add(tf.keras.layers.Dense(nodes))\n",
    "dnn_01.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "dnn.add(tf.keras.layers.Dense(nodes))\n",
    "dnn.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "# Output layer\n",
    "dnn_01.add(tf.keras.layers.Dense(out_layer))\n",
    "\n",
    "\n",
    "\n",
    "dnn_01.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "dnn_01.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Training DNN\n",
      "---------------------------------------------------------------------------------\n",
      "Epoch 1/5\n",
      "32/82 [==========>...................] - ETA: 0s - loss: 1.4411"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 1s 6ms/step - loss: 0.9644\n",
      "Epoch 2/5\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4250\n",
      "Epoch 3/5\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.3967\n",
      "Epoch 4/5\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.4926\n",
      "Epoch 5/5\n",
      "82/82 [==============================] - 0s 6ms/step - loss: 0.6453\n"
     ]
    }
   ],
   "source": [
    "print('---------------------------------------------------------------------------------')\n",
    "print('Training DNN')\n",
    "with open(output_file_name, \"a\") as f: print('---------------------------------------------------------------------------------', file = f)\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('Training DNN', file = f)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "# Convert Y_test back to its original format\n",
    "# y_test = np.argmax(Y_test, axis=1)\n",
    "\n",
    "# Start the timer\n",
    "start = time.time()\n",
    "dnn_01.fit(X_train_01, y_train_01, epochs=epochs, batch_size=batch_size)\n",
    "# End the timer\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "# joblib.dump(dnn_01, 'dnn_level_01.joblib')\n",
    "dnn_01.save(\"dnn_level_01.h5\")\n",
    "\n",
    "# Calculate the time taken and print it out\n",
    "# print(f'Time taken for training: {time_taken} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_01 = load_model(\"dnn_level_01.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DNN\n",
    "start = time.time()\n",
    "pred_dnn = dnn_01.predict(X_test_01)\n",
    "preds_dnn_01 = np.argmax(pred_dnn,axis = 1)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = y_test_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------\n",
    "with open(output_file_name, \"a\") as f: print('Stack model - Strong learner - level 01', file = f)\n",
    "with open(output_file_name, \"a\") as f: print('-------------------------------------------------------', file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "        0       1       2      3    4\n",
      "0  7667.0    59.0   560.0  998.0  0.0\n",
      "1     3.0  1090.0  5249.0    2.0  0.0\n",
      "2     1.0   238.0  1489.0    5.0  0.0\n",
      "3     0.0   348.0   101.0    2.0  0.0\n",
      "4     0.0     9.0     2.0    0.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.5749873758626494\n",
      "Precision total:  0.36553073628548777\n",
      "Recall total:  0.3722567111467182\n",
      "F1 total:  0.30054143561282254\n",
      "BACC total:  0.3722567111467182\n",
      "MCC total:  0.4491257396926296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('CONFUSION MATRIX')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "with open(output_file_name, \"a\") as f: print('DNN', file = f)\n",
    "pred_label = preds_dnn_01\n",
    "\n",
    "# pred_label = ypred\n",
    "#pred_label = label[ypred]\n",
    "\n",
    "confusion_matrix = pd.crosstab(y_test_01, pred_label,rownames=['Actual ALERT'],colnames = ['Predicted ALERT'], dropna=False).sort_index(axis=0).sort_index(axis=1)\n",
    "all_unique_values = sorted(set(pred_label) | set(y_test_01))\n",
    "z = np.zeros((len(all_unique_values), len(all_unique_values)))\n",
    "rows, cols = confusion_matrix.shape\n",
    "z[:rows, :cols] = confusion_matrix\n",
    "confusion_matrix  = pd.DataFrame(z, columns=all_unique_values, index=all_unique_values)\n",
    "# confusion_matrix.to_csv('Ensemble_conf_matrix.csv')\n",
    "# with open(output_file_name, \"a\") as f:print(confusion_matrix,file=f)\n",
    "print(confusion_matrix)\n",
    "with open(output_file_name, \"a\") as f: print('Confusion Matrix', file = f)\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print(confusion_matrix, file = f)\n",
    "\n",
    "\n",
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "TP_total = sum(TP)\n",
    "TN_total = sum(TN)\n",
    "FP_total = sum(FP)\n",
    "FN_total = sum(FN)\n",
    "\n",
    "TP_total = np.array(TP_total,dtype=np.float64)\n",
    "TN_total = np.array(TN_total,dtype=np.float64)\n",
    "FP_total = np.array(FP_total,dtype=np.float64)\n",
    "FN_total = np.array(FN_total,dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------#----------------------------------------------------------------\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('METRICS')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "# Acc = ACC(TP_total,TN_total, FP_total, FN_total)\n",
    "# Precision = PRECISION(TP_total, FP_total)\n",
    "# Recall = RECALL(TP_total, FN_total)\n",
    "# F1 = F1(Recall,Precision)\n",
    "# BACC = BACC(TP_total,TN_total, FP_total, FN_total)\n",
    "# MCC = MCC(TP_total,TN_total, FP_total, FN_total)\n",
    "\n",
    "\n",
    "Acc = accuracy_score(y_test_01, pred_label)\n",
    "Precision = precision_score(y_test_01, pred_label, average='macro')\n",
    "Recall = recall_score(y_test_01, pred_label, average='macro')\n",
    "F1 =  f1_score(y_test_01, pred_label, average='macro')\n",
    "BACC = balanced_accuracy_score(y_test_01, pred_label)\n",
    "MCC = matthews_corrcoef(y_test_01, pred_label)\n",
    "\n",
    "# with open(output_file_name, \"a\") as f:print('Accuracy total: ', Acc,file=f)\n",
    "print('Accuracy total: ', Acc)\n",
    "print('Precision total: ', Precision )\n",
    "print('Recall total: ', Recall )\n",
    "print('F1 total: ', F1 )\n",
    "print('BACC total: ', BACC)\n",
    "print('MCC total: ', MCC)\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('Accuracy total: ', Acc, file = f)\n",
    "with open(output_file_name, \"a\") as f: print('Precision total: ', Precision, file = f)\n",
    "with open(output_file_name, \"a\") as f: print('Recall total: ', Recall , file = f)\n",
    "with open(output_file_name, \"a\") as f: print('F1 total: ', F1, file = f)\n",
    "with open(output_file_name, \"a\") as f: print('BACC total: ', BACC , file = f)\n",
    "with open(output_file_name, \"a\") as f: print('MCC total: ', MCC, file = f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "Defining SVM Model\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('Defining SVM Model')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Instantiate the SGDClassifier with additional hyperparameters\n",
    "clf = SGDClassifier(\n",
    "    loss='hinge',           # hinge loss for linear SVM\n",
    "    penalty='l2',           # L2 regularization to prevent overfitting\n",
    "    alpha=1e-4,             # Learning rate (small value for fine-grained updates)\n",
    "    max_iter=1000,          # Number of passes over the training data\n",
    "    random_state=42,        # Seed for reproducible results\n",
    "    learning_rate='optimal' # Automatically adjusts the learning rate based on the training data\n",
    ")\n",
    "\n",
    "#SVM\n",
    "start = time.time()\n",
    "clf.fit(X_train_01, y_train_01)\n",
    "end = time.time()\n",
    "clf.score(X_train_01, y_train_01)\n",
    "time_taken = end - start\n",
    "with open(output_file_name, \"a\") as f: print('Elapsed training time ', time_taken, file = f)\n",
    "joblib.dump(clf, 'svm_level_01.joblib')\n",
    "\n",
    "\n",
    "clf = loaded_model = joblib.load('svm_level_01.joblib')\n",
    "\n",
    "\n",
    "#SVM\n",
    "start = time.time()\n",
    "preds_svm_01 = clf.predict(X_test_01)\n",
    "end = time.time()\n",
    "time_taken = end - start\n",
    "with open(output_file_name, \"a\") as f: print('Elapsed prediction time ', time_taken, file = f)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------\n",
      "CONFUSION MATRIX\n",
      "---------------------------------------------------------------------------------\n",
      "        0       1      2      3    4\n",
      "0  9042.0   230.0    1.0   11.0  0.0\n",
      "1   137.0  6207.0    0.0    0.0  0.0\n",
      "2    10.0  1072.0  650.0    1.0  0.0\n",
      "3    11.0    21.0    1.0  418.0  0.0\n",
      "4     1.0     2.0    0.0    8.0  0.0\n",
      "---------------------------------------------------------------------------------\n",
      "METRICS\n",
      "---------------------------------------------------------------------------------\n",
      "Accuracy total:  0.9155024406665545\n",
      "Precision total:  0.7516147186363611\n",
      "Recall total:  0.6508479677533582\n",
      "F1 total:  0.6716801573836702\n",
      "BACC total:  0.6508479677533582\n",
      "MCC total:  0.8599951010231157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "with open(output_file_name, \"a\") as f: print('-------------------------------------------------------', file = f)\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('CONFUSION MATRIX')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "with open(output_file_name, \"a\") as f: print('SVM', file = f)\n",
    "pred_label = preds_svm_01\n",
    "\n",
    "# pred_label = ypred\n",
    "#pred_label = label[ypred]\n",
    "\n",
    "confusion_matrix = pd.crosstab(y_test_01, pred_label,rownames=['Actual ALERT'],colnames = ['Predicted ALERT'], dropna=False).sort_index(axis=0).sort_index(axis=1)\n",
    "all_unique_values = sorted(set(pred_label) | set(y_test_01))\n",
    "z = np.zeros((len(all_unique_values), len(all_unique_values)))\n",
    "rows, cols = confusion_matrix.shape\n",
    "z[:rows, :cols] = confusion_matrix\n",
    "confusion_matrix  = pd.DataFrame(z, columns=all_unique_values, index=all_unique_values)\n",
    "# confusion_matrix.to_csv('Ensemble_conf_matrix.csv')\n",
    "# with open(output_file_name, \"a\") as f:print(confusion_matrix,file=f)\n",
    "print(confusion_matrix)\n",
    "with open(output_file_name, \"a\") as f: print('Confusion Matrix', file = f)\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print(confusion_matrix, file = f)\n",
    "\n",
    "\n",
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
    "TP_total = sum(TP)\n",
    "TN_total = sum(TN)\n",
    "FP_total = sum(FP)\n",
    "FN_total = sum(FN)\n",
    "\n",
    "TP_total = np.array(TP_total,dtype=np.float64)\n",
    "TN_total = np.array(TN_total,dtype=np.float64)\n",
    "FP_total = np.array(FP_total,dtype=np.float64)\n",
    "FN_total = np.array(FN_total,dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------#----------------------------------------------------------------\n",
    "\n",
    "print('---------------------------------------------------------------------------------')\n",
    "print('METRICS')\n",
    "print('---------------------------------------------------------------------------------')\n",
    "\n",
    "# Acc = ACC(TP_total,TN_total, FP_total, FN_total)\n",
    "# Precision = PRECISION(TP_total, FP_total)\n",
    "# Recall = RECALL(TP_total, FN_total)\n",
    "# F1 = F1(Recall,Precision)\n",
    "# BACC = BACC(TP_total,TN_total, FP_total, FN_total)\n",
    "# MCC = MCC(TP_total,TN_total, FP_total, FN_total)\n",
    "\n",
    "\n",
    "Acc = accuracy_score(y_test_01, pred_label)\n",
    "Precision = precision_score(y_test_01, pred_label, average='macro')\n",
    "Recall = recall_score(y_test_01, pred_label, average='macro')\n",
    "F1 =  f1_score(y_test_01, pred_label, average='macro')\n",
    "BACC = balanced_accuracy_score(y_test_01, pred_label)\n",
    "MCC = matthews_corrcoef(y_test_01, pred_label)\n",
    "\n",
    "# with open(output_file_name, \"a\") as f:print('Accuracy total: ', Acc,file=f)\n",
    "print('Accuracy total: ', Acc)\n",
    "print('Precision total: ', Precision )\n",
    "print('Recall total: ', Recall )\n",
    "print('F1 total: ', F1 )\n",
    "print('BACC total: ', BACC)\n",
    "print('MCC total: ', MCC)\n",
    "\n",
    "with open(output_file_name, \"a\") as f: print('Accuracy total: ', Acc, file = f)\n",
    "with open(output_file_name, \"a\") as f: print('Precision total: ', Precision, file = f)\n",
    "with open(output_file_name, \"a\") as f: print('Recall total: ', Recall , file = f)\n",
    "with open(output_file_name, \"a\") as f: print('F1 total: ', F1, file = f)\n",
    "with open(output_file_name, \"a\") as f: print('BACC total: ', BACC , file = f)\n",
    "with open(output_file_name, \"a\") as f: print('MCC total: ', MCC, file = f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import sklearn\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# split = 0.7\n",
    "\n",
    "# #AUC ROC\n",
    "# #---------------------------------------------------------------------\n",
    "\n",
    "# #AUCROC\n",
    "# aucroc =[]\n",
    "# y_array = [y_0,y_1,y_2,y_3,y_4]\n",
    "# for j in range(0,len(y_array)):\n",
    "#     # print(j)\n",
    "#     #------------------------------------------------------------------------------------------------------------\n",
    "#     X_train,X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y_array[j], train_size=split)\n",
    "    \n",
    "#     # evaluate the model\n",
    "\n",
    "#     knn_clf.fit(X_train,y_train)\n",
    "#     y_pred=knn_clf.predict(X_test) #These are the predicted output value\n",
    "#     # y_pred = knn_clf.predict_proba(X_test)\n",
    "\n",
    "    \n",
    "#     y_scores = y_pred\n",
    "#     y_true = y_test\n",
    "\n",
    "#     # model = LGBMClassifier()\n",
    "#     # model.fit(X_train, y_train)\n",
    "#     # y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "#     y_scores = y_pred\n",
    "#     y_true = y_test\n",
    "    \n",
    "#     # Calculate AUC-ROC score\n",
    "#     auc_roc_score= roc_auc_score(y_true, y_scores,  average='weighted')  # Use 'micro' or 'macro' for different averaging strategies\n",
    "#     # print(\"AUC-ROC Score class:\", auc_roc_score)\n",
    "#     aucroc.append(auc_roc_score)\n",
    "#     #-------------------------------------------------------------------------------------------------------    -----\n",
    "#     # Calculate the average\n",
    "# average = sum(aucroc) / len(aucroc)\n",
    "\n",
    "# # Display the result\n",
    "# # with open(output_file_name, \"a\") as f:print(\"AUC ROC Average:\", average, file = f)\n",
    "# print(\"AUC ROC Average:\", average)\n",
    "\n",
    "# #End AUC ROC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
